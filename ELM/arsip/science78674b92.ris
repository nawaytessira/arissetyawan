TY  - JOUR
T1  - The memory degradation based online sequential extreme learning machine
JO  - Neurocomputing
VL  - 275
IS  - 
SP  - 2864
EP  - 2879
PY  - 2018/1/31/
T2  - 
AU  - Zou, Quan-Yi
AU  - Wang, Xiao-Jun
AU  - Zhou, Chang-Jun
AU  - Zhang, Qiang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.11.030
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217317897
KW  - Online learning
KW  - Extreme learning machine
KW  - Memory factor
KW  - Similarity
AB  - Abstract
In online learning, the contribution of old samples to a model decreases as time passes, and old samples gradually become invalid. Although the Online Sequential Extreme Learning Machine (OS-ELM) can avoid the repetitive training of old samples, invalid samples are still used, which goes against improving the accuracy of an OS-ELM model. The Online Sequence Extreme Learning Machine with Forgetting Mechanism (FOS-ELM) timely discards invalid samples, but it does not consider the differences among valid samples and then hasÂ the limitation on boosting the accuracy and generalization. To solve this issue, the Memory Degradation Based OS-ELM (MDOS-ELM) is proposed in this paper. The MDOS-ELM adjusts the weights of the old and new samples in real time by a self-adaptive memory factor, and simultaneously discards invalid samples. The self-adaptive memory factor is determined by two elements. One is the similarity between the new and old samples, and the other is the prediction errors of the current training samples on the previous model. The performance of the proposed MDOS-ELM is validated on both regression and classification datasets which include an artificial dataset and twenty-two real-world dataset. The results demonstrate that the MDOS-ELM model outperforms the OS-ELM and the FOS-ELM models on the accuracy and generalization.
ER  - 

TY  - JOUR
T1  - Ensemble dropout extreme learning machine via fuzzy integral for data classification
JO  - Neurocomputing
VL  - 275
IS  - 
SP  - 1043
EP  - 1052
PY  - 2018/1/31/
T2  - 
AU  - Zhai, Junhai
AU  - Zang, Liguang
AU  - Zhou, Zhaoyi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.09.047
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217315667
KW  - Extreme learning machine
KW  - Dropout
KW  - Ensemble learning
KW  - Fuzzy integral
KW  - Data classification
AB  - Abstract
Extreme learning machine (ELM) is a simple but efficient algorithm for training single hidden layer feed-forward neural networks (SLFNs) with fast speed and good generalization ability. ELM has been successfully applied to many fields, such as pattern recognition, computer vision, biological information processing, etc. However, there are two problems in ELM. the first one is architecture selection, the second one is prediction instability. In order to deal with the two problems, based on dropout technique, an ensemble learning method is proposed in this paper. The proposed method can solve the first problem and can improve prediction stability. Our experimental results and statistical analysis on 14 data sets confirm this conclusion. Furthermore, our experimental results also show that the proposed approach outperforms the original ELM on prediction stability and classification accuracy.
ER  - 

TY  - JOUR
T1  - Local kernel alignment based multi-view clustering using extreme learning machine
JO  - Neurocomputing
VL  - 275
IS  - 
SP  - 1099
EP  - 1111
PY  - 2018/1/31/
T2  - 
AU  - Wang, Qiang
AU  - Dou, Yong
AU  - Liu, Xinwang
AU  - Xia, Fei
AU  - Lv, Qi
AU  - Yang, Ke
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.09.060
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217315795
KW  - Multi-view clustering
KW  - Extreme learning machine
KW  - Local kernel alignment
AB  - Abstract
A similarity or dissimilarity measure, such as the Euclidean distance, is crucial to discriminative clustering algorithms. These measures used to calculate pairwise similarities between samples rely on data representations in a feature space. However, discriminative clustering fails if the samples in a feature space are linearly inseparable. This problem can be solved by performing a nonlinear data transformation into a high dimensional feature space, which can increase the probability of the linear separability of the samples within the transformed feature space and simplify the associated data structure. Mercer kernels, which are constructed using such a nonlinear data transformation, have been widely used in clustering tasks. Extreme learning machine (ELM) is a new method that exhibits promising clustering performance owing to its universal approximation capability, easy parameter selection, explicit feature mapping process, and excellent feature representation capability. This study proposes an ELM based multi-view learning approach with different views generated by ELM random feature mapping with respect to different hidden-layer nodes, and exploits the properties of these views. Experiments show that better clustering results can be obtained by combining these views together compared with the corresponding ELM-based single-view clustering methods and the traditional algorithms which are performed in the feature space of the original data. Moreover, local kernel alignment property is widespread in these views. This alignment helps the clustering algorithm focus on closer sample pairs. This study also proposes an ELM based multiple kernel clustering algorithm with local kernel alignment maximization. The proposed algorithm is experimentally demonstrated on 10 single-view benchmark datasets and yields superior clustering performance when compared with the state-of-the-art multi-view clustering methods in recent literatures. Thus, the effectiveness and superiority of maximizing local kernel alignment on those views constructed by the proposed method are verified.
ER  - 

TY  - JOUR
T1  - Feature selection of generalized extreme learning machine for regression problems
JO  - Neurocomputing
VL  - 275
IS  - 
SP  - 2810
EP  - 2823
PY  - 2018/1/31/
T2  - 
AU  - Zhao, Yong-Ping
AU  - Pan, Ying-Ting
AU  - Song, Fang-Quan
AU  - Sun, Liguo
AU  - Chen, Ting-Hao
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.11.056
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217318155
KW  - Single hidden layer feedforward network
KW  - Extreme learning machine
KW  - Feature selection
KW  - Greedy learning
KW  - Iterative updating
AB  - Abstract
Recently a generalized single-hidden layer feedforward network was proposed, which is an extension of the original extreme learning machine (ELM). Different from the traditional ELM, this generalized ELM (GELM) utilizes the p-order reduced polynomial functions of complete input features as output weights. According to the empirical results, there may be insignificant or redundant input features to construct the p-order reduced polynomial function as output weights in GELM. However, to date there has not been such work of selecting appropriate input features used for constructing output weights of GELM. Hence, in this paper two greedy learning algorithms, i.e., a forward feature selection algorithm (FFS-GELM) and a backward feature selection algorithm (BFS-GELM), are first proposed to tackle this issue. To reduce the computational complexity, an iterative strategy is used in FFS-GELM, and its convergence is proved. In BFS-GELM, a decreasing iteration is applied to decay this model, and in this process an accelerating scheme was proposed to speed up computation of removing the insignificant or redundant features. To show the effectiveness of the proposed FFS-GELM and BFS-GELM, twelve benchmark data sets are employed to do experiments. From these reports, it is demonstrated that both FFS-GELM and BFS-GELM can select appropriate input features to construct the p-order reduced polynomial function as output weights for GELM. FFS-GELM and BFS-GELM enhance the generalization performance and simultaneously reduce the testing time compared to the original GELM. BFS-GELM works better than FFS-GELM in terms of the sparsity ratio, the testing time and the training time. However, it slightly loses the advantage in the generalization performance over FFS-GELM.
ER  - 

TY  - JOUR
T1  - Hyperspectral image classification by AdaBoost weighted composite kernel extreme learning machines
JO  - Neurocomputing
VL  - 275
IS  - 
SP  - 1725
EP  - 1733
PY  - 2018/1/31/
T2  - 
AU  - Li, Lu
AU  - Wang, Chengyi
AU  - Li, Wei
AU  - Chen, Jingbo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.09.004
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314753
KW  - Hyperspectral image classification
KW  - Extreme learning machine
KW  - Composite Kernel
KW  - AdaBoost
AB  - Abstract
Extreme learning machine (ELM) is an efficient learning algorithm for multi-classification and regression. However, original ELM doesn't consider the weight of each sample in training-set, which may cause the accuracy decreasing especially in imbalanced datasets. Even if each training sample is assigned with an extra weight, the problem on how to determinate the weight adaptively still remains. Inspiration by AdaBoost algorithm, we embed the weighted ELM algorithm in AdaBoost framework. In the meanwhile, we incorporate spatial and spectral information in composite kernel for each sample, which has a good performance in hyperspectral image (HSI) classification. By combining composite kernel methods and Adaboost framework with weighted ELM, a novel algorithm, namely AdaBoost composite kernel extreme learning machines denoted as AdaBoost-WCKELM is proposed. Experimental results demonstrate that the proposed method outperforms current state-of-the-art algorithms and derives a good improvement in HSI classification accuracy.
ER  - 

TY  - JOUR
T1  - Robot teaching by teleoperation based on visual interaction and extreme learning machine
JO  - Neurocomputing
VL  - 275
IS  - 
SP  - 2093
EP  - 2103
PY  - 2018/1/31/
T2  - 
AU  - Xu, Yang
AU  - Yang, Chenguang
AU  - Zhong, Junpei
AU  - Wang, Ning
AU  - Zhao, Lijun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.10.034
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217316855
KW  - Robot teaching
KW  - Teleoperation
KW  - Extreme learning machine (ELM)
KW  - Human-robot interaction (HRI)
AB  - Abstract
Compared with traditional robot teaching methods, robots can learn various human-like skills in a more efficient and natural manner through teleoperation. In this paper, we propose a teleoperation method based on human-robot interaction (HRI), which mainly uses visual information. With only one teleoperation, the robot can reproduce a trajectory. There is a certain error between this trajectory and the optimal trajectory due to the cause of the human demonstrator or the robot. So we use an extreme learning machine (ELM) based algorithm to transfer the demonstratorâs motions to the robot. To verify the method, we use a Microsoft KinectV2 to capture the human body motion and the hand state, according to which a Baxter robot in Virtual Robot Experimentation Platform (V-REP) will be controlled by the command. Through learning and training by the ELM, the robot in V-REP can complete a certain task autonomously and the robot in reality can reproduce this trajectory well. The experimental results show that the developed method has achieved satisfactory performance.
ER  - 

TY  - JOUR
T1  - Ensemble based reactivated regularization extreme learning machine for classification
JO  - Neurocomputing
VL  - 275
IS  - 
SP  - 255
EP  - 266
PY  - 2018/1/31/
T2  - 
AU  - Zhang, Boyang
AU  - Ma, Zhao
AU  - Liu, Yingyi
AU  - Yuan, Haiwen
AU  - Sun, Lingjie
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.07.018
UR  - https://www.sciencedirect.com/science/article/pii/S092523121731264X
KW  - Ensemble
KW  - Extreme learning machine
KW  - Reactivated
KW  - Majority voting
AB  - Abstract
Ensemble trick has been widely used in extreme learning machine (ELM), and most paradigms concern about the training phase with expectation of improving their generalization ability. Unlike traditional strategies, this paper pays more attention to the prediction phase and proposes a discriminatory approach called ensemble based reactivated regularization ELM (ER2-ELM). In short, the novel literature consists of two interrelated steps where the probability density estimation is first conducted to show the degree of difficulty of identifying an instance, and then a random factor is adopted to determine whether the ELM base learner is sequentially reactivated. As such, instances easily to identify cost less computing burden, while the vague ones are taken carefully consideration. Compared with other ensemble methods, the prediction computation overhead decreases. In the end, a number of examples, including UCI benchmark datasets, handwritten digits, object detection, etc., are employed so as to illustrate its state-of-the-art performance.
ER  - 

TY  - JOUR
T1  - Multi-modal local receptive field extreme learning machine for object recognition
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 4
EP  - 11
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Liu, Huaping
AU  - Li, Fengxue
AU  - Xu, Xinying
AU  - Sun, Fuchun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.04.077
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314169
KW  - Representation learning
KW  - Multi-modal
KW  - Local receptive field
KW  - Extreme learning machine
AB  - Abstract
Learning rich representations efficiently plays an important role in the multi-modal recognition task, which is crucial to achieving high generalization performance. To address this problem, in this paper, we propose an effective Multi-Modal Local Receptive Field Extreme Learning Machine (MM-LRF-ELM) structure, while maintaining ELMâs advantages of training efficiency. In this structure, LRF-ELM is first conducted for feature extraction for each modality separately. And then, the shared layer is developed by combining these features from each modality. Finally, the Extreme Learning Machine (ELM) is used as supervised feature classifier for the final decision. Experimental validation on Washington RGB-D Object Dataset illustrates that the proposed multiple modality fusion method achieves better recognition performance.
ER  - 

TY  - JOUR
T1  - Extreme learning machines with heterogeneous data types
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 38
EP  - 52
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - ValdÃ©s, Julio J.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.02.103
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314091
KW  - Extreme learning machines
KW  - Heterogeneous data types
KW  - Nonlinear space transformations
KW  - Intrinsic dimension
KW  - Dissimilarities
KW  - Machine learning
KW  - Classification
KW  - Regression
AB  - Abstract
Current advances in communication, sensor and computing technologies are generating information in never before seen amounts and at constantly increasing rates (i.e. the information explosion, the Internet of Things). From the point of view of data analytics, the information is composed of a diversity of data types and it contains uncertainties and incompleteness of different degrees, which add an extra component to the original heterogeneity. Many data mining and machine learning methods do not handle heterogeneity well.

Extreme learning machines (ELM) are interesting computational algorithms because of their simplicity, their good performance and their speed. They can be extended for processing information composed of heterogeneous data types (HT-ELM), capable of addressing classification and regression problems with complex data. Two approaches are discussed: one works directly with the heterogeneous data and the other one transforms the information into simpler homogeneous spaces that preserve structural properties. In them, standard learning methods can be applied, including classical ELMs among others. Both approaches are illustrated using real world examples involving heterogeneous predictor variables composed of mixtures of nominal, ordinal, interval, ratio, fuzzy variables, and entire empirical probability distributions. In all cases HT-ELM and ELM models produced results that compare favorably with well-established methods.
ER  - 

TY  - JOUR
T1  - Automatic detection of neovascularization in retinal images using extreme learning machine
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 218
EP  - 227
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Huang, He
AU  - Ma, He
AU  - JW van Triest, Han
AU  - Wei, Yinghua
AU  - Qian, Wei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.03.093
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217313991
KW  - Detection of neovascularization
KW  - Retinal image
KW  - Extreme learning machine
AB  - Abstract
Diabetic Retinopathy is one complication of diabetes, which can cause blindness. Diabetic retinopathy can be divided into Non-Proliferative Diabetic Retinopathy (NPDR) and Proliferative Diabetic Retinopahy (PDR), and neovascularization is a key symbol to make diagnosis between them. An automatic detection of neovascularization in retinal images using extreme learning machine is proposed. Furthermore, we use a series of filter banks to get the features of neovascularization from retinal images. The detection framework is evaluated with images annotated by expert ophthalmologists based on the images selected from several public retinal image databases. The experimental results illustrate that the framework can mark and show the suspected neovascularization regions to ophthalmologists, and thus support for their decision making.
ER  - 

TY  - JOUR
T1  - Discriminant document embeddings with an extreme learning machine for classifying clinical narratives
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 129
EP  - 138
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Lauren, Paula
AU  - Qu, Guangzhi
AU  - Zhang, Feng
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.01.117
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314157
KW  - Document classification
KW  - Feature learning
KW  - Word embeddings
KW  - Document embeddings
KW  - Skip-gram
KW  - PV-DBOW
KW  - Multiple discriminant analysis
KW  - Extreme learning machines
KW  - Clinical narratives
AB  - Abstract
The unstructured nature of clinical narratives makes them complex for automatically extracting information. Feature learning is an important precursor to document classification, a sub-discipline of natural language processing (NLP). In NLP, word and document embeddings are an effective approach for generating word and document representations (vectors) in a low-dimensional space. This paper uses skip-gram and paragraph vectors-distributed bag of words (PV-DBOW) with multiple discriminant analysis (MDA) to arrive at discriminant document embeddings. A kernel-based extreme learning machine (ELM) is used to map the clinical texts to the medical code. Experimental results on clinical texts indicate overall improvement especially for the minority classes.
ER  - 

TY  - JOUR
T1  - Quasi-curvature Local Linear Projection and Extreme Learning Machine for nonlinear dimensionality reduction
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 208
EP  - 217
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Liu, Shenglan
AU  - Wu, Jun
AU  - Feng, Lin
AU  - Luo, Sen
AU  - Yan, Deqin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.05.098
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314066
KW  - Quasi-curvature LLE
KW  - Quasi-curvature Local Linear Projection
KW  - Dimensionality reduction
KW  - Extreme Learning Machine
AB  - Abstract
As one of the classical nonlinear dimensionality reduction algorithms, Locally Linear Embedding (LLE) has shown powerful performance in many research fields. However, there are still two limitations in LLE: (1) traditional LLE is sensitive to high-curvature noise; (2) the computation is too expensive. To solve these problems, we present Quasi-curvature LLE (QLLE) through taking the curvature of local neighborhoods into consideration when mapping local configuration into low-dimensional coordinates. And then a novel learning framework called Quasi-curvature Local Linear Projection (QLLP) is proposed for efficient dimensionality reduction. This framework first selects small landmarks from original data to obtain the low-dimensional coordinates in QLLE, and then adopts Extreme Learning Machine (ELM) to learn the explicit mapping function from original data to low-dimensional coordinates for nonlinear dimensionality reduction. The extensive experiments in synthetic and Frey facial expression datasets demonstrate that this framework can greatly improve the efficiency in nonlinear dimensionality reduction.
ER  - 

TY  - JOUR
T1  - Gaussian derivative models and ensemble extreme learning machine for texture image classification
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 53
EP  - 64
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Song, Yan
AU  - Zhang, Shujing
AU  - He, Bo
AU  - Sha, Qixin
AU  - Shen, Yue
AU  - Yan, Tianhong
AU  - Nian, Rui
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.01.113
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314017
KW  - Gaussian derivative models
KW  - Extreme learning machine
KW  - Ensemble extreme learning machine
KW  - Texture classification
KW  - Gabor filters
AB  - Abstract
In this paper, we propose an innovative classification method which combines texture features of images filtered by Gaussian derivative models with extreme learning machine (ELM). In the texture image classification, feature extraction is a very crucial step. Thusly, we use linear filters consisting of two Gaussian derivative models, difference of Gaussian (DOG) and difference of offset Gaussian (DOOG), to detect texture information of images. Besides, ensemble extreme learning machine (E2LM) is proposed to reduce the randomness of original ELM and used as the classifier in this paper. We evaluate the performance of both the texture features and the classifier E2LM by using three datasets: Brodatz album, VisTex database and Berkeley image segmentation database. Experimental results indicate that Gaussian derivative models are superior to Gabor filters, and E2LM outperforms the support vector machine (SVM) and ELM in classification accuracy.
ER  - 

TY  - JOUR
T1  - Bi-directional extreme learning machine for semi-blind watermarking of compressed images
JO  - Journal of Information Security and Applications
VL  - 38
IS  - 
SP  - 71
EP  - 84
PY  - 2018/2//
T2  - 
AU  - Mishra, Anurag
AU  - Rajpal, Ankit
AU  - Bala, Rajni
SN  - 2214-2126
DO  - https://doi.org/10.1016/j.jisa.2017.11.008
UR  - https://www.sciencedirect.com/science/article/pii/S2214212617303162
KW  - Semi-blind watermarking
KW  - Bi-directional extreme learning machine
KW  - Normalized correlation (NC)
KW  - Peak signal to noise ratio (PSNR)
KW  - SSIM_Index
KW  - Bit error rate (BER)
KW  - Root mean square error (RMSE)
AB  - Abstract
Bi-directional Extreme Learning Machine (B-ELM) is a newly developed single layer feed-forward network capable of fast training with few hidden neurons. It is also reported to show better generalization capability as compared to its old counterpart ELM. In the past, it has never been applied to image processing data-sets and particularly to any of its applications. In this work, B-ELM is successfully used to carry out watermarking of JPEG compressed images by inserting a binary watermark into it. Two invertible activation functions â Sine and Sigmoid are tested in this work. The RMSE is plotted as a function of number of hidden neurons. As observed in case of other applications, this plot indicates that Sigmoid is better placed in comparison to Sine function. The robustness of embedding scheme is examined by applying seven different attacks over signed images. These results prove that the proposed scheme is robust enough against the selected attacks. The computed processing time for embedding and extraction in milliseconds indicates that this scheme is suitable for developing real time watermarking applications for videos.
ER  - 

TY  - JOUR
T1  - Ocean wave height prediction using ensemble of Extreme Learning Machine
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 12
EP  - 20
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Kumar, N. Krishna
AU  - Savitha, R.
AU  - Al Mamun, Abdullah
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.03.092
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217313942
KW  - Wave characteristics
KW  - SLFN
KW  - Extreme Learning Machine
KW  - SVR
KW  - OS-ELM
AB  - Abstract
The intense increase in offshore operational activities warrants periodical and accurate prediction of the wave characteristics. Usually, complex numerical models that require high computational power are used in this prediction. To overcome these challenges of these numerical models, in this paper, we propose the use of an ensemble of Extreme Learning Machine (Ens-ELM) to predict the daily wave height. We exploit the randomness of initialization in ELM to obtain better generalization performance. This is done by constructing an Ensemble of ELM, with the parameters of each ELM initialized in distinct regions of the input space. For each sample in the data set, the output of the ELM with the least mean square for each sample in the data set is reported as its output. We study the performance of the Ens-ELM to predict the daily wave height in 10 stations of varying terrains from Gulf of Mexico, Brazil and Korean region. The Ens-ELM network is trained using the past wave data and the measured atmospheric conditions obtained in these stations between Jan 1, 2011 and Dec 31, 2014 and is tested with data in these stations between Jan 1, 2015 and Aug 30, 2015. In this study, the performance of Ens-ELM is evaluated in comparison with ELM, Online Sequential ELM (OS-ELM), and Support Vector Regression (SVR). From this study, we infer that the Ens-ELM out performs ELM, OS-ELM and SVR in the daily wave height prediction.
ER  - 

TY  - JOUR
T1  - Online extreme learning machine based modeling and optimization for point-by-point engine calibration
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 187
EP  - 197
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Wong, Pak Kin
AU  - Gao, Xiang Hui
AU  - Wong, Ka In
AU  - Vong, Chi Man
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.02.104
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314108
KW  - Engine calibration
KW  - Engine modeling
KW  - Engine optimization
KW  - Initial-training-free online extreme learning machine
AB  - Abstract
An online extreme learning machine (ELM) based modeling and optimization approach for point-by-point engine calibration is proposed to improve the efficiency of conventional model-based calibration approach. Instead of building hundreds of local engine models for every engine operating point, only one ELM model is necessary for the whole process. This ELM model is firstly constructed for a starting operating point, and calibration of this starting point is conducted by determining the optimal parameters of the model. This ELM model is then re-used as a base model for a nearby target operating point, and optimization is performed on the model to search for its best parameters. With a design of experiment strategy on the best parameters obtained, new measurements from the target operating point can be collected and used to update the model. By repeating the optimization and model update procedures, the optimal parameters for the target point can be found after several iterations. By using the model of this target point as the base model for another nearby operating point and repeating the same process again, calibration for all the operating points can be done online efficiently. The contribution of the proposed method is to save the number of experiments in the calibration process. To verify the effectiveness of the proposed approach, experiments on a commercial engine simulation software have been conducted. Three variants of online ELM are utilized in the model update process for comparison. The results show that engine calibration can be carried out with much fewer measurements and time using the proposed approach, and the initial training free online ELM is the most efficient online modeling method for this application.
ER  - 

TY  - JOUR
T1  - Hierarchical extreme learning machines
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 1
EP  - 3
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Huang, Guang-Bin
AU  - Wu, Jonathan
AU  - Wunsch II, Donald C.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.07.067
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217313954
ER  - 

TY  - JOUR
T1  - Extreme Learning Machine for Joint Embedding and Clustering
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 78
EP  - 88
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Liu, Tianchi
AU  - Liyanaarachchi Lekamalage, Chamara Kasun
AU  - Huang, Guang-Bin
AU  - Lin, Zhiping
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.01.115
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314078
KW  - Feature learning
KW  - Embedding
KW  - Clustering
KW  - k-means
KW  - Manifold regularization
KW  - Extreme learning machine
AB  - Abstract
Clustering generic data, i.e., data not specific to a particular field, is a challenging problem due to their diverse complex structures in the original feature space. Traditional approaches address this problem by complementing clustering with feature learning methods, which either capture the intrinsic structure of the data or represent the data such that clusters are better revealed. In this paper, we propose an approach referred to as Extreme Learning Machine for Joint Embedding and Clustering (ELM-JEC), which incorporates desirable properties of both types of feature learning methods at the same time, specifically by (1) preserving the manifold structure of the data in the original space; (2) maximizing the class separability of the data in the embedded space. Since either type of method has improved clustering performance in some cases, our motivation is to integrate the two desirable properties to further improve the accuracy and robustness of clustering. Additional notable features of ELM-JEC are that it provides nonlinear feature mappings and achieves feature learning and clustering in the same formulation. The proposed approach can be implemented using alternating optimization, and its clustering performance compares favorably with several state-of-the-art methods on the real-world benchmark datasets.
ER  - 

TY  - JOUR
T1  - Semi-supervised multi-graph classification using optimal feature selection and extreme learning machine
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 89
EP  - 100
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Pang, Jun
AU  - Gu, Yu
AU  - Xu, Jia
AU  - Yu, Ge
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.01.114
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217314042
KW  - Multi-graph
KW  - Semi-supervised
KW  - Feature selection
KW  - Extreme learning machine
AB  - Abstract
A multi-graph is represented by a bag of graphs. Semi-supervised multi-graph classification is a partly supervised learning problem, which has a wide range of applications, such as bio-pharmaceutical activity tests, scientific publication categorization and online product recommendation. However, to the best of our knowledge, few research works have be reported. In this paper, we propose a semi-supervised multi-graph classification algorithm to handle the semi-supervised multi-graph classification problem. Our algorithm consists of three main steps, including the optimal subgraph feature selection, the subgraph feature representation of multi-graph and the semi-supervised classifier building. We first propose an evaluation criterion of the optimal subgraph features, which not only considers unlabeled multi-graphs but also considers the constraints between the multi-graph level and the graph level. Then, the optimal subgraph feature selection problem is equivalently converted into the problem of mining m most informative subgraph features. Based on those derived m subgraph features, every multi-graph is represented by an m-dimensional vector, where the ith dimension equals to 1 if at least one graph involved in the multi-graph contains the ith subgraph feature. At last, based on these vectors, semi-supervised extreme learning machine(semi-supervised ELM) is adopted to build the prediction model for predicting the labels of unseen multi-graphs. Extensive experiments on real-world and synthetic graph datasets show that the proposed algorithm is effective and efficient.
ER  - 

TY  - JOUR
T1  - A clustering method based on extreme learning machine
JO  - Neurocomputing
VL  - 277
IS  - 
SP  - 108
EP  - 119
PY  - 2018/2/14/
T2  - Hierarchical Extreme Learning Machines
AU  - Huang, Jinhong
AU  - Yu, Zhu Liang
AU  - Gu, Zhenghui
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.02.100
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217313930
KW  - Clustering
KW  - Extreme learning machine
KW  - Alternative direction optimization
KW  - Optimal ELM classifier
AB  - Abstract
Though many successful methods have been proposed for supervised learning tasks, such as support vector machines and extreme learning machines (ELM), it is still an open problem to extend the successful supervised learning methods to unsupervised learning tasks and obtain better results. In this paper, we propose to extend the ELM to an unsupervised learning version and propose a clustering method based on ELM (CM-ELM) for both binary class and multiple class problems, which aims to find a labeling that would yield an optimal ELM classifier. In the ELM feature space, we propose to combine the Gaussian hidden nodes and sigmoid hidden nodes in the hidden layer to combine their advantages. Then we propose to adopt the alternative direction method to solve the non-convex problems in CM-ELM simply. Furthermore, in order to make the results of the non-convex problems robust and satisfactory, we propose to initial the labels with cluster ensemble methods. Experiments on the artificial and benchmark data sets show that the CM-ELM is competitive to the state-of-the-art clustering methods.
ER  - 

TY  - JOUR
T1  - Restricted Boltzmann machine to determine the input weights for extreme learning machines
JO  - Expert Systems with Applications
VL  - 96
IS  - 
SP  - 77
EP  - 85
PY  - 2018/4/15/
T2  - 
AU  - Pacheco, Andre G.C.
AU  - Krohling, Renato A.
AU  - da Silva, Carlos A.S.
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2017.11.054
UR  - https://www.sciencedirect.com/science/article/pii/S0957417417308102
KW  - Neural networks
KW  - Extreme learning machine
KW  - Restricted Boltzmann machine
KW  - Weights initialization
AB  - Abstract
The Extreme Learning Machine (ELM) is a single-hidden layer feedforward neural network (SLFN) learning algorithm that can learn effectively and quickly. The ELM training phase assigns the input weights and bias randomly and does not change them in the whole process. Although the network works well, the random weights in the input layer may affect the algorithm performance. Therefore, we propose a new approach to determine the input weights and bias for the ELM using the restricted Boltzmann machine (RBM), which we call RBM-ELM. We compare our new approach to the well-known ELM-AE and to the ELM-RO, a state of the art algorithm to select the input weights for the ELM. The experimental results show that the RBM-ELM achieves a better performance than the ELM and outperforms the ELM-AE and ELM-RO.
ER  - 

TY  - JOUR
T1  - Data decomposition based fast reduced kernel extreme learning machine for currency exchange rate forecasting and trend analysis
JO  - Expert Systems with Applications
VL  - 96
IS  - 
SP  - 427
EP  - 449
PY  - 2018/4/15/
T2  - 
AU  - Das, P.P.
AU  - Bisoi, R.
AU  - Dash, P.K.
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2017.10.053
UR  - https://www.sciencedirect.com/science/article/pii/S0957417417307352
KW  - Kernel Fast reduced Extreme Learning Machine
KW  - Kernel functions
KW  - Empirical mode decomposition
KW  - Currency exchange rate forecasting
KW  - Trend and Trading analysis
AB  - Abstract
In this paper, we propose a hybrid forecasting model that combines Empirical Mode Decomposition (EMD) with fast reduced kernel Extreme Learning Machine (KELM) for day ahead foreign currency exchange rate forecasting. EMD is an efficient method for nonlinear data decomposition in such a noisy environment and the purpose is to find important components in terms of Intrinsic Mode Functions (IMFs) by which the nonlinear time series is converted into stationary time series by making the data smoother and simpler for analysis. The average IMFs decomposed from EMD (AEMD) are hybridized with fast KELM named as AEMD-KELM for producing a more accurate forecast. The experimental results using AEMD-KELM method for seven currency exchange rates like CAD/HKD, CAD/CNY, CAD/USD, CAD/BRL, CAD/JPY, EUR/USD, and GBP/USD provide superior prediction and trend analysis in comparison with EMD based ELM (EMD-ELM) approaches. Further currency exchange rate movement trends are used for generating trading signals like buy, sell or hold.
ER  - 

TY  - JOUR
T1  - Multi-kernel extreme learning machine for EEG classification in brain-computer interfaces
JO  - Expert Systems with Applications
VL  - 96
IS  - 
SP  - 302
EP  - 310
PY  - 2018/4/15/
T2  - 
AU  - Zhang, Yu
AU  - Wang, Yu
AU  - Zhou, Guoxu
AU  - Jin, Jing
AU  - Wang, Bei
AU  - Wang, Xingyu
AU  - Cichocki, Andrzej
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2017.12.015
UR  - https://www.sciencedirect.com/science/article/pii/S0957417417308291
KW  - Brain-computer interface
KW  - Electroencephalogram
KW  - Extreme learning machine
KW  - Multi-kernel learning
KW  - Motor imagery
AB  - Abstract
One of the most important issues for the development of a motor-imagery based brain-computer interface (BCI) is how to design a powerful classifier with strong generalization capability. Extreme learning machine (ELM) has recently proven to be comparable or more efficient than support vector machine for many pattern recognition problems. In this study, we propose a multi-kernel ELM (MKELM)-based method for motor imagery electroencephalogram (EEG) classification. The kernel extension of ELM provides an elegant way to circumvent calculation of the hidden layer outputs and inherently encode it in a kernel matrix. We investigate effects of two different kernel functions (i.e., Gaussian kernel and polynomial kernel) on the performance of kernel ELM. The MKELM method is subsequently developed by integrating these two types of kernels with a multi-kernel learning strategy, which can effectively explore the supplementary information from multiple nonlinear feature spaces for more robust classification of EEG. An extensive experimental comparison with two public EEG datasets indicates that the MKELM method gives higher classification accuracy than those of the other competing algorithms. The experimental results confirm that superiority of the proposed MKELM-based method for accurate classification of EEG associated with motor imagery in BCI applications. Our method also provides a promising and generalized solution to investigate the complex and nonlinear information for various applications in the fields of expert and intelligent systems.
ER  - 

TY  - JOUR
T1  - Speech emotion recognition based on feature selection and extreme learning machine decision tree
JO  - Neurocomputing
VL  - 273
IS  - 
SP  - 271
EP  - 280
PY  - 2018/1/17/
T2  - 
AU  - Liu, Zhen-Tao
AU  - Wu, Min
AU  - Cao, Wei-Hua
AU  - Mao, Jun-Wei
AU  - Xu, Jian-Ping
AU  - Tan, Guan-Zheng
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.07.050
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217313565
KW  - Speech emotion recognition
KW  - Feature selection
KW  - Correlation analysis
KW  - Decision tree
KW  - Extreme learning machine
AB  - Abstract
Feature selection is a crucial step in the development of a system for identifying emotions in speech. Recently, the interaction between features generated from the same audio source was rarely considered, which may produce redundant features and increase the computational costs. To solve this problem, feature selection method based on correlation analysis and Fisher is proposed, which can remove the redundant features that have close correlations with each other. To improve the recognition performance of the feature subset after proposal feature selection further, an emotion recognition method based on extreme learning machine (ELM) decision tree is proposed according to the confusion degree among different basic emotions. A framework of speech emotion recognition is proposed and the classification experiments based on proposed classification method by using Chinese speech database from institute of automation of Chinese academy of sciences (CASIA) are performed. And the experimental results show that the proposal achieved 89.6% recognition rate on average. By proposal, it would be fast and efficient to discriminate emotional states of different speakers from speech, and it would make it possible to realize the interaction between speaker-independent and computer/robot in the future.
ER  - 

TY  - JOUR
T1  - Intelligent fault diagnosis of rolling bearing using deep wavelet auto-encoder with extreme learning machine
JO  - Knowledge-Based Systems
VL  - 140
IS  - 
SP  - 1
EP  - 14
PY  - 2018/1/15/
T2  - 
AU  - Haidong, Shao
AU  - Hongkai, Jiang
AU  - Xingqiu, Li
AU  - Shuaipeng, Wu
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2017.10.024
UR  - https://www.sciencedirect.com/science/article/pii/S0950705117304938
KW  - Intelligent fault diagnosis
KW  - Rolling bearing
KW  - Deep wavelet auto-encoder
KW  - Extreme learning machine
KW  - Unsupervised feature learning
AB  - Abstract
Unsupervised feature learning from the raw vibration data is a great challenge for rolling bearing intelligent fault diagnosis. In this paper, a novel method called deep wavelet auto-encoder (DWAE) with extreme learning machine (ELM) is proposed for intelligent fault diagnosis of rolling bearing. Firstly, wavelet function is employed as the nonlinear activation function to design wavelet auto-encoder (WAE), which can effectively capture the signal characteristics. Secondly, a DWAE is constructed with multiple WAEs to enhance the unsupervised feature learning ability. Finally, ELM is adopted as the classifier to accurately identify different bearing faults. The proposed method is applied to analyze the experimental bearing vibration signals, and the results confirm that the proposed method is superior to the traditional methods and standard deep learning methods.
ER  - 

TY  - JOUR
T1  - Ensemble of Extreme Learning Machines with trained classifier combination and statistical features for hyperspectral data
JO  - Neurocomputing
VL  - 271
IS  - 
SP  - 28
EP  - 37
PY  - 2018/1/3/
T2  - 
AU  - Ksieniewicz, PaweÅ
AU  - Krawczyk, Bartosz
AU  - WoÅºniak, MichaÅ
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.04.076
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217312195
KW  - Ensemble learning
KW  - Extreme Learning Machines
KW  - Hyperspectral imaging
KW  - Computer vision
KW  - Feature extraction
KW  - Dimensionality reduction
KW  - Image classification
AB  - Abstract
Remote sensing and hyperspectral data analysis are areas offering wide range of valuable practical applications. However, they generate massive and complex data that is very difficult to be analyzed by a human being. Therefore, methods for efficient data representation and data mining are of high interest to these fields. In this paper, we introduce a novel pipeline for feature extraction and classification of hyperspectral images. To obtain a compressed representation we propose to extract a set of statistical-based properties from these images. This allows for embedding feature space into fourteen channels, obtaining a significant dimensionality reduction. These features are used as an input for the ensemble learning based on randomized neural networks. We introduce a novel method for forming ensembles of Extreme Learning Machines based on randomized feature subspaces and a trained combiner. It is based on continuous outputs and uses a perceptron-based learning scheme to calculate weights assigned to each classifier and class independently. Extensive experiments carried on a number of benchmarks images prove that using proposed feature extraction and extreme learning ensemble leads to a significant gain in classification accuracy.
ER  - 

TY  - JOUR
T1  - Predicting compressive strength of lightweight foamed concrete using extreme learning machine model
JO  - Advances in Engineering Software
VL  - 115
IS  - 
SP  - 112
EP  - 125
PY  - 2018/1//
T2  - 
AU  - Yaseen, Zaher Mundher
AU  - Deo, Ravinesh C.
AU  - Hilal, Ameer
AU  - Abd, Abbas M.
AU  - Bueno, Laura Cornejo
AU  - Salcedo-Sanz, Sancho
AU  - Nehdi, Moncef L.
SN  - 0965-9978
DO  - https://doi.org/10.1016/j.advengsoft.2017.09.004
UR  - https://www.sciencedirect.com/science/article/pii/S0965997817304441
KW  - Foamed concrete
KW  - Compressive strength
KW  - Prediction
KW  - ELM
KW  - MARS
KW  - M5 Tree
KW  - SVR
AB  - Abstract
In this research, a machine learning model namely extreme learning machine (ELM) is proposed to predict the compressive strength of foamed concrete. The potential of the ELM model is validated in comparison with multivariate adaptive regression spline (MARS), M5 Tree models and support vector regression (SVR). The Lightweight foamed concrete is produced via creating a cellular structure in a cementitious matrix during the mixing process, and is widely used in heat insulation, sound attenuation, roofing, tunneling and geotechnical applications. Achieving product consistency and accurate predictability of its performance is key to the success of this technology. In the present study, an experimental database encompassing pertinent data retrieved from several previous studies has been created and utilized to train and validate the ELM, MARS, M5 Tree and SVR machine learning models. The input parameters for the predictive models include the cement content, oven dry density, water-to-binder ratio and foamed volume. The predictive accuracy of the four models has been assessed via several statistical score indicators. The results showed that the proposed ELM model achieved an adequate level of prediction accuracy, improving MARS, M5 Tree and SVR models. Hence, the ELM model could be employed as a reliable and accurate data intelligent approach for predicting the compressive strength of foamed concrete, saving laborious trial batches required to attain the desired product quality.
ER  - 

TY  - JOUR
T1  - Distributing extreme learning machines with Apache Spark for NetFlow-based malware activity detection
JO  - Pattern Recognition Letters
VL  - 101
IS  - 
SP  - 14
EP  - 20
PY  - 2018/1/1/
T2  - 
AU  - Kozik, RafaÅ
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2017.11.004
UR  - https://www.sciencedirect.com/science/article/pii/S0167865517304099
KW  - Netflow
KW  - Extreme learning machines
KW  - Apache Spark
AB  - Abstract
The Netflow protocol is often used for network auditing, analysis, and monitoring. However, it also can be successfully used as a reliable source of information for incidents detection and forensic purposes. In this paper, the method that combines NetFlows with Extreme Learning Machines (ELM) classifier trained in a distributed environment of Apache Spark framework is proposed. The main contribution of this research is an algorithm that leverages Map-Reduce programming model to scale and distribute a training process of an ELM classifier for a NetFlow-based malware activities detection. Results reported on a benchmark dataset show that the proposed ELM-based NetFlow analysis can be considered as a reliable tool for a network incidents detection.
ER  - 

TY  - JOUR
T1  - An online semi-supervised P300 speller based on extreme learning machine
JO  - Neurocomputing
VL  - 269
IS  - 
SP  - 148
EP  - 151
PY  - 2017/12/20/
T2  - 
AU  - Wang, Junjie
AU  - Gu, Zhenghui
AU  - Yu, Zhuliang
AU  - Li, Yuanqing
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.12.098
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217309955
KW  - Brainâcomputer interface
KW  - Semi-supervised learning
KW  - Extreme learning machine
AB  - Abstract
Semi-supervised learning has been applied in brainâcomputer interfaces (BCIs) to reduce calibration time for user. For example, a sequential updated self-training least squares support vector machine (SUST-LSSVM) was devised for online semi-supervised P300 speller. Despite its good performance, the computational complexity becomes too high after several updates, which hinders its practical online application. In this paper, we present a self-training regularized weighted online sequential extreme learning machine (ST-RWOS-ELM) for P300 speller. It achieves much lower complexity compared to SUST-LSSVM without affecting the spelling accuracy performance. The experimental results validate its effectiveness in the P300 system.
ER  - 

TY  - JOUR
T1  - Extreme learning machine based transfer learning algorithms: A survey
JO  - Neurocomputing
VL  - 267
IS  - 
SP  - 516
EP  - 524
PY  - 2017/12/6/
T2  - 
AU  - Salaken, Syed Moshfeq
AU  - Khosravi, Abbas
AU  - Nguyen, Thanh
AU  - Nahavandi, Saeid
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.06.037
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217311657
KW  - Transfer learning
KW  - Extreme learning machine
AB  - Abstract
Extreme learning machine (ELM) has been increasingly popular in the field of transfer learning (TL) due to its simplicity, training speed and ease of use in online sequential learning process. This paper critically examines transfer learning algorithms formulated with ELM technique and provides state of the art knowledge to expedite the learning process ELM based TL algorithms. As this article discusses available ELM based TL algorithm in detail, it provides a holistic overview of current literature, serves as a starting point for new researchers in ELM based TL algorithms and facilitates identification of future research direction in concise manner.
ER  - 

TY  - JOUR
T1  - Toward an optimal kernel extreme learning machine using a chaotic moth-flame optimization strategy with applications in medical diagnoses
JO  - Neurocomputing
VL  - 267
IS  - 
SP  - 69
EP  - 84
PY  - 2017/12/6/
T2  - 
AU  - Wang, Mingjing
AU  - Chen, Huiling
AU  - Yang, Bo
AU  - Zhao, Xuehua
AU  - Hu, Lufeng
AU  - Cai, ZhenNao
AU  - Huang, Hui
AU  - Tong, Changfei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.04.060
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217308305
KW  - Kernel extreme learning machine
KW  - Parameter optimization
KW  - Feature selection
KW  - Improved moth-flame optimization
KW  - Medical diagnosis
AB  - Abstract
This study proposes a novel learning scheme for the kernel extreme learning machine (KELM) based on the chaotic moth-flame optimization (CMFO) strategy. In the proposed scheme, CMFO simultaneously performs parameter optimization and feature selection. The proposed methodology is rigorously compared to several other competitive KELM models that are based on the original moth-flame optimization, particle swarm optimization, and genetic algorithms. The comparison is made using the medical diagnosis problems of Parkinson's disease and breast cancer. And the proposed method has successfully been applied to practical medical diagnosis cases. The experimental results demonstrate that, compared to the alternative methods, the proposed method offers significantly better classification performance and also obtains a smaller feature subset. Promisingly, the proposed CMFOFS-KELM, can serve as an effective and efficient computer aided tool for medical diagnosis in the field of medical decision making.
ER  - 

TY  - JOUR
T1  - Unmanned Aerial System (UAS)-based phenotyping of soybean using multi-sensor data fusion and extreme learning machine
JO  - ISPRS Journal of Photogrammetry and Remote Sensing
VL  - 134
IS  - 
SP  - 43
EP  - 58
PY  - 2017/12//
T2  - 
AU  - Maimaitijiang, Maitiniyazi
AU  - Ghulam, Abduwasit
AU  - Sidike, Paheding
AU  - Hartling, Sean
AU  - Maimaitiyiming, Matthew
AU  - Peterson, Kyle
AU  - Shavers, Ethan
AU  - Fishman, Jack
AU  - Peterson, Jim
AU  - Kadam, Suhas
AU  - Burken, Joel
AU  - Fritschi, Felix
SN  - 0924-2716
DO  - https://doi.org/10.1016/j.isprsjprs.2017.10.011
UR  - https://www.sciencedirect.com/science/article/pii/S0924271617303246
KW  - Remote sensing
KW  - Unmanned Aerial System (UAS)
KW  - Phenotyping
KW  - Data Fusion
KW  - Extreme Learning Machine (ELM)
KW  - Extreme Learning Machine based Regression (ELR)
AB  - Abstract
Estimating crop biophysical and biochemical parameters with high accuracy at low-cost is imperative for high-throughput phenotyping in precision agriculture. Although fusion of data from multiple sensors is a common application in remote sensing, less is known on the contribution of low-cost RGB, multispectral and thermal sensors to rapid crop phenotyping. This is due to the fact that (1) simultaneous collection of multi-sensor data using satellites are rare and (2) multi-sensor data collected during a single flight have not been accessible until recent developments in Unmanned Aerial Systems (UASs) and UAS-friendly sensors that allow efficient information fusion. The objective of this study was to evaluate the power of high spatial resolution RGB, multispectral and thermal data fusion to estimate soybean (Glycine max) biochemical parameters including chlorophyll content and nitrogen concentration, and biophysical parameters including Leaf Area Index (LAI), above ground fresh and dry biomass. Multiple low-cost sensors integrated on UASs were used to collect RGB, multispectral, and thermal images throughout the growing season at a site established near Columbia, Missouri, USA. From these images, vegetation indices were extracted, a Crop Surface Model (CSM) was advanced, and a model to extract the vegetation fraction was developed. Then, spectral indices/features were combined to model and predict crop biophysical and biochemical parameters using Partial Least Squares Regression (PLSR), Support Vector Regression (SVR), and Extreme Learning Machine based Regression (ELR) techniques. Results showed that: (1) For biochemical variable estimation, multispectral and thermal data fusion provided the best estimate for nitrogen concentration and chlorophyll (Chl) a content (RMSE of 9.9% and 17.1%, respectively) and RGB color information based indices and multispectral data fusion exhibited the largest RMSE 22.6%; the highest accuracy for Chl a + b content estimation was obtained by fusion of information from all three sensors with an RMSE of 11.6%. (2) Among the plant biophysical variables, LAI was best predicted by RGB and thermal data fusion while multispectral and thermal data fusion was found to be best for biomass estimation. (3) For estimation of the above mentioned plant traits of soybean from multi-sensor data fusion, ELR yields promising results compared to PLSR and SVR in this study. This research indicates that fusion of low-cost multiple sensor data within a machine learning framework can provide relatively accurate estimation of plant traits and provide valuable insight for high spatial precision in agriculture and plant stress assessment.
ER  - 

TY  - JOUR
T1  - Tensor Decomposition Based Approach for Training Extreme Learning Machines
JO  - Big Data Research
VL  - 10
IS  - 
SP  - 8
EP  - 20
PY  - 2017/12//
T2  - 
AU  - Nair, Nikhitha K.
AU  - Asharaf, S.
SN  - 2214-5796
DO  - https://doi.org/10.1016/j.bdr.2017.07.002
UR  - https://www.sciencedirect.com/science/article/pii/S2214579616302258
KW  - ELM
KW  - TENSOR
KW  - PARAFAC
KW  - TUCKER
KW  - ALS
KW  - HOSVD
AB  - Abstract
Conventional Extreme Learning Machines utilize MooreâPenrose generalized pseudo-inverse to solve hidden layer activation matrix and perform analytical determination of output weights. Scalability is the major concern to be addressed in Extreme Learning Machines while dealing with large dataset. Motivated by these scalability concerns, this paper proposes a novel tensor decomposition based Extreme Learning Machine which utilize PARAFAC and TUCKER decomposition based techniques in a SPARK platform. This proposed Extreme Learning Machine achieve reduced training time and better accuracy when compared with a conventional Extreme Learning Machine.
ER  - 

TY  - JOUR
T1  - Orthogonal extreme learning machine for image classification
JO  - Neurocomputing
VL  - 266
IS  - 
SP  - 458
EP  - 464
PY  - 2017/11/29/
T2  - 
AU  - Peng, Yong
AU  - Kong, Wanzeng
AU  - Yang, Bing
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.05.058
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217309219
KW  - Extreme learning machine
KW  - Orthogonal constraint
KW  - Orthogonal procrustes problem
KW  - Image classification
AB  - Abstract
Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks in which the parameters of hidden units are randomly generated and thus the output weights can be analytically calculated. From the hidden to output layer, ELM essentially learns the output weight matrix based on the least squares regression formula that can be used for both classification/regression and dimensionality reduction. In this paper, we impose the orthogonal constraint on the output weight matrix and then formulate an orthogonal extreme learning machine (OELM) model, which produces orthogonal basis functions and can have more locality preserving power from ELM feature space to output layer than ELM. Since the locality preserving ability is potentially related to the discriminating power, the OELM is expect to have more discriminating power than ELM. Considering the case that the number of hidden units is usually greater than the number of classes, we propose an effective method to optimize the OELM objective by solving an orthogonal procrustes problem. Experiments by pairwisely comparing OELM with ELM on three widely used image data sets show the effectiveness of learning orthogonal mapping especially when given only limited training samples.
ER  - 

TY  - JOUR
T1  - Extreme learning machines for credit scoring: An empirical evaluation
JO  - Expert Systems with Applications
VL  - 86
IS  - 
SP  - 42
EP  - 53
PY  - 2017/11/15/
T2  - 
AU  - BequÃ©, Artem
AU  - Lessmann, Stefan
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2017.05.050
UR  - https://www.sciencedirect.com/science/article/pii/S0957417417303718
KW  - Credit scoring
KW  - Artificial neural networks
KW  - Extreme learning machines
KW  - Classifier ensembles
AB  - Abstract
Classification algorithms are used in many domains to extract information from data, predict the entry probability of events of interest, and, eventually, support decision making. This paper explores the potential of extreme learning machines (ELM), a recently proposed type of artificial neural network, for consumer credit risk management. ELM possess some interesting properties, which might enable them to improve the quality of model-based decision support. To test this, we empirically compare ELM to established scoring techniques according to three performance criteria: ease of use, resource consumption, and predictive accuracy. The mathematical roots of ELM suggest that they are especially suitable as a base model within ensemble classifiers. Therefore, to obtain a holistic picture of their potential, we assess ELM in isolation and in conjunction with different ensemble frameworks. The empirical results confirm the conceptual advantages of ELM and indicate that they are a valuable alternative to other credit risk modelling methods.
ER  - 

TY  - JOUR
T1  - Microcalcification diagnosis in digital mammography using extreme learning machine based on hidden Markov tree model of dual-tree complex wavelet transform
JO  - Expert Systems with Applications
VL  - 86
IS  - 
SP  - 135
EP  - 144
PY  - 2017/11/15/
T2  - 
AU  - Hu, Kai
AU  - Yang, Wei
AU  - Gao, Xieping
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2017.05.062
UR  - https://www.sciencedirect.com/science/article/pii/S0957417417303901
KW  - Microcalcification diagnosis
KW  - Digital mammography
KW  - Dual-tree complex wavelet transform
KW  - Hidden Markov tree model
KW  - Extreme learning machine
KW  - Feature extraction
AB  - Abstract
Diagnosis of benign and malignant microcalcifications in digital mammography using Computer-aided Diagnosis (CAD) system is critical for the early diagnosis of breast cancer. Wavelet transform based diagnosis methods are effective to accomplish this task, but limited by representing the correlation within each wavelet scale, these methods neglect the correlation between wavelet scales. In this paper, we apply the hidden Markov tree model of dual-tree complex wavelet transform (DTCWT-HMT) for microcalcification diagnosis in digital mammography. DTCWT-HMT can effectively capture the correlation between different wavelet coefficients and model the statistical dependencies and non-Gaussian statistics of real signals, is used to characterize microcalcifications for the diagnosis of benign and malignant cases. The combined features which consist of the DTCWT-HMT features and the DTCWT features are optimized by genetic algorithm (GA). Extreme learning machine (ELM), an efficient learning theory is employed as the classifier to diagnose the benign and malignant microcalcifications. The validity of the proposed method is evaluated on the Nijmegen, MIAS and DDSM datasets using area under curve (AUC) of receiver operating characteristic (ROC). The AUC values of 0.9856, 0.9941 and 0.9168 of the proposed method are achieved on Nijmegen, MIAS and DDSM, respectively. We compare the proposed method with state-of-the-art diagnosis methods, and the experimental results show the effectiveness of the proposed method for the diagnosis of the benign and malignant microcalcifications in mammograms in terms of the accuracy and stability.
ER  - 

TY  - JOUR
T1  - Blind quality estimator for 3D images based on binocular combination and extreme learning machine
JO  - Pattern Recognition
VL  - 71
IS  - 
SP  - 207
EP  - 217
PY  - 2017/11//
T2  - 
AU  - Zhou, Wujie
AU  - Yu, Lu
AU  - Zhou, Yang
AU  - Qiu, Weiwei
AU  - Wu, Ming-Wei
AU  - Luo, Ting
SN  - 0031-3203
DO  - https://doi.org/10.1016/j.patcog.2017.06.008
UR  - https://www.sciencedirect.com/science/article/pii/S0031320317302315
KW  - 3D image quality assessment
KW  - Binocular combination
KW  - Extreme learning machine
KW  - Local pattern
AB  - Abstract
Over recent years, blind quality estimators for three-dimensional (3D) images have received increasing attention. In this paper, we describe a blind quality estimator for 3D images based on binocular combination and an extreme learning machine (ELM) for more accurate alignment with subjective human experience. First, two binocular combinations of stimuli are generated using different combination strategies. Various binocular quality-aware features of these combinations are then extracted by local binary pattern operators, which give an effective description of the degradation pattern. Finally, these features are mapped to the subjective quality score of the distorted 3D image using an ELM. Experimental results using three benchmark databases confirm that the proposed metric is effective and achieves competitive prediction performance when compared with most current full reference and blind metrics.
ER  - 

TY  - JOUR
T1  - Sparse coding extreme learning machine for classification
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 50
EP  - 56
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Yu, Yuanlong
AU  - Sun, Zhenzhen
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.06.078
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302072
KW  - Sparse coding
KW  - Extreme learning machine
KW  - Gradient projection
AB  - Abstract
As one of supervised learning algorithms, extreme learning machine (ELM) has been proposed for training single-hidden-layer feedforward neural networks and shown great generalization performance. ELM randomly assigns the weights and biases between input and hidden layers and only learns the weights between hidden and output layers. Physiological research has shown that neurons at the same layer are laterally inhibited to each other such that outputs of each layer are sparse. However, it is difficult for ELM to accommodate the lateral inhibition by directly using random feature mapping. Therefore, this paper proposes a sparse coding ELM (ScELM) algorithm, which can map the input feature vector into a sparse representation. In this proposed ScELM algorithm, an unsupervised way is used for sparse coding and dictionary is randomly assigned rather than learned. Gradient projection based method is used for the sparse coding. The output weights are trained through the same supervised way as ELM. Experimental results on the benchmark datasets have shown that this proposed ScELM algorithm can outperform other state-of-the-art methods in terms of classification accuracy.
ER  - 

TY  - JOUR
T1  - Optimization extreme learning machine with Î½ regularization
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 11
EP  - 19
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Xiao-jian, Ding
AU  - Yuan, Lan
AU  - Zhi-feng, Zhang
AU  - xin, Xu
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.05.114
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217301996
KW  - Î½-optimization extreme learning machine
KW  - Classification
KW  - Parameter selection
AB  - Abstract
The problem of choosing error penalty parameter C for optimization extreme learning machine (OELM) is that it can take any positive value for different applications and it is therefore hard to choose correctly. In this paper, we reformulated OELM to take a new regularization parameter Î½ (Î½-OELM) which is inspired by SchÃ¶lkopf et al. The regularization in terms of Î½ is bounded between 0 and 1, and is easier to interpret as compared to C. This paper shows that: (1) Î½-OELM and Î½-SVM have similar dual optimization formulation, but Î½-OELM has less optimization constraints due to its special capability of class separation and (2) experiment results on both artificial and real binary classification problems show that Î½-OELM tends to achieve better generalization performance than Î½-SVM, OELM and other popular machine learning approaches, and it is computationally efficient on high dimension data sets. Additionally, the optimal parameter Î½ in Î½-OELM can be easily selected from few candidates.
ER  - 

TY  - JOUR
T1  - Online sequential prediction of imbalance data with two-stage hybrid strategy by extreme learning machine
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 94
EP  - 105
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Mao, Wentao
AU  - Wang, Jinwan
AU  - He, Ling
AU  - Tian, Yangyang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.05.111
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217301637
KW  - Extreme learning machine
KW  - Imbalance problem
KW  - Principal curve
KW  - Leave-one-out cross-validation
KW  - Online sequential learning
AB  - Abstract
In many practical engineering applications, data tend to be collected in online sequential way with imbalanced class. Many traditional machine learning methods such as support vector machine and so on generally get biased classifier which leads to lower classification precision for minor class than major class. To get fast and efficient classification, a new online sequential extreme learning machine method with two-stage hybrid strategy is proposed. In offline stage, data-based strategy is employed, and the principal curve is introduced to model the distribution of minority class data. In online stage, algorithm-based strategy is employed, and a new leave-one-out cross-validation method using ShermanâMorrison matrix inversion lemma is proposed to tackle online imbalance data, meanwhile, with add-delete mechanism for updating network weights. And the rationality of this strategy is proved theoretically. The proposed method is evaluated on four UCI datasets and the real-world Macau air pollutant forecasting dataset. The experimental results show that, the proposed method outperforms the classical ELM, OS-ELM and meta-cognitive OS-ELM in terms of generalization performance and numerical stability.
ER  - 

TY  - JOUR
T1  - Graph classification based on sparse graph feature selection and extreme learning machine
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 20
EP  - 27
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Yu, Yajun
AU  - Pan, Zhisong
AU  - Hu, Guyu
AU  - Ren, Huifeng
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.03.110
UR  - https://www.sciencedirect.com/science/article/pii/S092523121730200X
KW  - Graph kernel
KW  - Graph classification
KW  - Extreme learning machine
KW  - Lasso
AB  - Abstract
Identification and classification of graph data is a hot research issue in pattern recognition. The conventional methods of graph classification usually convert the graph data to the vector representation and then using SVM to be a classifier. These methods ignore the sparsity of graph data, and with the increase of the input sample, the storage and computation of the kernel matrix will cost a lot of memory and time. In this paper, we propose a new graph classification algorithm called graph classification based on sparse graph feature selection and extreme learning machine. The key of our method is using the lasso to select features because of the sparsity of graph data, and extreme learning machine (ELM) is introduced to the following classification task due to its good performance. Extensive experimental results on a series of benchmark graph data sets validate the effectiveness of the proposed methods.
ER  - 

TY  - JOUR
T1  - Multi-label text categorization using L21-norm minimization extreme learning machine
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 4
EP  - 10
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Jiang, Mingchu
AU  - Pan, Zhisong
AU  - Li, Na
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.04.069
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302011
KW  - Text categorization
KW  - Multi-label learning
KW  - Extreme learning machine
KW  - L21-norm minimization
AB  - Abstract
Extreme learning machine (ELM) is extended from the generalized single hidden layer feedforward networks where the input weights of the hidden layer nodes can be assigned randomly. It has been widely used for its much faster learning speed and less manual works. Considering the field of multi-label text classification, in this paper, we propose an ELM based algorithm combined with L21-norm minimization of the output weights matrix called L21-norm Minimization ELM, which not only fully inherits the merits of ELM but also facilitates group sparsity and reduces complexity of the learning model. Extensive experiments on several benchmark data sets show that our proposed algorithm can obtain superior performances compared with other common multi-label classification algorithms.
ER  - 

TY  - JOUR
T1  - On the construction of extreme learning machine for online and offline one-class classificationâAn expanded toolbox
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 126
EP  - 143
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Gautam, Chandan
AU  - Tiwari, Aruna
AU  - Leng, Qian
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.04.070
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302096
KW  - One-class classification (OCC)
KW  - Extreme learning machine (ELM)
KW  - Online sequential ELM (OSELM)
KW  - One-class ELM (OCELM)
KW  - Autoassociative ELM (AAELM)
AB  - Abstract
One-class classification (OCC) has been prime concern for researchers and effectively employed in various disciplines. But, traditional methods based one-class classifiers are very time consuming due to its iterative process and various parameters tuning. In this paper, we present six OCC methods and their thirteen variants based on extreme learning machine (ELM) and online sequential ELM (OSELM). Our proposed classifiers mainly lie in two categories: reconstruction based and boundary based, where three proposed classifiers belong to reconstruction based and three belong to boundary based. We are presenting both types of learning viz., online and offline learning for OCC. Out of six methods, four are offline and remaining two are online methods. Out of four offline methods, two methods perform random feature mapping and two methods perform kernel feature mapping. We present a comprehensive discussion on these methods and their comparison to each other. Kernel feature mapping based approaches have been tested with RBF kernel and online version of one-class classifiers is tested with both types of nodes viz., additive and RBF. It is well known fact that threshold decision is a crucial factor in case of OCC, so, three different threshold deciding criteria have been employed so far and analyze the effectiveness of one threshold deciding criteria over another. Further, these methods are tested on two artificial datasets to check their boundary construction capability and on eight benchmark datasets from different discipline to evaluate the performance of the classifiers. Our proposed classifiers exhibit better performance compared to ten traditional one-class classifiers and ELM based two one-class classifiers. Through proposed one-class classifiers, we intend to expand the functionality of the most used toolbox for OCC i.e. DD toolbox. All of our methods are totally compatible with all the present features of the toolbox.
ER  - 

TY  - JOUR
T1  - Extreme Learning Machine for large-scale graph classification based on MapReduce
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 106
EP  - 114
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Wang, Zhanghui
AU  - Zhao, Yuhai
AU  - Yuan, Ye
AU  - Wang, Guoren
AU  - Chen, Lei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.04.071
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302163
KW  - Discriminative subgraph pattern
KW  - MapReduce
KW  - Extreme Learning Machine
KW  - Graph classification
AB  - Abstract
Discriminative subgraph mining from a large collection of graph objects is a crucial problem for graph classification. Several main memory-based approaches have been proposed to mine discriminative subgraphs, but they always lack scalability and are not suitable for large-scale graph databases. Extreme Learning Machine (ELM) is a simple and efficient Single-hidden Layer Feedforward neural Networks (SLFNs) algorithm with extremely fast learning capacity. In this paper, we propose a discriminative subgraph mining approach based on ELM-Filter strategy within the scalable MapReduce computing model. We randomly partition the collection of graphs among worker nodes, and each worker applies a fast pattern evolutionary method to mine a set of discriminative subgraphs with the help of ELM-Filter strategy in its partition. And, the set of discriminative subgraphs must produce higher ELM training accuracy. The union of all such discriminative subgraphs is the mining result for the input large-scale graphs. Also, based on the proposed Support Graph Vector Model (SGVM) and ELM algorithm, we construct the graph classification model using the mined discriminative subgraphs. Extensive experimental results on both real and synthetic datasets show that our method obviously outperforms the other approaches in terms of both classification accuracy and runtime efficiency.
ER  - 

TY  - JOUR
T1  - The selection of input weights of extreme learning machine: A sample structure preserving point of view
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 28
EP  - 36
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Wang, Wenhui
AU  - Liu, Xueyi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.06.079
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302114
KW  - Monte Carlo sampling
KW  - Quasi-Monte Carlo sequence
KW  - Extreme learning machine
KW  - Distance preserving
KW  - Generalization performance
KW  - Orthogonal projection
AB  - Abstract
The random assignment strategy for input weights has brought extreme learning machine (ELM) many advantages such as fast learning speed, minimal manual intervention and so on. However, the Monte Carlo (MC) based random sampling method that is typically used to generate input weights of ELM has poor capability of sample structure preserving (SSP), which will degenerate the learning and generalization performance. For this reason, the Quasi-Monte Carlo (QMC) method is revisited and it is shown that the distortion error of QMC projection can obtain faster convergence rate than that of MC for relatively low-dimensional problems. Further, a unified random orthogonal (RO) projection method is proposed, and it is shown that such RO method can always provide the optimal transformation in terms of minimizing the loss of all the distances between samples. Experimental results on real-world benchmark data sets verify the rationality of theoretical analysis and indicate that by enhancing the SSP capability of input weights, QMC and RO projection methods tend to bring ELM algorithms better generalization performance.
ER  - 

TY  - JOUR
T1  - Advances in extreme learning machines (ELM2015)
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 1
EP  - 3
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Lendasse, Amaury
AU  - Vong, Chi Man
AU  - Toh, Kar-Ann
AU  - Miche, Yoan
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.01.089
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217303132
ER  - 

TY  - JOUR
T1  - Learning with similarity functions: A novel design for the extreme learning machine
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 37
EP  - 49
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Gastaldo, P.
AU  - Bisio, F.
AU  - Gianoglio, C.
AU  - Ragusa, E.
AU  - Zunino, R.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.05.116
UR  - https://www.sciencedirect.com/science/article/pii/S092523121730214X
KW  - Extreme learning machine
KW  - Similarity functions
KW  - Single-layer feedforward neural networks
AB  - Abstract
The paper addresses the role of randomization in the training process of a learning machine, and analyses the affinities between two well-known schemes, namely, Extreme Learning Machines (ELMs) and the learning framework using similarity functions. These paradigms share a common approach to inductive learning, which combines an explicit remapping of data with a linear separator; however, they seem to exploit different strategies in the design of the mapping layer. The paper shows that, in fact, the theory of learning with similarity functions can stimulate a novel interpretation of the ELM paradigm, thus leading to a common framework. New insights into the ELM model are obtained, and the ELM strategy for the setup of the neuronsâ parameters can be significantly improved. Experimental results confirm that the novel method improves over conventional approaches, especially in the trade-off between classification accuracy and machine complexity (i.e., the dimensionality of the remapped space). This, in turn, supports the reliability of the unified framework envisioned in this paper.
ER  - 

TY  - JOUR
T1  - A variable-structure online sequential extreme learning machine for time-varying system prediction
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 115
EP  - 125
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Yin, Jian-Chuan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.03.114
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302175
KW  - Online sequential extreme learning machine
KW  - Time-varying system
KW  - Pruning strategy
KW  - Tidal prediction
KW  - Real-time prediction
AB  - Abstract
A variable-structure online sequential extreme learning machine (OS-ELM) is proposed by incorporating a hidden units pruning strategy. As conventional OS-ELM increases network dimensionality by adding newly-received samples as hidden units, the hidden layer dimension would expand and result in âdimensionality curseâ finally. Furthermore, the vast number of hidden units cannot represent time-varying dynamics adaptively and would deteriorate the network generalization capability. Therefore, there is a practical need to adjust the dimension of OS-ELM not only by adding hidden units but also by simultaneously pruning superfluous units which contribute less to the output. To evaluate the individual contribution of existing hidden units, an index is proposed referred to as normalized error reduction ratio. The variable structure OS-ELM adds newly received samples in hidden units, and prunes those units contribute less to current dynamics from network simultaneously, thus the resulted network possesses parsimonious structure which can represent current system dynamics more efficiently. The online network structure adjustment approach can handle samples which are presented one-by-one or chuck-by-chuck. The variable-structure OS-ELM (VS-OSELM) can be implemented for online identification and prediction of time-varying systems. In this study, to evaluate the efficiency of VS-OSELM, it was implemented for real-time prediction of tidal level change which is a complex time-varying process. Online tidal prediction simulations is conducted based on the real measured tidal and meteorological data of Old Port Tampa in Florida, United States. Simulation results demonstrate that the proposed variable-structure OS-ELM is suitable for identification and prediction of complex time-varying systems with high prediction accuracy and fast computation speed.
ER  - 

TY  - JOUR
T1  - Parallel multi-graph classification using extreme learning machine and MapReduce
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 171
EP  - 183
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Pang, Jun
AU  - Gu, Yu
AU  - Xu, Jia
AU  - Kong, Xiaowang
AU  - Yu, Ge
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.03.111
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302035
KW  - Multi-graph
KW  - Classification
KW  - Extreme learning machine
KW  - MapReduce
AB  - Abstract
A multi-graph is represented by a bag of graphs and modeled as a generalization of a multi-instance. Multi-graph classification is a supervised learning problem, which has a wide range of applications, such as scientific publication categorization, bio-pharmaceutical activity tests and online product recommendation. However, existing algorithms are limited to process small datasets due to high computation complexity of multi-graph classification. Specially, the precision is not high enough for a large dataset. In this paper, we propose a scalable and high-precision parallel algorithm to handle the multi-graph classification problem on massive datasets using MapReduce and extreme learning machine. Extensive experiments on real-world and synthetic graph datasets show that the proposed algorithm is effective and efficient.
ER  - 

TY  - JOUR
T1  - Dynamic adjustment of hidden layer structure for convex incremental extreme learning machine
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 83
EP  - 93
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Sun, Yongjiao
AU  - Chen, Yuangen
AU  - Yuan, Ye
AU  - Wang, Guoren
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.07.072
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217301984
KW  - Extreme learning machine
KW  - Dynamic adjustment
KW  - Feed-forward neural network
KW  - Convex optimal increment
AB  - Abstract
Extreme Learning Machine (ELM) is a learning algorithm based on generalized single-hidden-layer feed-forward neural network. Since ELM has an excellent performance on regression and classification problems, it has been paid more and more attention recently. The determination of structure of ELM plays a vital role in ELM applications. Essentially, determination of the structure of ELM is equivalent to the determination of the hidden layer structure. Utilizing a smaller scale of the hidden layer structure can promote faster running speed. In this paper, we propose algorithm PCI-ELM (Pruned-Convex Incremental Extreme Learning Machine) based on CI-ELM (Convex Incremental Extreme Learning Machine). Furthermore, we also present an improved PCI-ELM algorithm, EPCI-ELM (Enhanced Pruned-Convex Incremental Extreme Learning Machine), which introduces a filtering strategy for PCI-ELM during the neurons adding process. In order to adjust the single-hidden-layer feed-forward neural network more flexibly and achieve the most compact form of the hidden layer structure, in this paper, we propose an algorithm which can dynamically determine hidden layer structure, DCI-ELM (Dynamic Convex Incremental Extreme Learning Machine). At the end of this paper, we verify the performance of PCI-ELM, EPCI-ELM and DCI-ELM. The results show that PCI-ELM, EPCI-ELM and DCI-ELM control hidden layer structure very well and construct the more compact single-hidden-layer feed-forward neural network.
ER  - 

TY  - JOUR
T1  - Extreme learning machine based mutual information estimation with application to time-series change-points detection
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 204
EP  - 216
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Oh, Beom-Seok
AU  - Sun, Lei
AU  - Ahn, Chung Soo
AU  - Yeo, Yong Kiang
AU  - Yang, Yan
AU  - Liu, Nan
AU  - Lin, Zhiping
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.11.138
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302187
KW  - Density ratio approximation
KW  - Squared-loss mutual information estimation
KW  - Extreme learning machine
KW  - Change-points detection
KW  - Electrocardiogram
KW  - Driving stress
AB  - Abstract
In this paper, we propose an efficient parameter tuning-free squared-loss mutual information (SMI) estimator in a form of a radial basis function (RBF) network. The input layer of the proposed network propagates a sample pair of two random variables to the hidden layer. The propagated samples are then transformed by a set of Gaussian RBF kernels with randomly determined kernel centers and widths similar to that in an extreme learning machine. The output layer adopts a linear weighting scheme which can be analytically estimated. Our empirical results show that the proposed estimator outperforms the competing state-of-the-art SMI estimators in terms of computational efficiency while showing the comparable estimation accuracy performance. Moreover, the proposed model achieves promising results in an application study of time-series change-points detection and driving stress.
ER  - 

TY  - JOUR
T1  - Heterogeneous blocked CPU-GPU accelerate scheme for large scale extreme learning machine
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 153
EP  - 163
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Li, Shijie
AU  - Niu, Xin
AU  - Dou, Yong
AU  - Lv, Qi
AU  - Wang, Yueqing
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.05.112
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217301959
KW  - ELM-LRF
KW  - GPU
KW  - Blocked CPU-GPU accelerate algorithm
AB  - Abstract
Extreme learning machine (ELM) has been intensively studied during the last decade due to its high efficiency, effectiveness and easy to implement. Recently, a variant of ELM named local receptive fields based ELM (ELM-LRF) has been proposed to reduce the global connections and introduce local receptive fields to the input layer. However, an ELM-LRF model with large number of hidden neurons spend plenty of time on solving large scale Moore-Penrose Matrix Inversion (MPMI) problem which has heavy computational cost and needs much more runtime memory. Moreover, this procedure can not be directly accelerated by GPU platforms due to the limited memory of GPU devices. In this paper, we propose three efficient approaches to perform ELM-LRF on GPU platform. First we propose a novel blocked LU decomposition algorithm, which overcomes the limitation of global memory size so that any size of ELM-LRF models can be trained. Furthermore, an efficient blocked Cholesky decomposition algorithm is presented to accelerate blocked LU decomposition algorithm according to matrix characteristics in the ELM-LRF model. Finally we present a heterogeneous blocked CPU-GPU parallel algorithm to fully exploit resources on a GPU node such as to accelerate blocked Cholesky decomposition algorithm furthermore in the ELM-LRF model.
ER  - 

TY  - JOUR
T1  - Class-specific cost regulation extreme learning machine for imbalanced classification
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 70
EP  - 82
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Xiao, Wendong
AU  - Zhang, Jie
AU  - Li, Yanjiao
AU  - Zhang, Sen
AU  - Yang, Weidong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.09.120
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302199
KW  - Extreme learning machine
KW  - Imbalanced data distribution
KW  - Class-specific cost regulation extreme learning machine
KW  - Blast furnace status diagnosis
AB  - Abstract
Due to its much faster speed and better generalization performance, extreme learning machine (ELM) has attracted much attention as an effective learning approach. However, ELM rarely involves strategies for imbalanced data distributions which may exist in many fields. Existing approaches for imbalance learning only consider the effect of the number of the class samples ignoring the dispersion degree of the data, and may lead to the suboptimal learning results. In this paper, we will propose a novel ELM, class-specific cost regulation extreme learning machine (CCR-ELM), together with its kernel based extension, for binary and multiclass classification problems with imbalanced data distributions. CCR-ELM introduces class-specific regulation cost for misclassification of each class in the performance index as the tradeoff of structural risk and empirical risk. The performance of CCR-ELM is verified using a number of benchmark datasets and the real blast furnace status diagnosis problem. Experimental results show that CCR-ELM can achieve better performance for classification problems with imbalanced data distributions than the original ELM and existing ELM imbalance learning approach, and the kernel based CCR-ELM can improve the performance further.
ER  - 

TY  - JOUR
T1  - Distributed extreme learning machine with alternating direction method of multiplier
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 164
EP  - 170
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Luo, Minnan
AU  - Zhang, Lingling
AU  - Liu, Jun
AU  - Guo, Jun
AU  - Zheng, Qinghua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.03.112
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302047
KW  - Extreme learning machine
KW  - Neuron work
KW  - Alternating direction method of multiplier
AB  - Abstract
Extreme learning machine, as a generalized single-hidden-layer feedforward network, has achieved much attention for its extremely fast learning speed and good generalization performance. However, big data often makes a challenge in large scale learning of extreme learning machine due to the memory limitation of single machine as well as the distributed manner of large scale data in many applications. For the purpose of relieving the limitation of memory with big data, in this paper, we exploit a novel distributed model to implement the extreme learning machine algorithm in parallel for large-scale data set, namely distributed extreme learning machine (DELM). A corresponding algorithm is developed on the basis of alternating direction method of multipliers which has shown its effectiveness in distributed convex optimization. Finally, extensive experiments on some benchmark data sets are carried out to illustrate the effectiveness and superiority of the proposed DELM method with an analysis on the performance of speedup, scaleup and sizeup.
ER  - 

TY  - JOUR
T1  - Discriminative extreme learning machine with supervised sparsity preserving for image classification
JO  - Neurocomputing
VL  - 261
IS  - 
SP  - 242
EP  - 252
PY  - 2017/10/25/
T2  - Advances in Extreme Learning Machines (ELM 2015)Selected papers from the International Conference on Extreme Learning Machines (ELM 2015)
AU  - Peng, Yong
AU  - Lu, Bao-Liang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.05.113
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217301972
KW  - Extreme learning machine
KW  - Sparse representation
KW  - Group sparsity
KW  - Sparsity preserving
KW  - Image classification
AB  - Abstract
In order to seek non-propagation method to train generalized single-hidden layer feed forward neural networks, extreme learning machine was proposed, which has been proven to be an effective and efficient model for both multi-class classification and regression. Different from most of existing studies which consider extreme learning machine as a classifier, we make improvements on it to let it become a feature extraction model in this paper. Specifically, a discriminative extreme learning machine with supervised sparsity preserving (SPELM) model is proposed. From the hidden layer to output layer, SPELM performs as a subspace learning method by considering the discriminative as well as sparsity information of data. The sparsity information of data is identified by solving a supervised sparse representation objective. Experiments are conducted on four widely used image benchmark data sets and the classification results demonstrate the effectiveness of the proposed SPELM model.
ER  - 

TY  - JOUR
T1  - Twin extreme learning machines for pattern classification
JO  - Neurocomputing
VL  - 260
IS  - 
SP  - 235
EP  - 244
PY  - 2017/10/18/
T2  - 
AU  - Wan, Yihe
AU  - Song, Shiji
AU  - Huang, Gao
AU  - Li, Shuang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.04.036
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217307312
KW  - Twin extreme learning machine
KW  - Pattern classification
KW  - Extreme learning machine
KW  - Twin support vector machine
KW  - Nonparallel separating hyperplane
AB  - Abstract
Extreme learning machine (ELM) is an efficient and effective learning algorithm for pattern classification. For binary classification problem, traditional ELM learns only one hyperplane to separate different classes in the feature space. In this paper, we propose a novel twin extreme learning machine (TELM) to simultaneously train two ELMs with two nonparallel classification hyperplanes. Specifically, TELM first utilizes the random feature mapping mechanism to construct the feature space, and then two nonparallel separating hyperplanes are learned for the final classification. For each hyperplane, TELM jointly minimizes its distance to one class and requires it to be far away from the other class. TELM incorporates the idea of twin support vector machine (TSVM) into the basic framework of ELM, thus TELM could have the advantages of the both algorithms. Moreover, compared to TSVM, TELM has fewer optimization constraint variables but with better classification performance. We also introduce a successive over-relaxation technique to speed up the training of our algorithm. Comprehensive experimental results on a large number of datasets verify the effectiveness and efficiency of TELM.
ER  - 

TY  - JOUR
T1  - A multi-label classification algorithm based on kernel extreme learning machine
JO  - Neurocomputing
VL  - 260
IS  - 
SP  - 313
EP  - 320
PY  - 2017/10/18/
T2  - 
AU  - Luo, Fangfang
AU  - Guo, Wenzhong
AU  - Yu, Yuanlong
AU  - Chen, Guolong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.04.052
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217308068
KW  - Multi-label learning
KW  - Extreme learning machine
KW  - Kernel extreme learning machine
KW  - Threshold selection
AB  - Abstract
Multi-label classification learning provides a multi-dimensional perspective for polysemic object, and becomes a new research hotspot in machine learning in recent years. In the big data environment, it is urgent to obtain a fast and efficient multi-label classification algorithm. Kernel extreme learning machine was applied to multi-label classification problem (ML-KELM) in this paper, so the iterative learning operations can be avoided. Meanwhile, a dynamic, self-adaptive threshold function was designed to solve the transformation from ML-KELM networkâs real-value outputs to binary multi-label vector. ML-KELM has the least square optimal solution of ELM, and less parameters that needs adjustment, stable running, faster convergence speed and better generalization performance. Extensive multi-label classification experiments were conducted on data sets of different scale. Comparison results show that ML-KELM outperformance in large scale dataset with high dimension instance feature.
ER  - 

TY  - JOUR
T1  - Dual-layer kernel extreme learning machine for action recognition
JO  - Neurocomputing
VL  - 260
IS  - 
SP  - 123
EP  - 130
PY  - 2017/10/18/
T2  - 
AU  - Nguyen, Tam V.
AU  - Mirza, Bilal
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.04.007
UR  - https://www.sciencedirect.com/science/article/pii/S092523121730677X
KW  - Action recognition
KW  - Extreme learning machine
KW  - Dual-layer kernel learning
AB  - Abstract
In this paper, we propose a simple yet effective method for video based action recognition referred to as dual-layer kernel extreme learning machine (DKELM). Our approach takes advantages of both early and late fusion techniques into a unified framework. In particular, the first layer in DKELM adopts linear kernel extreme learning machine (KELM) on handcrafted feature kernel, deep-learned feature kernel, and the fused kernel to provide various perspectives about the video. The second layer trains a radial basis function based KELM classifier on different fusion scores obtained from the first layer to predict the final action class label. Finally, we empirically show the superior performance of DKELM, both in terms of accuracy and computational time, over some state-of-the-art human action recognition methods on two large-scale datasets.
ER  - 

TY  - JOUR
T1  - Random forests-based extreme learning machine ensemble for multi-regime time series prediction
JO  - Expert Systems with Applications
VL  - 83
IS  - 
SP  - 164
EP  - 176
PY  - 2017/10/15/
T2  - 
AU  - Lin, Lin
AU  - Wang, Fang
AU  - Xie, Xiaolong
AU  - Zhong, Shisheng
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2017.04.013
UR  - https://www.sciencedirect.com/science/article/pii/S0957417417302488
KW  - Extreme learning machine
KW  - Random forests
KW  - Ensemble learning
KW  - Multi-regime time series
KW  - Time series prediction
AB  - Abstract
Accurate and timely predicting values of performance parameters are currently strongly needed for important complex equipment in engineering. In time series prediction, two problems are urgent to be solved. One problem is how to achieve the accuracy, stability and efficiency together, and the other is how to handle time series with multiple regimes. To solve these two problems, random forests-based extreme learning machine ensemble model and a novel multi-regime approach are proposed respectively, and these two approaches can be integrated to achieve better performance. First, the extreme learning machine (ELM) is used in the proposed model because of its efficiency. Then the regularized ELM and ensemble learning strategy are used to improve generalization performance and prediction accuracy. The bootstrap sampling technique is used to generate training sample sets for multiple base-level ELM models, and then the random forests (RF) model is used as the combiner to aggregate these ELM models to achieve more accurate and stable performance. Next, based on the specific properties of turbofan engine time series, a multi-regime approach is proposed to handle it. Regimes are first separated, then the proposed RF-based ELM ensemble model is used to learn models of all regimes, individually, and last, all the learned regime models are aggregated to predict performance parameter at the future timestamp. The proposed RF-based ELM ensemble model and multi-regime approaches are evaluated by using NN3 time series and NASA turbofan engine time series, and then the proposed model is applied to the exhaust gas temperature prediction of CFM engine. The results demonstrate that the proposed RF-based ELM ensemble model and multi-regime approach can be accurate, stable and efficient in predicting multi-regime time series, and it can be robust against overfitting.
ER  - 

TY  - JOUR
T1  - Incremental laplacian regularization extreme learning machine for online learning
JO  - Applied Soft Computing
VL  - 59
IS  - 
SP  - 546
EP  - 555
PY  - 2017/10//
T2  - 
AU  - Yang, Lixia
AU  - Yang, Shuyuan
AU  - Li, Sujing
AU  - Liu, Zhi
AU  - Jiao, Licheng
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2017.05.051
UR  - https://www.sciencedirect.com/science/article/pii/S1568494617303290
KW  - Extreme learning machine
KW  - Graph laplacian
KW  - Incremental laplacian regularization
KW  - Semi-supervised incremental/online learning
AB  - Abstract
The past decade has witnessed an explosive growth of data streams in Internet, biometrics, remote sensing and other fields. Nowadays many supervised incremental/online learning approaches have been developed, to avoid retraining and reduce the computational complexity when data come chunk by chunk. However, these methods canât obtain satisfied performance when the labeled samples are limited. In this paper, we propose an Incremental Laplacian Regularization Extreme Learning Machine (ILR-ELM) for semi-supervised online learning, by utilizing both labeled and unlabeled samples. Unlike most of the existing semi-supervised incremental/online learning algorithms, this paper not only proposes incremental/online learning mechanism for data chunk containing both labeled and unlabeled samples but also proposes incremental/online learning mechanism for data chunk containing only unlabeled samples. The latter case is more common in practical applications because there is usually no enough time to label the samples for continuously arriving data stream. The alternative analytical solutions of ILR-ELM for the two incremental/online learning mechanisms are also presented. The performance of ILR-ELM is evaluated on three benchmark machine learning data, and the results show that it can achieve near accurate and robust classification/regression with a small number of labeled data, and outperforms the incremental/online learning approaches. Compared with the supervised and the comparative semi-supervised incremental/online learning methods, the generalization accuracy of ILR-ELM is increased by nearly 9% and 2% respectively for the classification problem. For the regression problem, the generalization error of ILR-ELM is reduced by nearly 14% than the supervised incremental/online learning methods and 1% than compared semi-supervised incremental/online learning methods Furthermore, ILR-ELM can achieve comparable prediction to semi-supervised batch learning, using less time and Random Access Memory (RAM).
ER  - 

TY  - JOUR
T1  - An adaptive kernel-based weighted extreme learning machine approach for effective detection of Parkinsonâs disease
JO  - Biomedical Signal Processing and Control
VL  - 38
IS  - 
SP  - 400
EP  - 410
PY  - 2017/9//
T2  - 
AU  - Wang, Yang
AU  - Wang, An-Na
AU  - Ai, Qing
AU  - Sun, Hai-Jing
SN  - 1746-8094
DO  - https://doi.org/10.1016/j.bspc.2017.06.015
UR  - https://www.sciencedirect.com/science/article/pii/S1746809417301271
KW  - Parkinsonâs disease
KW  - Imbalanced data
KW  - Extreme learning machine
KW  - Artificial bee colony
KW  - Feature selection
AB  - Abstract
Imbalanced data appear in many real-world applications, from biomedical application to network intrusion or fraud detection, etc. Existing methods for Parkinsonâs disease (PD) diagnosis are usually more concerned with overall accuracy (ACC), but ignore the classification performance of the minority class. To alleviate the bias against performance caused by imbalanced data, in this paper, an effective method named AABC-KWELM has been proposed for PD detection. First, based on a fast classifier extreme learning machine (ELM), weighted strategy is used for dealing with imbalanced data and non-linear mapping of kernel function is used for improving the extent of linear separation. Furthermore, both binary version and continuous version of an adaptive artificial bee colony (AABC) algorithm are used for performing feature selection and parameters optimization, respectively. Finally, PD data set is used for evaluating rigorously the effectiveness of the proposed method in accordance with specificity, sensitivity, ACC, G-mean and F-measure. Experimental results demonstrate that the proposed AABC-KWELM remarkably outperforms other approaches in the literature and obtains better classification performance via 5-fold cross-validation (CV), with specificity of 100%, sensitivity of 98.62%, ACC of 98.97%, G-mean of 99.30%, and F-measure of 99.30%.
ER  - 

TY  - JOUR
T1  - Cascaded re-ranking modelling of translation hypotheses using extreme learning machines
JO  - Applied Soft Computing
VL  - 58
IS  - 
SP  - 681
EP  - 689
PY  - 2017/9//
T2  - 
AU  - Vong, Chi Man
AU  - Liu, Yan
AU  - Cao, Jiuwen
AU  - Yin, Chun
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2017.05.002
UR  - https://www.sciencedirect.com/science/article/pii/S1568494617302533
KW  - cascaded re-ranking modelling
KW  - Extreme learning machine
KW  - Statistical machine translation
AB  - Abstract
In statistical machine translation (SMT), re-ranking of huge amount of randomly generated translation hypotheses is one of the essential components in determining the quality of translation result. In this work, a novel re-ranking modelling framework called cascaded re-ranking modelling (CRM) is proposed by cascading a classification model and a regression model. The proposed CRM effectively and efficiently selects the good but rare hypotheses in order to alleviate simultaneously the issues of translation quality and computational cost. CRM can be partnered with any classifier such as support vector machines (SVM) and extreme learning machine (ELM). Compared to other state-of-the-art methods, experimental results show that CRM partnered with ELM (CRM-ELM) can raise at most 11.6% of translation quality over the popular benchmark ChineseâEnglish corpus (IWSLT 2014) and FrenchâEnglish parallel corpus (WMT 2015) with extremely fast training time for huge corpus.
ER  - 

TY  - JOUR
T1  - Kernel fusion based extreme learning machine for cross-location activity recognition
JO  - Information Fusion
VL  - 37
IS  - 
SP  - 1
EP  - 9
PY  - 2017/9//
T2  - 
AU  - Wang, Zhelong
AU  - Wu, Donghui
AU  - Gravina, Raffaele
AU  - Fortino, Giancarlo
AU  - Jiang, Yongmei
AU  - Tang, Kai
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2017.01.004
UR  - https://www.sciencedirect.com/science/article/pii/S1566253517300088
KW  - Human activity recognition
KW  - Extreme learning machine
KW  - Inertial sensors
KW  - Mixed kernel
KW  - Machine learning
AB  - Abstract
Fixed placements of inertial sensors have been utilized by previous human activity recognition algorithms to train the classifier. However, the distribution of sensor data is seriously affected by the sensor placement. The performance will be degraded when the model trained on one placement is used in others. In order to tackle this problem, a fast and robust human activity recognition model called TransM-RKELM (Transfer learning mixed and reduced kernel Extreme Learning Machine) is proposed in this paper; It uses a kernel fusion method to reduce the influence by the choice of kernel function and the reduced kernel is utilized to reduce the computational cost. After realizing initial activity recognition model by mixed and reduced kernel extreme learning model (M-RKELM), in the online phase M-RKELM is utilized to classify the activity and adapt the model to new locations based on high confident recognition results in real time. Experimental results show that the proposed model can adapt the classifier to new sensor locations quickly and obtain good recognition performance.
ER  - 

TY  - JOUR
T1  - Optimizing area under the ROC curve via extreme learning machines
JO  - Knowledge-Based Systems
VL  - 130
IS  - 
SP  - 74
EP  - 89
PY  - 2017/8/15/
T2  - 
AU  - Yang, Zhiyong
AU  - Zhang, Taohong
AU  - Lu, Jingcheng
AU  - Zhang, Dezheng
AU  - Kalui, Dorothy
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2017.05.013
UR  - https://www.sciencedirect.com/science/article/pii/S0950705117302241
KW  - Extreme learning machine (ELM)
KW  - Area under the ROC curve (AUC)
KW  - Imbalanced datasets
KW  - Multi-class AUC optimization
AB  - Abstract
Recently, Extreme learning machine (ELM), an efficient training algorithm for single-hidden-layer feedforward neural networks (SLFN), has gained increasing popularity in machine learning communities. In this paper the ELM based Area Under the ROC Curve (AUC) optimization algorithms are studied so as to further improve the performance of ELM for imbalanced datasets. For binary class problems, a novel ELM algorithm is proposed based on an efficient least square method. For multi-class problems, the following works are done in this paper: First of all, theoretical comparison analysis is proposed for the potential multi-class extensions of AUC; Secondly, a unified objective function for multi-class AUC optimization is proposed following the theoretical analysis; Subsequently, two ELM based multi-class AUC optimization algorithms called E L M M A U C and E L M m a c r o A U C respectively are proposed followed with complexity analyses; Finally, the generalization analysis is established for E L M M A U C in search of theoretical supports. Empirical study on a variety of real-world datasets show the effectiveness of our proposed algorithms.
ER  - 

TY  - JOUR
T1  - Verification and predicting temperature and humidity in a solar greenhouse based on convex bidirectional extreme learning machine algorithm
JO  - Neurocomputing
VL  - 249
IS  - 
SP  - 72
EP  - 85
PY  - 2017/8/2/
T2  - 
AU  - Zou, Weidong
AU  - Yao, Fenxi
AU  - Zhang, Baihai
AU  - He, Chaoxing
AU  - Guan, Zixiao
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.03.023
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217305180
KW  - Solar greenhouse
KW  - Support vector machine
KW  - Radial basis function
KW  - Convex bidirectional extreme learning machine
AB  - Abstract
Predictions regarding the solar greenhouse temperature and humidity are important because they play a critical role in greenhouse cultivation. On account of this, it is important to set up a predictive model of temperature and humidity that would precisely predict the temperature and humidity, reducing potential financial losses. This paper presents a novel temperature and humidity prediction model based on convex bidirectional extreme learning machine (CB-ELM). Simulation results show that the convergence rate of the bidirectional extreme learning machine (B-ELM) can further be improved while retaining the same simplicity, by simply recalculating the output weights of the existing nodes based on a convex optimization method when a new hidden node is randomly added. The performance of the CB-ELM model is compared with other modeling approaches by applying it to predict solar greenhouse temperature and humidity. The experiment results show that the CB-ELM model predictions are more accurate than those of the B-ELM, Back Propagation Neural Network (BPNN), Support Vector Machine (SVM), and Radial Basis Function (RBF). Therefore, it can be considered as a suitable and effective method for predicting the solar greenhouse temperature and humidity.
ER  - 

TY  - JOUR
T1  - Ultrasound-based differentiation of malignant and benign thyroid Nodules: An extreme learning machine approach
JO  - Computer Methods and Programs in Biomedicine
VL  - 147
IS  - 
SP  - 37
EP  - 49
PY  - 2017/8//
T2  - 
AU  - Xia, Jianfu
AU  - Chen, Huiling
AU  - Li, Qiang
AU  - Zhou, Minda
AU  - Chen, Limin
AU  - Cai, Zhennao
AU  - Fang, Yang
AU  - Zhou, Hong
SN  - 0169-2607
DO  - https://doi.org/10.1016/j.cmpb.2017.06.005
UR  - https://www.sciencedirect.com/science/article/pii/S0169260716310422
KW  - Extreme learning machine
KW  - Feature selection
KW  - Medical diagnosis
KW  - Thyroid cancer
KW  - Sonographic features
AB  - AbstractBackground and objectives
It is important to be able to accurately distinguish between benign and malignant thyroid nodules in order to make appropriate clinical decisions. The purpose of this study was to improve the effectiveness and efficiency for discriminating the malignant from benign thyroid cancers based on the Ultrasonography (US) features.
Methods
There were 114 benign nodules in 106 patients (82 women and 24 men) and 89 malignant nodules in 81 patients (69 women and 12 men) included in this study. The potential of extreme learning machine (ELM) has been explored for the first time to discriminate malignant and benign thyroid nodules based on the sonographic features in ultrasound images. The influence of two key parameters (the number of hidden neurons and type of activation function) on the performance of ELM was investigated. The relationship between feature subsets obtained by the feature selection method and the classification performance of ELM was also examined. A real-life dataset was used to evaluate the effectiveness of the proposed method in terms of classification accuracy, sensitivity, specificity, and area under the ROC (receiver operating characteristic) curve (AUC).
Results
The results demonstrate that there are significant differences between the malignant and benign thyroid nodules (p-value&lt;0.01), the most discriminative features are echogenicity, calcification, margin, composition and shape. Compared with other methods, the proposed method not only has achieved very promising classification accuracy via 10-fold cross-validation (CV) scheme, but also greatly reduced the computational cost compared to other counterparts. The proposed ELM-based approach achieves 87.72% ACC, 0.8672 AUC, 78.89% sensitivity, and 94.55% specificity.
Conclusions
Based on the empirical analysis, the proposed ELM-based approach for thyroid cancer detection has promising potential in clinical use, and it can be of assistance as an optional tool for the clinicians.
ER  - 

TY  - JOUR
T1  - The novel use of an Extreme learning machines for clinical decision support systems
JO  - Computer Methods and Programs in Biomedicine
VL  - 147
IS  - 
SP  - A1
EP  - 
PY  - 2017/8//
T2  - 
AU  - Syed-Abdul, Shabbir
AU  - Iqbal, Usman
AU  - (Jack) Li, Yu-Chuan
SN  - 0169-2607
DO  - https://doi.org/10.1016/S0169-2607(17)30895-7
UR  - https://www.sciencedirect.com/science/article/pii/S0169260717308957
ER  - 

TY  - JOUR
T1  - Grey wolf optimization evolving kernel extreme learning machine: Application to bankruptcy prediction
JO  - Engineering Applications of Artificial Intelligence
VL  - 63
IS  - 
SP  - 54
EP  - 68
PY  - 2017/8//
T2  - 
AU  - Wang, Mingjing
AU  - Chen, Huiling
AU  - Li, Huaizhong
AU  - Cai, Zhennao
AU  - Zhao, Xuehua
AU  - Tong, Changfei
AU  - Li, Jun
AU  - Xu, Xin
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2017.05.003
UR  - https://www.sciencedirect.com/science/article/pii/S095219761730088X
KW  - Kernel extreme learning machine
KW  - Parameter tuning
KW  - Grey wolf optimization
KW  - Bankruptcy prediction
AB  - Abstract
This study proposes a new kernel extreme learning machine (KELM) parameter tuning strategy using a novel swarm intelligence algorithm called grey wolf optimization (GWO). GWO, which simulates the social hierarchy and hunting behavior of grey wolves in nature, is adopted to construct an effective KELM model for bankruptcy prediction. The derived model GWO-KELM is rigorously compared with three competitive KELM methods, which are typical in a comprehensive set of methods including particle swarm optimization-based KELM, genetic algorithm-based KELM, grid-search technique-based KELM, extreme learning machine, improved extreme learning machine, support vector machines and random forest, on two real-life datasets via 10-fold cross validation analysis. Results obtained clearly confirm the superiority of the developed model in terms of classification accuracy (training, validation, test), Type I error, Type II error, area under the receiver operating characteristic curve (AUC) criterion as well as computational time. Therefore, the proposed GWO-KELM prediction model is promising to serve as a powerful early warning tool with excellent performance for bankruptcy prediction.
ER  - 

TY  - JOUR
T1  - Instance cloned extreme learning machine
JO  - Pattern Recognition
VL  - 68
IS  - 
SP  - 52
EP  - 65
PY  - 2017/8//
T2  - 
AU  - Zhang, Yongshan
AU  - Wu, Jia
AU  - Zhou, Chuan
AU  - Cai, Zhihua
SN  - 0031-3203
DO  - https://doi.org/10.1016/j.patcog.2017.02.036
UR  - https://www.sciencedirect.com/science/article/pii/S0031320317300997
KW  - Extreme Learning Machine
KW  - Instance cloning
KW  - Local learning
KW  - Classification
AB  - Abstract
Extreme Learning Machine (ELM) is a popular machine learning method which can flexibly simulate the relationships of real-world classification applications. When facing problems (i.e., data sets) with a smaller number of samples (i.e., instances), ELM may often result in the overfitting trouble. In this paper, we propose a new Instance Cloned Extreme Learning Machine (IC-ELM for short) which can handle numerous different classification problems. IC-ELM uses an instance cloning method to balance the input dataâs distribution and extend the training data set, which alleviates the overfitting issue and enhances the testing classification accuracy. Experiments and comparisons on 20 UCI data sets, and validations on image and text classification applications, demonstrate that IC-ELM is able to achieve superior results compared to the original ELM algorithm and its variants, as well as several other classical machine learning algorithms.
ER  - 

TY  - JOUR
T1  - Recursive least mean -power Extreme Learning Machine
JO  - Neural Networks
VL  - 91
IS  - 
SP  - 22
EP  - 33
PY  - 2017/7//
T2  - 
AU  - Yang, Jing
AU  - Ye, Feng
AU  - Rong, Hai-Jun
AU  - Chen, Badong
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2017.04.001
UR  - https://www.sciencedirect.com/science/article/pii/S0893608017300813
KW  - Recursive least mean   p  -power
KW  - Extreme learning machine
KW  - Online sequential learning
KW  - Non-Gaussian noises
KW  - Alpha-stable noises
AB  - Abstract
As real industrial processes have measurement samples with noises of different statistical characteristics and obtain the sample one by one usually, on-line sequential learning algorithms which can achieve better learning performance for systems with noises of various statistics are necessary. This paper proposes a new online Extreme Learning Machine (ELM, of Huang et al.) algorithm, namely recursive least mean p -power ELM (RLMP-ELM). In RLMP-ELM, a novel error criterion for cost function, namely the least mean p -power (LMP) error criterion, provides a mechanism to update the output weights sequentially. The LMP error criterion aims to minimize the mean p -power of the error that is the generalization of the mean square error criterion used in the ELM. The proposed on-line learning algorithm is able to provide on-line predictions of variables with noises of different statistics and obtains better performance than ELM and online sequential ELM (OS-ELM) while the non-Gaussian noises impact the processes. Simulations are reported to demonstrate the performance and effectiveness of the proposed methods.
ER  - 

TY  - JOUR
T1  - Fast object detection in pastoral landscapes using a Colour Feature Extreme Learning Machine
JO  - Computers and Electronics in Agriculture
VL  - 139
IS  - 
SP  - 204
EP  - 212
PY  - 2017/6/15/
T2  - 
AU  - Sadgrove, Edmund J.
AU  - Falzon, Greg
AU  - Miron, David
AU  - Lamb, David
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2017.05.017
UR  - https://www.sciencedirect.com/science/article/pii/S0168169916310638
KW  - Extreme learning machine
KW  - Object detection
KW  - Colour image
KW  - Weed detection
KW  - Stock monitoring
KW  - Vehicle detection
AB  - Abstract
Object detection is an essential function of robotics based agricultural systems and many algorithms exist for this purpose. Colour although an important characteristic is often avoided in place of faster grey-scale implementations or is only used in an rudimentary arrangement. This study presents the Colour Feature Extreme Learning Machine (CF-ELM), which is an implementation of the extreme learning machine (ELM), with a partially connected hidden layer and a fully connected output layer, taking three colour inputs instead of the standard grey-scale input. The CF-ELM was tested with three different colour systems including HSV, RGB and YâUV and compared for time and accuracy against the standard grey-scale ELM. The four implementations were tested on three different datasets including weed detection, vehicle detection and stock detection. It was found that the colour implementation performed better overall for all three datasets and the YâUV was best performing colour system on all tested datasets. With the YâUV delivering the highest accuracy in weed detection at 84%, 96% in vehicle detection and 86% in stock detection. Along side the CF-ELM, an algorithm is introduced for desktop based classification of objects within a pastoral landscape, with individual speeds between 0.06 s and 0.18 s for a single image, tested within each colour space. The algorithm is designed for use in a scenario that provides difficult and unpredictable terrain, making it ideal for use in an agricultural or pastoral landscape.
ER  - 

TY  - JOUR
T1  - GramâSchmidt process based incremental extreme learning machine
JO  - Neurocomputing
VL  - 241
IS  - 
SP  - 1
EP  - 17
PY  - 2017/6/7/
T2  - 
AU  - Zhao, Yong-Ping
AU  - Li, Zhi-Qiang
AU  - Xi, Peng-Peng
AU  - Liang, Dong
AU  - Sun, Liguo
AU  - Chen, Ting-Hao
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.01.049
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217301236
KW  - Extreme learning machine
KW  - Incremental learning
KW  - QR decomposition
KW  - GramâSchmidt process
AB  - Abstract
To compact the architecture of extreme learning machine (ELM), two incremental learning algorithms are proposed in this paper. The previous incremental learning algorithms for ELM recruit hidden nodes randomly, which is equivalent to implementing a random selection from a candidate set of infinite size. Hence, it is impossible to recruit good hidden nodes, and thus it usually requires more hidden nodes than traditional neural networks to achieve matched performance. To improve the quality of the hidden nodes recruited, an incremental learning algorithm for ELM is presented based on Gram--Schmidt process (GSI-ELM), which recruits the best hidden node from a random subset of fixed size via defining an evaluating criterion at each learning step. However, the ânesting effectâ exists in the GSI-ELM, that is to say, the hidden nodes once recruited by GSI-ELM can not be later discarded. To treat this ânesting problemâ, the improved GSI-ELM (IGSI-ELM) is generated with an elimination mechanism. At each learning step IGSI-ELM eliminates the worst hidden node from the already-recruited group if it is not the newly-recruited one. Finally, to verify the efficacy and feasibility of the proposed algorithms, i.e. GSI-ELM and IGSI-ELM, in this paper, experiments on regression and classification benchmark data sets are investigated.
ER  - 

TY  - JOUR
T1  - A new Self-Organizing Extreme Learning Machine soft sensor model and its applications in complicated chemical processes
JO  - Engineering Applications of Artificial Intelligence
VL  - 62
IS  - 
SP  - 38
EP  - 50
PY  - 2017/6//
T2  - 
AU  - Geng, Zhiqiang
AU  - Dong, Jungen
AU  - Chen, Jie
AU  - Han, Yongming
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2017.03.011
UR  - https://www.sciencedirect.com/science/article/pii/S0952197617300635
KW  - Self-Organizing
KW  - Extreme Learning Machine
KW  - Mutual Information
KW  - Hebbian learning rule
KW  - Soft sensor
KW  - Complicated chemical processes
AB  - Abstract
The control of product quality of complex chemical processes strictly depends on the measure of the key process variables. However, the online measure device is extremely expensive, and these devices are hard to protect. Meanwhile, there is a delay for these online measure devices. Therefore, the soft sensor technology plays a vital role in measuring the key process variables. Extreme Learning Machine (ELM) is an efficient and simple single layer feed-forward neural networks (SLFNs) to building an exact soft sensor model. However, unsuitable selected hidden nodes and random parameters will greatly affect the performance of the ELM. Therefore, this paper proposes a novel Self-Organizing Extreme Learning Machine (SOELM) algorithm constructed by the biological neuron-glia interaction principle to solve the issue of the ELM. Firstly, the weights between input layer nodes and the CNS are tuned iteratively by the Hebbian learning rule. Then the network structure is adjusted self-organizing by Mutual Information (MI) among different structures of networks. Secondly, the weights between the CNS and output layer nodes are obtained by the ELM. The experimental results based on different UCI data sets prove that the SOELM has a better generalization capability and stability than that of the ELM. Moreover, our proposed method is developed as a soft sensor model for accurately predicting the key variables of the Purified Terephthalic Acid (PTA) process.
ER  - 

TY  - JOUR
T1  - A switching delayed PSO optimized extreme learning machine for short-term load forecasting
JO  - Neurocomputing
VL  - 240
IS  - 
SP  - 175
EP  - 182
PY  - 2017/5/31/
T2  - 
AU  - Zeng, Nianyin
AU  - Zhang, Hong
AU  - Liu, Weibo
AU  - Liang, Jinling
AU  - Alsaadi, Fuad E.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.01.090
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217303144
KW  - Short-term load forecasting
KW  - Extreme learning machine
KW  - Switching delayed particle swarm optimization (SDPSO)
KW  - Neural network
KW  - Time-delay
AB  - Abstract
In this paper, a hybrid learning approach, which combines the extreme learning machine (ELM) with a new switching delayed PSO (SDPSO) algorithm, is proposed for the problem of the short-term load forecasting (STLF). In particular, the input weights and biases of ELM are optimized by a new developed SDPSO algorithm, where the delayed information of locally best particle and globally best particle are exploited to update the velocity of particle. By testing the proposed SDPSO-ELM in a comprehensive manner on a tanh function, this approach obtain better generalization performance and can also avoid adding unnecessary hidden nodes and overtraining problems. Moreover, it has shown outstanding performance than other state-of-the-art ELMs. Finally, the proposed SDPSO-ELM algorithm is successfully applied to the STLF of power system. Experiment results demonstrate that the proposed learning algorithm can get better forecasting results in comparison with the radial basis function neural network (RBFNN) algorithm.
ER  - 

TY  - JOUR
T1  - Deep object recognition across domains based on adaptive extreme learning machine
JO  - Neurocomputing
VL  - 239
IS  - 
SP  - 194
EP  - 203
PY  - 2017/5/24/
T2  - 
AU  - Zhang, Lei
AU  - He, Zhenwei
AU  - Liu, Yan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2017.02.016
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302862
KW  - Deep learning
KW  - Image classification
KW  - Support vector machine
KW  - Extreme learning machine
KW  - Object recognition
AB  - Abstract
Deep learning with a convolutional neural network (CNN) has been proved to be very effective in feature extraction and representation of images. For image classification problems, this work aims at exploring the capability of extreme learning machine on high-level deep features of images. Additionally, motivated by the biological learning mechanism of ELM, in this paper, an adaptive extreme learning machine (AELM) method is proposed for handling cross-task (domain) learning problems, without loss of its nature of randomization and high efficiency. The proposed AELM is an extension of ELM from single task to cross task learning, by introducing a new error term and Laplacian graph based manifold regularization term in objective function. We have discussed the nearest neighbor, support vector machines and extreme learning machines for image classification under deep convolutional activation feature representation. Specifically, we adopt 4 benchmark object recognition datasets from multiple sources with domain bias for evaluating different classifiers. The deep features of the object dataset are obtained by a well-trained CNN with five convolutional layers and three fully-connected layers on ImageNet. Experiments demonstrate that the proposed AELM is comparable and effective in single and multiple domains based recognition tasks.
ER  - 

TY  - JOUR
T1  - Dynamic extreme learning machine for data stream classification
JO  - Neurocomputing
VL  - 238
IS  - 
SP  - 433
EP  - 449
PY  - 2017/5/17/
T2  - 
AU  - Xu, Shuliang
AU  - Wang, Junhong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.12.078
UR  - https://www.sciencedirect.com/science/article/pii/S0925231217302722
KW  - Data stream
KW  - Classification
KW  - Concept drift
KW  - Extreme learning machine
KW  - Online learning
AB  - Abstract
In our society, many fields have produced a large number of data streams. How to mining the interesting knowledge and patterns from continuous data stream becomes a problem which we have to solve. Different from conventional classification algorithms, data stream classification algorithms have to adjust their classification models with the change of data stream because of concept drift. However, conventional classification models will keep stable once models are trained. To solve the problem, a dynamic extreme learning machine for data stream classification (DELM) is proposed. DELM utilizes online learning mechanism to train ELM as basic classifier and trains a double hidden layer structure to improve the performance of ELM. When an alert about concept drift is set, more hidden layer nodes are added into ELM to improve the generalization ability of classifier. If the value measuring concept drift reaches the upper limit or the accuracy of ELM is in a low level, the current classifier will be deleted, and the algorithm will use new data to train a new classifier so as to learn new concept. The experimental results showed DELM could improve the accuracy of classification result, and can adapt to new concept in a short time.
ER  - 

TY  - JOUR
T1  - Joint multiple fully connected convolutional neural network with extreme learning machine for hepatocellular carcinoma nuclei grading
JO  - Computers in Biology and Medicine
VL  - 84
IS  - 
SP  - 156
EP  - 167
PY  - 2017/5/1/
T2  - 
AU  - Li, Siqi
AU  - Jiang, Huiyan
AU  - Pang, Wenbo
SN  - 0010-4825
DO  - https://doi.org/10.1016/j.compbiomed.2017.03.017
UR  - https://www.sciencedirect.com/science/article/pii/S0010482517300720
KW  - Multiple fully connected layers
KW  - Convolutional neural network
KW  - Extreme learning machine
KW  - Back propagation
KW  - Hepatocellular carcinoma nuclei grading
AB  - Abstract
Accurate cell grading of cancerous tissue pathological image is of great importance in medical diagnosis and treatment. This paper proposes a joint multiple fully connected convolutional neural network with extreme learning machine (MFC-CNN-ELM) architecture for hepatocellular carcinoma (HCC) nuclei grading. First, in preprocessing stage, each grayscale image patch with the fixed size is obtained using center-proliferation segmentation (CPS) method and the corresponding labels are marked under the guidance of three pathologists. Next, a multiple fully connected convolutional neural network (MFC-CNN) is designed to extract the multi-form feature vectors of each input image automatically, which considers multi-scale contextual information of deep layer maps sufficiently. After that, a convolutional neural network extreme learning machine (CNN-ELM) model is proposed to grade HCC nuclei. Finally, a back propagation (BP) algorithm, which contains a new up-sample method, is utilized to train MFC-CNN-ELM architecture. The experiment comparison results demonstrate that our proposed MFC-CNN-ELM has superior performance compared with related works for HCC nuclei grading. Meanwhile, external validation using ICPR 2014 HEp-2 cell dataset shows the good generalization of our MFC-CNN-ELM architecture.
ER  - 

TY  - JOUR
T1  - Modeling reference evapotranspiration using extreme learning machine and generalized regression neural network only with temperature data
JO  - Computers and Electronics in Agriculture
VL  - 136
IS  - 
SP  - 71
EP  - 78
PY  - 2017/4/15/
T2  - 
AU  - Feng, Yu
AU  - Peng, Yong
AU  - Cui, Ningbo
AU  - Gong, Daozhi
AU  - Zhang, Kuandi
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2017.01.027
UR  - https://www.sciencedirect.com/science/article/pii/S0168169916306275
KW  - Reference evapotranspiration
KW  - Temperature data
KW  - Extreme learning machine
KW  - Generalized regression neural network
KW  - Hargreaves model
AB  - Abstract
Accurate estimation of reference evapotranspiration (ET0) is essential to agricultural water management. The present study developed two artificial intelligence models for daily ET0 estimation only with temperature data, including extreme learning machine (ELM) and generalized regression neural network (GRNN) in 6 meteorological stations of Sichuan basin, southwest China, and compared the proposed ELM and GRNN with the corresponding temperature-based Hargreaves (HG) model and its calibrated version considering FAO-56 Penman-Monteith ET0 as benchmark. Two data management scenarios were evaluated for estimation of ET0: (1) the models were trained/calibrated and tested using the local data of each station; and (2) the models were trained/calibrated using the pooled data from all the stations and tested in each station. In the first scenario, the results showed that the temperature-based ELM model provided the better estimation than the GRNN, HG and calibrated HG models, with average relative root mean square error (RRMSE) of 0.198, mean absolute error (MAE) of 0.267 mm/d and Nash-Sutcliffe coefficient (NS) of 0.891, respectively. In the second scenario, GRNN model provided the most accurate results among the considered models, with average RRMSE of 0.194, MAE of 0.263 mm/d and NS of 0.895, respectively. Both of the temperature-based GRNN and ELM performed much better than the HG and calibrated HG models for the two scenarios, and the temperature-based GRNN and ELM models are appropriate alternatives for accurate estimation of ET0 for Sichuan basin of southwest China, which is very helpful for farmers or irrigation system operators to improve their irrigation scheduling.
ER  - 

TY  - JOUR
T1  - Intelligent visual servoing with extreme learning machine and fuzzy logic
JO  - Expert Systems with Applications
VL  - 72
IS  - 
SP  - 344
EP  - 356
PY  - 2017/4/15/
T2  - 
AU  - YÃ¼ksel, Tolga
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2016.10.048
UR  - https://www.sciencedirect.com/science/article/pii/S0957417416305899
KW  - Image-based visual servoing
KW  - Extreme learning machine
KW  - Fuzzy logic
AB  - Abstract
While visual servoing (VS) provides the ability of motion using vision for robot manipulators, the approaches for a better VS have to deal with three common problems: obtaining the interaction matrix and its pseudoinverse for defined feature points, finding an appropriate gain value for the VS controller and keeping the features in the field of view (FOV) for VS permanency.

In this study, a new intelligent image-based visual servoing (IBVS) system for eye-in-hand configured robot manipulators using extreme learning machine (ELM) and fuzzy logic (FL) is proposed to solve these common problems of VS in a single system. As the first stage of the system, the pseudoinverse of the interaction matrix is approximated using trained ELMs which do not need hidden layer tuning. As the second stage, the classical IBVS controller is modified by a differential equation regarding initial velocity continuity and an appropriate gain in each loop is assigned by an FL unit to provide fast convergence within velocity limits. This unit also promotes manipulability of the manipulator to avoid singularities. As the last stage of the proposed system, regions are defined in the image plane to take precautions before feature missing. When a feature comes close to the edge of a restricted region, an FL unit is activated to obtain negative linear velocities in x and y direction which will be added to the instant velocities to drag the features towards the center of the FOV. In addition to these abilities, some VS metrics are redefined analytically to standardize the performance metric definitions of VS. To show the performance of the proposed system, simulation results of the classical and the proposed IBVS system under practical disturbances are presented for visual servoing of a Puma 560 arm. The advantages of singular matrix and joint configuration avoidance, adaptive gain with smooth gain surface, decreased convergence time within velocity limits, initial velocity continuity, FOV keeping with smooth velocity assurance, redefined VS metrics for standardization and robustness against disturbances are proved by variety of simulations. The simulation results also verify that the proposed system utilizing intelligent methods like ELM and FL is capable of dealing with common problems of VS and achieves sufficient results in terms of VS metrics.
ER  - 

TY  - JOUR
T1  - Hybrid evolutionary algorithm with extreme machine learning fitness function evaluation for two-stage capacitated facility location problems
JO  - Expert Systems with Applications
VL  - 71
IS  - 
SP  - 57
EP  - 68
PY  - 2017/4/1/
T2  - 
AU  - Guo, Peng
AU  - Cheng, Wenming
AU  - Wang, Yi
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2016.11.025
UR  - https://www.sciencedirect.com/science/article/pii/S0957417416306601
KW  - Facility location
KW  - Evolutionary algorithm
KW  - Fitness approximation
KW  - Local search
KW  - Extreme machine learning
AB  - Abstract
This paper considers the two-stage capacitated facility location problem (TSCFLP) in which products manufactured in plants are delivered to customers via storage depots. Customer demands are satisfied subject to limited plant production and limited depot storage capacity. The objective is to determine the locations of plants and depots in order to minimize the total cost including the fixed cost and transportation cost. However, the problem is known to be NP-hard. A practicable exact algorithm is impossible to be developed. In order to solve large-sized problems encountered in the practical decision process, an efficient alternative approximate method becomes more valuable. This paper aims to propose a hybrid evolutionary algorithm framework with machine learning fitness approximation for delivering better solutions in a reasonable amount of computational time. In our study, genetic operators are adopted to perform the search process and a local search strategy is used to refine the best solution found in the population. To avoid the expensive consumption of computational time during the fitness evaluating process, the framework uses extreme machine learning to approximate the fitness of most individuals. Moreover, two heuristics based on the characteristics of the problem is incorporated to generate a good initial population. Computational experiments are performed on two sets of test instances from the recent literature. The performance of the proposed algorithm is evaluated and analyzed. Compared with other algorithms in the literature, the proposed algorithm can find the optimal or near-optimal solutions in a reasonable amount of computational time. By employing the proposed algorithm, facilities can be positioned more efficiently, which means the fixed cost and the transportation cost can be decreased significantly, and organizations can enhance competitiveness by using the optimized facility location scheme.
ER  - 

TY  - JOUR
T1  - A physically based and machine learning hybrid approach for accurate rainfall-runoff modeling during extreme typhoon events
JO  - Applied Soft Computing
VL  - 53
IS  - 
SP  - 205
EP  - 216
PY  - 2017/4//
T2  - 
AU  - Young, Chih-Chieh
AU  - Liu, Wen-Cheng
AU  - Wu, Ming-Chang
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2016.12.052
UR  - https://www.sciencedirect.com/science/article/pii/S1568494617300017
KW  - Rainfall-runoff
KW  - Typhoon events
KW  - Hydrologic modeling system (HEC-HMS)
KW  - Support vector regression (SVR)
KW  - Artificial neural network (ANN)
KW  - Hybrid approach
AB  - Abstract
Accurate rainfall-runoff modeling during typhoon events is an essential task for natural disaster reduction. In this study, a novel hybrid model which integrates the outputs of physically based hydrologic modeling system into support vector machine is developed to predict hourly runoff discharges in Chishan Creek basin in southern Taiwan. Seven storms (with a total of 1200 data sets) are used for model calibration (training) and validation. Six statistical indices (mean absolute error, root mean square error, correlation coefficient, error of time to peak discharge, error of peak discharge, and coefficient of efficiency) are employed to assess prediction performance. Overall, superiority of the present approach especially for a longer (6-h) lead time prediction is revealed through a systematic comparison among three individual methods (i.e., the physically based hydrologic model, artificial neural network, and support vector machine) as well as their two hybrid combinations. Besides, our analysis and in-depth discussions further clarify the roles of physically based and data-driven components in the proposed framework.
ER  - 

TY  - JOUR
T1  - Quantitative thickness prediction of tectonically deformed coal using Extreme Learning Machine and Principal Component Analysis: a case study
JO  - Computers & Geosciences
VL  - 101
IS  - 
SP  - 38
EP  - 47
PY  - 2017/4//
T2  - 
AU  - Wang, Xin
AU  - Li, Yan
AU  - Chen, Tongjun
AU  - Yan, Qiuyan
AU  - Ma, Li
SN  - 0098-3004
DO  - https://doi.org/10.1016/j.cageo.2017.02.001
UR  - https://www.sciencedirect.com/science/article/pii/S0098300417301206
KW  - Thickness prediction
KW  - Tectonically deformed coal
KW  - Extreme learning machine
KW  - Seismic attribute
KW  - Principal component analysis
KW  - Cross validation
AB  - Abstract
The thickness of tectonically deformed coal (TDC) has positive correlation associations with gas outbursts. In order to predict the TDC thickness of coal beds, we propose a new quantitative predicting method using an extreme learning machine (ELM) algorithm, a principal component analysis (PCA) algorithm, and seismic attributes. At first, we build an ELM prediction model using the PCA attributes of a synthetic seismic section. The results suggest that the ELM model can produce a reliable and accurate prediction of the TDC thickness for synthetic data, preferring Sigmoid activation function and 20 hidden nodes. Then, we analyze the applicability of the ELM model on the thickness prediction of the TDC with real application data. Through the cross validation of near-well traces, the results suggest that the ELM model can produce a reliable and accurate prediction of the TDC. After that, we use 250 near-well traces from 10 wells to build an ELM predicting model and use the model to forecast the TDC thickness of the No. 15 coal in the study area using the PCA attributes as the inputs. Comparing the predicted results, it is noted that the trained ELM model with two selected PCA attributes yields better predication results than those from the other combinations of the attributes. Finally, the trained ELM model with real seismic data have a different number of hidden nodes (10) than the trained ELM model with synthetic seismic data. In summary, it is feasible to use an ELM model to predict the TDC thickness using the calculated PCA attributes as the inputs. However, the input attributes, the activation function and the number of hidden nodes in the ELM model should be selected and tested carefully based on individual application.
ER  - 

TY  - JOUR
T1  - Robust regularized extreme learning machine for regression using iteratively reweighted least squares
JO  - Neurocomputing
VL  - 230
IS  - 
SP  - 345
EP  - 358
PY  - 2017/3/22/
T2  - 
AU  - Chen, Kai
AU  - Lv, Qi
AU  - Lu, Yao
AU  - Dou, Yong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.12.029
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216315053
KW  - Extreme learning machine
KW  - Iteratively reweighted least squares
KW  - Robustness
KW  - â2-norm regularization
KW  - â1-norm regularization
AB  - Abstract
Extreme learning machine (ELM) for regression has been used in many fields because of its easy-implementation, fast training speed and good generalization performance. However, basic ELM with â2-norm loss function is sensitive to outliers. Recently, â1-norm loss function and Huber loss function have been used in ELM to enhance the robustness. However, the â1-norm loss function and the Huber loss function can also be effected by outliers because of their linear correlation with the errors. Moreover, existing robust ELM methods only use â2-norm regularization or have no regularization term. In this study, we propose a unified model for robust regularized ELM regression using iteratively reweighted least squares (IRLS), and call it RELM-IRLS. We perform a comprehensive study on the robust loss function and regularization term for robust ELM regression. Four loss functions (i.e., â1-norm, Huber, Bisquare and Welsch) are used to enhance the robustness, and two types of regularization (â2-norm and â1-norm) are used to avoid overfitting. Experiments show that our proposed RELM-IRLS with â2-norm and â1-norm regularization is stable and accurate for data with 0 â¼ 40 % outlier levels, and that RELM-IRLS with â1-norm regularization can obtain a compact network because of the highly sparse output weights of the network.
ER  - 

TY  - JOUR
T1  - Generalized extreme learning machine autoencoder and a new deep neural network
JO  - Neurocomputing
VL  - 230
IS  - 
SP  - 374
EP  - 381
PY  - 2017/3/22/
T2  - 
AU  - Sun, Kai
AU  - Zhang, Jiangshe
AU  - Zhang, Chunxia
AU  - Hu, Junying
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.12.027
UR  - https://www.sciencedirect.com/science/article/pii/S092523121631503X
KW  - Extreme learning machine
KW  - Generalized extreme learning machine autoencoder
KW  - Manifold regularization
KW  - Deep neural network
KW  - Multilayer generalized extreme learning machine autoencoder
AB  - Abstract
Extreme learning machine (ELM) is an efficient learning algorithm of training single layer feed-forward neural networks (SLFNs). With the development of unsupervised learning in recent years, integrating ELM with autoencoder has become a new perspective for extracting feature using unlabeled data. In this paper, we propose a new variant of extreme learning machine autoencoder (ELM-AE) called generalized extreme learning machine autoencoder (GELM-AE) which adds the manifold regularization to the objective of ELM-AE. Some experiments carried out on real-world data sets show that GELM-AE outperforms some state-of-the-art unsupervised learning algorithms, including k-means, laplacian embedding (LE), spectral clustering (SC) and ELM-AE. Furthermore, we also propose a new deep neural network called multilayer generalized extreme learning machine autoencoder (ML-GELM) by stacking several GELM-AE to detect more abstract representations. The experiments results show that ML-GELM outperforms ELM and many other deep models, such as multilayer ELM autoencoder (ML-ELM), deep belief network (DBN) and stacked autoencoder (SAE). Due to the utilization of ELM, ML-GELM is also faster than DBN and SAE.
ER  - 

TY  - JOUR
T1  - An improved incremental constructive single-hidden-layer feedforward networks for extreme learning machine based on particle swarm optimization
JO  - Neurocomputing
VL  - 228
IS  - 
SP  - 133
EP  - 142
PY  - 2017/3/8/
T2  - Advanced Intelligent Computing: Theory and Applications
AU  - Han, Fei
AU  - Zhao, Min-Ru
AU  - Zhang, Jian-Ming
AU  - Ling, Qing-Hua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.09.092
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216312826
KW  - Extreme learning machine
KW  - Particle swarm optimization
KW  - Network structure
KW  - Generalization performance
KW  - Condition value
AB  - Abstract
How to determine the network structure is an open problem in extreme learning machine (ELM). Error minimized extreme learning machine (EM-ELM) is a simple and efficient approach to determine the number of hidden nodes. However, similar to other constructive ELM, EM-ELM lays much emphasis on the convergence accuracy, which may obtain a single-hidden-layer feedforward neural networks (SLFN) with good convergence performance but bad condition. In this paper, an effective approach based on error minimized ELM and particle swarm optimization (PSO) is proposed to adaptively determine the structure of SLFN for regression problem. In the new method, to establish a compact and well-conditioning SLFN, the hidden node optimized by PSO is added to the SLFN one by one. Moreover, not only the regression accuracy but also the condition value of the hidden output matrix of the network is considered in the optimization process. Experiment results on various regression problems verify that the proposed algorithm achieves better generalization performance with fewer hidden nodes than other constructive ELM.
ER  - 

TY  - JOUR
T1  - An islanding detection algorithm for distributed generation based on HilbertâHuang transform and extreme learning machine
JO  - Sustainable Energy, Grids and Networks
VL  - 9
IS  - 
SP  - 13
EP  - 26
PY  - 2017/3//
T2  - 
AU  - Mishra, M.
AU  - Sahani, M.
AU  - Rout, P.K.
SN  - 2352-4677
DO  - https://doi.org/10.1016/j.segan.2016.11.002
UR  - https://www.sciencedirect.com/science/article/pii/S2352467716301436
KW  - Distributed generation
KW  - Hilbert transform
KW  - Empirical mode decomposition
KW  - Extreme learning machine
KW  - Intrinsic mode function
AB  - Abstract
This study presents a novel method to detect an islanding condition in a distribution system with distributed generations (DGs). The proposed approach is based on HilbertâHuang transform (HHT) and Extreme learning machine (ELM). The system taken for testing of the proposed method consists of different types of DGs like hydro turbine generator with synchronous machine and wind turbine generator with asynchronous machine. The analysis starts with extracting the non-stationary three phase voltage signals at the target DG end and decomposed into mono component signals, called intrinsic mode function (IMF), by the empirical mode decomposition (EMD) method. In the next step, the amplitude, phase angle and frequency of the components are computed by applying the HHT to each IMF. Then, the different distinguish features are calculated such as, energy, standard deviation of phase and amplitude to track the islanding condition from different non-islanding conditions like single line to ground fault, line to line fault, three phase fault, voltage sag, voltage swell, sudden load change, capacitor switching and other DG tripping etc. To test the accuracy of proposed method, a modified ELM classifier is developed based on the feature index. It has been found that the proposed HHTâELM technique is highly successful to discriminate islanding events under a wide range of operating conditions from the other type of disturbances in the power distribution network. The proposed scheme is simulated by the MATLAB/SIMULINK environment.
ER  - 

TY  - JOUR
T1  - Fast learning method for convolutional neural networks using extreme learning machine and its application to lane detection
JO  - Neural Networks
VL  - 87
IS  - 
SP  - 109
EP  - 121
PY  - 2017/3//
T2  - 
AU  - Kim, Jihun
AU  - Kim, Jonghong
AU  - Jang, Gil-Jin
AU  - Lee, Minho
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2016.12.002
UR  - https://www.sciencedirect.com/science/article/pii/S0893608016301885
KW  - Convolutional neural network
KW  - Extreme learning machine
KW  - Advanced driver assistance system
KW  - Lane detection
AB  - Abstract
Deep learning has received significant attention recently as a promising solution to many problems in the area of artificial intelligence. Among several deep learning architectures, convolutional neural networks (CNNs) demonstrate superior performance when compared to other machine learning methods in the applications of object detection and recognition. We use a CNN for image enhancement and the detection of driving lanes on motorways. In general, the process of lane detection consists of edge extraction and line detection. A CNN can be used to enhance the input images before lane detection by excluding noise and obstacles that are irrelevant to the edge detection result. However, training conventional CNNs requires considerable computation and a big dataset. Therefore, we suggest a new learning algorithm for CNNs using an extreme learning machine (ELM). The ELM is a fast learning method used to calculate network weights between output and hidden layers in a single iteration and thus, can dramatically reduce learning time while producing accurate results with minimal training data. A conventional ELM can be applied to networks with a single hidden layer; as such, we propose a stacked ELM architecture in the CNN framework. Further, we modify the backpropagation algorithm to find the targets of hidden layers and effectively learn network weights while maintaining performance. Experimental results confirm that the proposed method is effective in reducing learning time and improving performance.
ER  - 

TY  - JOUR
T1  - Effective pixel classification of Mars images based on ant colony optimization feature selection and extreme learning machine
JO  - Neurocomputing
VL  - 226
IS  - 
SP  - 66
EP  - 79
PY  - 2017/2/22/
T2  - 
AU  - Rashno, Abdolreza
AU  - Nazari, Behzad
AU  - Sadri, Saeed
AU  - Saraee, Mohamad
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.11.030
UR  - https://www.sciencedirect.com/science/article/pii/S092523121631431X
KW  - Pixel classification
KW  - Feature selection
KW  - Ant colony optimization
KW  - Extreme learning machine
KW  - Wavelet features
KW  - Color features
AB  - Abstract
one of the most important tasks of Mars rover, a robot which explores the Mars surface, is the process of automatic segmentation of images taken by front-line Panoramic Camera (Pancam). This procedure is highly significant since the transformation cost of images from Mars to earth is extremely high. Also, image analysis may help Mars rover for its navigation and localization. In this paper, a new feature vector including wavelet and color features for Mars images is proposed. Then, this feature vector is presented for extreme learning machine (ELM) classifier which leads to a high accuracy pixel classifier. It is shown that this system statistically outperforms support vector machine (SVM) and k-nearest neighbours (KNNs) classifiers with respect to both accuracy and run time. After that, dimension reduction in feature space is done by two proposed feature section algorithms based on ant colony optimization (ACO) to decrease the time complexity which is very important in Mars on-board applications. In the first proposed feature selection algorithm, the same feature subset is selected among the feature vector for all pixel classes, while in the second proposed algorithm, the most significant features are selected for each pixel class, separately. Proposed pixel classifier with complete feature set outperforms prior methods by 6.44% and 5.84% with respect to average Fmeasure and accuracy, respectively. Finally, proposed feature selection methods decrease the feature vector size up to 76% and achieves Fmeasure and accuracy of 91.72% and 91.05%, respectively, which outperforms prior methods with 87.22% and 86.64%.
ER  - 

TY  - JOUR
T1  - Extreme learning machine with a deterministic assignment of hidden weights in two parallel layers
JO  - Neurocomputing
VL  - 226
IS  - 
SP  - 109
EP  - 116
PY  - 2017/2/22/
T2  - 
AU  - HenrÃ­quez, Pablo A.
AU  - Ruz, Gonzalo A.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.11.040
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216314412
KW  - Extreme learning machine
KW  - Low-discrepancy points
KW  - Parallel layers
KW  - Regression
KW  - Classification
AB  - Abstract
Extreme learning machine (ELM) is a machine learning technique based on competitive single-hidden layer feedforward neural network (SLFN). However, traditional ELM and its variants are only based on random assignment of hidden weights using a uniform distribution, and then the calculation of the weights output using the least-squares method. This paper proposes a new architecture based on a non-linear layer in parallel by another non-linear layer and with entries of independent weights. We explore the use of a deterministic assignment of the hidden weight values using low-discrepancy sequences (LDSs). The simulations are performed with Halton and Sobol sequences. The results for regression and classification problems confirm the advantages of using the proposed method called PL-ELM algorithm with the deterministic assignment of hidden weights. Moreover, the PL-ELM algorithm with the deterministic generation using LDSs can be extended to other modified ELM algorithms.
ER  - 

TY  - JOUR
T1  - Monotonic classification extreme learning machine
JO  - Neurocomputing
VL  - 225
IS  - 
SP  - 205
EP  - 213
PY  - 2017/2/15/
T2  - 
AU  - Zhu, Hong
AU  - Tsang, Eric C.C.
AU  - Wang, Xi-Zhao
AU  - Aamir Raza Ashfaq, Rana
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.11.021
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216314023
KW  - Monotonic classification
KW  - Extreme learning machine
KW  - Constrained extreme learning machine
KW  - Monotonicity
KW  - Quadratic programming
AB  - Abstract
Monotonic classification problems mean that both feature values and class labels are ordered and monotonicity relationships exist between some features and the decision label. Extreme Learning Machine (ELM) is a single-hidden layer feedforward neural network with fast training rate and good generalization capability, but due to the existence of training error, ELM cannot be directly used to handle monotonic classification problems. This work proposes a generalization of ELM for processing the monotonic classification, named as Monotonic Classification Extreme Learning Machine (MCELM) in which the monotonicity constraints are imposed to the original ELM model. Mathematically, MCELM is a quadratic programming problem in which the monotonicity relationships are considered as constraints and the training error is the objective to be minimized. The mathematical model of MCELM not only can make the generated classifier monotonic but also can minimize the classification error. MCELM does not need to tune parameters iteratively, and therefore, keeps the advantage of extremely fast training which is the essential characteristic of ELM. MCELM does not require that the monotonic relationships existing between features and the output are consistent, which essentially relaxes the assumption of consistent monotonicity used in most existing approaches to handling monotonic classification problems. In comparison with exiting approaches to handling monotonic classification, MCELM can indeed generate a monotonicity-reserving classifier which experimentally shows a much better generalization capability on both artificial and real world datasets.
ER  - 

TY  - JOUR
T1  - Online sequential prediction of bearings imbalanced fault diagnosis by extreme learning machine
JO  - Mechanical Systems and Signal Processing
VL  - 83
IS  - 
SP  - 450
EP  - 473
PY  - 2017/1/15/
T2  - 
AU  - Mao, Wentao
AU  - He, Ling
AU  - Yan, Yunju
AU  - Wang, Jinwan
SN  - 0888-3270
DO  - https://doi.org/10.1016/j.ymssp.2016.06.024
UR  - https://www.sciencedirect.com/science/article/pii/S0888327016302035
KW  - Fault diagnosis
KW  - Extreme learning machine
KW  - Imbalance problem
KW  - Incipient fault
KW  - Online sequential Learning
AB  - Abstract
Diagnosis of bearings generally plays an important role in fault diagnosis of mechanical system, and machine learning has been a promising tool in this field. In many real applications of bearings fault diagnosis, the data tend to be online imbalanced, which means, the number of fault data is much less than the normal data while they are all collected in online sequential way. Suffering from this problem, many traditional diagnosis methods will get low accuracy of fault data which acts as the minority class in the collected bearing data. To address this problem, an online sequential prediction method for imbalanced fault diagnosis problem is proposed based on extreme learning machine. This method introduces the principal curve and granulation division to simulate the flow distribution and overall distribution characteristics of fault data, respectively. Then a confident over-sampling and under-sampling process is proposed to establish the initial offline diagnosis model. In online stage, the obtained granules and principal curves are rebuilt on the bearing data which are arrived in sequence, and after the over-sampling and under-sampling process, the balanced sample set is formed to update the diagnosis model dynamically. A theoretical analysis is provided and proves that, even existing information loss, the proposed method has lower bound of the model reliability. Simulation experiments are conducted on IMS bearing data and CWRU bearing data. The comparative results demonstrate that the proposed method can improve the fault diagnosis accuracy with better effectiveness and robustness than other algorithms.
ER  - 

TY  - JOUR
T1  - Approximate kernel extreme learning machine for large scale data classification
JO  - Neurocomputing
VL  - 219
IS  - 
SP  - 210
EP  - 220
PY  - 2017/1/5/
T2  - 
AU  - Iosifidis, Alexandros
AU  - Tefas, Anastasios
AU  - Pitas, Ioannis
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.09.023
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216310402
KW  - Extreme Learning Machine
KW  - Large Scale Learning
KW  - Facial Image Classification
AB  - Abstract
In this paper, we propose an approximation scheme of the Kernel Extreme Learning Machine algorithm for Single-hidden Layer Feedforward Neural network training that can be used for large scale classification problems. The Approximate Kernel Extreme Learning Machine is able to scale well in both computational cost and memory, while achieving good generalization performance. Regularized versions and extensions in order to exploit the total and within-class variance of the training data in the feature space are also proposed. Extensive experimental evaluation in medium-scale and large-scale classification problems denotes that the proposed approach is able to operate extremely fast in both the training and test phases and to provide satisfactory performance, outperforming relating classification schemes.
ER  - 

TY  - JOUR
T1  - FASTA-ELM: A fast adaptive shrinkage/thresholding algorithm for extreme learning machine and its application to gender recognition
JO  - Neurocomputing
VL  - 219
IS  - 
SP  - 312
EP  - 322
PY  - 2017/1/5/
T2  - 
AU  - Mahmood, Saif F.
AU  - Marhaban, Mohammad Hamiruce
AU  - Rokhani, Fakhrul Zaman
AU  - Samsudin, Khairulmizam
AU  - Arigbabu, Olasimbo Ayodeji
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.09.046
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216310748
KW  - Fast adaptive shrinkage/thresholding
KW  - Extreme learning machine
KW  - Hidden node selection
KW  - Feature representation
KW  - Face gender recognition
AB  - Abstract
Extreme learning machine (ELM) is an interesting algorithm for learning the hidden layer of single layer feed forward neural networks. However, one of the main shortcomings restricting further improvement of ELM is the complexity of singular value decomposition (SVD) for computing the Moore-Penrose generalized inverse of the hidden layer matrix. This paper presents a new algorithm named fast adaptive shrinkage/thresholding algorithm ELM (FASTA-ELM) which uses an extension of forward-backward splitting (FBS) to compute the smallest norm of the output weights in ELM. The proposed FASTA-ELM algorithm is evaluated on face gender recognition problem using 5 benchmarked datasets. The results indicate that FASTA-ELM provides efficient performance and outperforms the standard ELM and two other variants of ELM in terms of generalization ability and computational time. Furthermore, the recognition performance of FASTA-ELM is comparable to other state-of-the-art face gender recognition methods.
ER  - 

TY  - JOUR
T1  - Evaluation of extreme learning machine for classification of individual and combined finger movements using electromyography on amputees and non-amputees
JO  - Neural Networks
VL  - 85
IS  - 
SP  - 51
EP  - 68
PY  - 2017/1//
T2  - 
AU  - Anam, Khairul
AU  - Al-Jumaily, Adel
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2016.09.004
UR  - https://www.sciencedirect.com/science/article/pii/S0893608016301319
KW  - Classification
KW  - Myoelectric pattern recognition
KW  - Electromyography (EMG)
KW  - Extreme learning machine (ELM)
KW  - Amputee
AB  - Abstract
The success of myoelectric pattern recognition (M-PR) mostly relies on the features extracted and classifier employed. This paper proposes and evaluates a fast classifier, extreme learning machine (ELM), to classify individual and combined finger movements on amputees and non-amputees. ELM is a single hidden layer feed-forward network (SLFN) that avoids iterative learning by determining input weights randomly and output weights analytically. Therefore, it can accelerate the training time of SLFNs. In addition to the classifier evaluation, this paper evaluates various feature combinations to improve the performance of M-PR and investigate some feature projections to improve the class separability of the features. Different from other studies on the implementation of ELM in the myoelectric controller, this paper presents a complete and thorough investigation of various types of ELMs including the node-based and kernel-based ELM. Furthermore, this paper provides comparisons of ELMs and other well-known classifiers such as linear discriminant analysis (LDA), k-nearest neighbour (kNN), support vector machine (SVM) and least-square SVM (LS-SVM). The experimental results show the most accurate ELM classifier is radial basis function ELM (RBF-ELM). The comparison of RBF-ELM and other well-known classifiers shows that RBF-ELM is as accurate as SVM and LS-SVM but faster than the SVM family; it is superior to LDA and kNN. The experimental results also indicate that the accuracy gap of the M-PR on the amputees and non-amputees is not too much with the accuracy of 98.55% on amputees and 99.5% on the non-amputees using six electromyography (EMG) channels.
ER  - 

TY  - JOUR
T1  - Fault detection based on signal reconstruction with Auto-Associative Extreme Learning Machines
JO  - Engineering Applications of Artificial Intelligence
VL  - 57
IS  - 
SP  - 105
EP  - 117
PY  - 2017/1//
T2  - 
AU  - Hu, Yang
AU  - PalmÃ©, Thomas
AU  - Fink, Olga
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2016.10.010
UR  - https://www.sciencedirect.com/science/article/pii/S0952197616301853
KW  - Fault detection
KW  - Auto-Associative Extreme Learning Machines
KW  - Performance comparison
KW  - Auto-Associative Kernel Regression
KW  - Principal Component Analysis
KW  - Combined-cycle power plant compressor
AB  - Abstract
Early fault detection of engineering systems allows early warnings of anomalies and provides time to initiate proactive mitigation actions before the anomaly has developed to a problem that either requires extensive maintenance or affects the productivity of the system. In this paper, a new fault detection method using signal reconstruction based on Auto-Associative Extreme Learning Machines (AAELM) is proposed. AAELM are applied for fault detection on an artificially generated dataset to test the performance of the algorithm under controlled conditions and a real case study based on condition monitoring data from a combined-cycle power plant compressor. The performance of AAELM is compared to that of two other commonly used signal reconstruction methods: Auto-Associative Kernel Regression (AAKR) and Principal Component Analysis (PCA). The results from the two case studies demonstrate that AAELM achieve a smaller reconstruction error, shorter detection delay, lower spillover and a higher distinguishability compared to AAKR and PCA on the evaluated datasets. The obtained results are generalized to elaborate guidelines for industrial users for selecting suitable signal reconstruction algorithms based on their specific requirements and boundary conditions.
ER  - 

TY  - JOUR
T1  - Multi-level hybrid support vector machine and extreme learning machine based on modified K-means for intrusion detection system
JO  - Expert Systems with Applications
VL  - 67
IS  - 
SP  - 296
EP  - 303
PY  - 2017/1//
T2  - 
AU  - Al-Yaseen, Wathiq Laftah
AU  - Othman, Zulaiha Ali
AU  - Nazri, Mohd Zakree Ahmad
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2016.09.041
UR  - https://www.sciencedirect.com/science/article/pii/S0957417416305310
KW  - Intrusion detection system
KW  - Support vector machine
KW  - Extreme learning machine
KW  - K-means
KW  - Multi-level
KW  - KDD Cup 1999
AB  - Abstract
Intrusion detection has become essential to network security because of the increasing connectivity between computers. Several intrusion detection systems have been developed to protect networks using different statistical methods and machine learning techniques. This study aims to design a model that deals with real intrusion detection problems in data analysis and classify network data into normal and abnormal behaviors. This study proposes a multi-level hybrid intrusion detection model that uses support vector machine and extreme learning machine to improve the efficiency of detecting known and unknown attacks. A modified K-means algorithm is also proposed to build a high-quality training dataset that contributes significantly to improving the performance of classifiers. The modified K-means is used to build new small training datasets representing the entire original training dataset, significantly reduce the training time of classifiers, and improve the performance of intrusion detection system. The popular KDD Cup 1999 dataset is used to evaluate the proposed model. Compared with other methods based on the same dataset, the proposed model shows high efficiency in attack detection, and its accuracy (95.75%) is the best performance thus far.
ER  - 

TY  - JOUR
T1  - Retinal vessel segmentation in colour fundus images using Extreme Learning Machine
JO  - Computerized Medical Imaging and Graphics
VL  - 55
IS  - 
SP  - 68
EP  - 77
PY  - 2017/1//
T2  - Special Issue on Ophthalmic Medical Image Analysis
AU  - Zhu, Chengzhang
AU  - Zou, Beiji
AU  - Zhao, Rongchang
AU  - Cui, Jinkai
AU  - Duan, Xuanchu
AU  - Chen, Zailiang
AU  - Liang, Yixiong
SN  - 0895-6111
DO  - https://doi.org/10.1016/j.compmedimag.2016.05.004
UR  - https://www.sciencedirect.com/science/article/pii/S0895611116300416
KW  - Colour fundus image
KW  - Retinal vessel segmentation
KW  - Feature extraction
KW  - Supervised learning
KW  - Computer-aided diagnosis
AB  - Abstract
Attributes of the retinal vessel play important role in systemic conditions and ophthalmic diagnosis. In this paper, a supervised method based on Extreme Learning Machine (ELM) is proposed to segment retinal vessel. Firstly, a set of 39-D discriminative feature vectors, consisting of local features, morphological features, phase congruency, Hessian and divergence of vector fields, is extracted for each pixel of the fundus image. Then a matrix is constructed for pixel of the training set based on the feature vector and the manual labels, and acts as the input of the ELM classifier. The output of classifier is the binary retinal vascular segmentation. Finally, an optimization processing is implemented to remove the region less than 30 pixels which is isolated from the retinal vascilar. The experimental results testing on the public Digital Retinal Images for Vessel Extraction (DRIVE) database demonstrate that the proposed method is much faster than the other methods in segmenting the retinal vessels. Meanwhile the average accuracy, sensitivity, and specificity are 0.9607, 0.7140 and 0.9868, respectively. Moreover the proposed method exhibits high speed and robustness on a new Retinal Images for Screening (RIS) database. Therefore it has potential applications for real-time computer-aided diagnosis and disease screening.
ER  - 

TY  - JOUR
T1  - Application of Extreme Learning Machine Combination Model for Dam Displacement Prediction
JO  - Procedia Computer Science
VL  - 107
IS  - 
SP  - 373
EP  - 378
PY  - 2017///
T2  - Advances in Information and Communication Technology: Proceedings of 7th International Congress of Information and Communication Technology (ICICT2017)
AU  - Cheng, Jiatang
AU  - Xiong, Yan
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2017.03.120
UR  - https://www.sciencedirect.com/science/article/pii/S1877050917303952
KW  - dam
KW  - displacement
KW  - combination prediction
KW  - extreme learning machine
AB  - Abstract
The dam displacement can effectively reflect the dam security status. To improve the accuracy of dam displacement prediction, a combination prediction model is presented based on extreme learning machine (ELM). In this combination model, the predictive values of the grey GM(1,1) and regression analysis, combined with the average values of predictive results of the two methods, are used as the input vectors of ELM, and the actual values of dam displacement are selected as the output vectors, and then the nonlinear combination prediction model is built. The simulation results show that the mean relative error, the average absolute error are 3.04% and 4.14% of the combination method based on extreme learning machine, respectively, which less than those of the GM(1,1), regression analysis and equal weight combination method, and is suitable for the prediction of dam displacement.
ER  - 

TY  - JOUR
T1  - Extreme Learning Machine based weighting for decision rule in Collaborative Representation Classifier
JO  - Procedia Computer Science
VL  - 112
IS  - 
SP  - 504
EP  - 513
PY  - 2017///
T2  - Knowledge-Based and Intelligent Information &amp; Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France
AU  - Ramli, Dzati Athiar
AU  - Chien, Tan Wan
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2017.08.154
UR  - https://www.sciencedirect.com/science/article/pii/S1877050917315119
KW  - Extreme learning machine (ELM)
KW  - collaborative representation based classification (CRC)
KW  - sparse representation based classification (SRC)
KW  - classification
KW  - l2-norm minimization
AB  - Abstract
Sparse representation based classification (SRC) has been widely used for pattern recognition especially to face recognition due to its robustness to illumination change, noise and occlusion in face images. SRC method emphasizes the role of parsimonious representation in achieving robustness and accurate classification. To enforce sparsity, the linear representation of query sample and training samples is computed using l1-minimization which is complex and time consuming. Recently, many studies have proved the robustness of SRC is achieved by the collaborative representation mechanism and not the l1 sparsity constraint. Thus, the l1-norm based representation in SRC classification framework could be replaced by l2-norm based representation which is computationally more efficient. This type of classification method is called Collaborative representation based classification (CRC) in the literature. In this paper, an output weight computed from extreme learning machine ELM regarded as a class membership is utilized in conjunction with the classification decision in collaborative representation classifier to improve high classification accuracy over various public available face and speech recognition datasets. The role of ELM is to provide the class membership which denotes the nonlinear similarity of the query sample to training samples from each class. Whereas the CRC provides the linear representation of the query sample and training. The collaborative representation from CRC and class membership from ELM are applied in the regularized residual classification decision to classify the query sample. Experimental results prove that the classification accuracy of the proposed algorithm i.e. CRC-ELM is greatly improved the baseline performances.
ER  - 

TY  - JOUR
T1  - Saliency detection via extreme learning machine
JO  - Neurocomputing
VL  - 218
IS  - 
SP  - 103
EP  - 112
PY  - 2016/12/19/
T2  - 
AU  - Zhang, Lu
AU  - Li, Jianhua
AU  - Lu, Huchuan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.08.066
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216309626
KW  - Saliency detection
KW  - Extreme learning machine
KW  - Multi-scale superpixels
AB  - Abstract
In this paper, we propose an effective algorithm based on Extreme Learning Machine (ELM) for salient object detection. First, saliency maps generated by existing methods are taken as prior maps, from which training samples are collected for an ELM classifier. Second, the ELM classifier is learned to detect the salient regions, and the final results are generated by fusing multi-scale saliency maps. This ELM-based model can improve the performance of different state-of-the-art methods to a large degree. Furthermore, we present an integration mechanism to take advantages of superiorities of multiple saliency maps. Extensive experiments on five datasets demonstrate that our method performs well and the significant improvement can be achieved when applying our model to existing saliency approaches.
ER  - 

TY  - JOUR
T1  - A fast incremental extreme learning machine algorithm for data streams classification
JO  - Expert Systems with Applications
VL  - 65
IS  - 
SP  - 332
EP  - 344
PY  - 2016/12/15/
T2  - 
AU  - Xu, Shuliang
AU  - Wang, Junhong
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2016.08.052
UR  - https://www.sciencedirect.com/science/article/pii/S0957417416304511
KW  - Data mining
KW  - Extreme learning machine
KW  - Data streams
KW  - Classification
KW  - Concept drift
AB  - Abstract
Data streams classification is an important approach to get useful knowledge from massive and dynamic data. Because of concept drift, traditional data mining techniques cannot be directly applied in data streams environment. Extreme learning machine (ELM) is a single hidden layer feedforward neural network (SLFN), comparing with the traditional neural network (e.g. BP network), ELM has a faster speed, so it is very suitable for real-time data processing. In order to deal with the challenge in data streams classification, a new approach based on extreme learning machine is proposed in this paper. The approach utilizes ELMs as base classifiers and adaptively decides the number of the neurons in hidden layer, in addition, activation functions are also randomly selected from a series of functions to improve the performance of the approach. Finally, the algorithm trains a series of classifiers and the decision results for unlabeled data are made by weighted voting strategy. When the concept in data streams keeps stable, every classifier is incrementally updated by using new data; if concept drift is detected, the classifiers with weak performance will be cleared away. In the experiment, we used 7 artificial data sets and 9 real data sets from UCI repository to evaluate the performance of the proposed approach. The testing results showed, comparing with the conventional classification methods for data streams such as ELM, BP, AUE2 and Learn++.MF, on most data sets, the new approach could not only be simplest in the structure, but also get a higher and more stable accuracy with lower time consuming.
ER  - 

TY  - JOUR
T1  - Multimodal biometrics recognition based on local fusion visual features and variational Bayesian extreme learning machine
JO  - Expert Systems with Applications
VL  - 64
IS  - 
SP  - 93
EP  - 103
PY  - 2016/12/1/
T2  - 
AU  - Chen, Yarui
AU  - Yang, Jucheng
AU  - Wang, Chao
AU  - Liu, Na
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2016.07.009
UR  - https://www.sciencedirect.com/science/article/pii/S0957417416303529
KW  - Multimodal biometrics recognition
KW  - Local fusion visual feature
KW  - Extreme learning machine
KW  - Variational Bayesian
AB  - Abstract
Multimodal biometrics provides rich information in biometric recognition systems, thus a valid multimodal feature fusion framework and an efficient recognition algorithm are desirable for multimodal biometrics systems. In this paper, we design a multimodal fusion framework for face and fingerprint images using block based feature-image matrix, and extract a type of middle-layer semantic feature from local featuresâa local fusion visual feature, which has better characterization capabilities with lower dimension for multimodal biometrics. Furthermore, we create recognition utilizing the Variational Bayesian Extreme Learning Machine (VBELM), which has an obvious speed advantage by random input weights, and also has superior stability and generalization by adding a non-informative full Gaussian prior. This research enables multimodal biometrics recognition system to have a concentrated fusion feature description and great recognition performance. Experimental results show that the proposed multimodal biometrics recognition system has a higher testing accuracy in comparison to the traditional methods with higher efficiency and better stability.
ER  - 

TY  - JOUR
T1  - Economic growth forecasting by artificial neural network with extreme learning machine based on trade, import and export parameters
JO  - Computers in Human Behavior
VL  - 65
IS  - 
SP  - 43
EP  - 45
PY  - 2016/12//
T2  - 
AU  - Sokolov-MladenoviÄ, Svetlana
AU  - MilovanÄeviÄ, Milos
AU  - MladenoviÄ, Igor
AU  - Alizamir, Meysam
SN  - 0747-5632
DO  - https://doi.org/10.1016/j.chb.2016.08.014
UR  - https://www.sciencedirect.com/science/article/pii/S0747563216305799
KW  - Artificial neural network
KW  - Extreme learning machine
KW  - Forecasting
KW  - Gross domestic product
AB  - Abstract
Economic growth may be developed based on trade, imports and exports parameters. The main goal in this study was to predict the economic growth based on trade in services, exports of goods and services, imports of goods and services, trade and merchandise trade on the economic growth. Gross domestic product (GDP) was used as economic growth indicator. The main purpose of this research is to develop and apply the artificial neural network (ANN) with back propagation learning (BP) algorithm and with extreme learning machine (ELM) in order predict GDP growth rate. The aim was to compare the results of BP and ELM prediction accuracy for the GDP growth rate prediction based on the trade data. Based on results, it was demonstrated that ELM can be utilized effectively in applications of GDP growth rate forecasting.
ER  - 

TY  - JOUR
T1  - Recursive reduced kernel based extreme learning machine for aero-engine fault pattern recognition
JO  - Neurocomputing
VL  - 214
IS  - 
SP  - 1038
EP  - 1045
PY  - 2016/11/19/
T2  - 
AU  - You, Cheng-Xin
AU  - Huang, Jin-Quan
AU  - Lu, Feng
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.06.069
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216307561
KW  - Extreme learning machine
KW  - Kernel method
KW  - Sparseness
KW  - Reduced technique
KW  - Aero-engine
KW  - Fault pattern recognition
AB  - Abstract
Kernel based extreme learning machine (K-ELM) has better generalization performance than basic ELM with less tuned parameters in most applications. However the original K-ELM is lack of sparseness, which makes the model scale grows linearly with sample size. This paper focuses on sparsity of K-ELM and proposes recursive reduced kernel based extreme learning machine (RR-KELM). The proposed algorithm chooses samples making more contribution to target function to constitute kernel dictionary meanwhile considering all the constraints generated by the whole training set. As a result it can simplify model structure and realize sparseness of K-ELM. Experimental results on benchmark datasets show that no matter for regression or classification problems, RR-KELM produces more compact model structure and higher real-time in comparison with other methods. The application of RR-KELM for aero-engine fault pattern recognition is also given in this paper. The simulation results demonstrate that RR-KELM has a high recognition rate on aero-engine fault pattern based on measurable parameters of aero-engine.
ER  - 

TY  - JOUR
T1  - A sequential method using multiplicative extreme learning machine for epileptic seizure detection
JO  - Neurocomputing
VL  - 214
IS  - 
SP  - 692
EP  - 707
PY  - 2016/11/19/
T2  - 
AU  - Li, Dazi
AU  - Xie, Qianwen
AU  - Jin, Qibing
AU  - Hirasawa, Kotaro
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.06.056
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216307299
KW  - Discrete Wavelet Transforms (DWT)
KW  - Phase Space Reconstruction (PSR)
KW  - Singular values of covariance matrix
KW  - Multiplicative extreme learning machine
KW  - Epileptic seizure detection
AB  - Abstract
Epilepsy, one of the most common neurological disorders of the human brain, is unpredictable and irregular. There is much difficulty involved in its detection. Here, a sequential processing feature extraction method and a novel multiplicative extreme learning machine are proposed for using in the electroencephalogram (EEG) classification process towards epileptic seizure detection. Firstly, a discrete wavelet transform (DWT) algorithm based on the frequency decomposition is used to obtain the sub-band wavelet coefficients. Secondly, two-dimensional (2D) and three-dimensional (3D) phase space reconstruction (PSR) of the sub-band are calculated to reveal the nonlinear chaos characteristics of signals in the high dimension. Thirdly, and differing from other statistical methods, the singular values are calculated based on the covariance matrix of 2D or 3D phase space as features that reduce the correlation of each dimension and which demonstrate the crucial variance in the original EEG signals. A combination of the proposed sequential methods can extract the significant features of epileptic seizure signals for classification. Finally, a novel multiplicative extreme learning machine (M-ELM) is proposed for using in the classification process. As compared with the normal ELM, support vector machine (SVM) with different kernels and backpropagation (BP) neural networks, the use of M-ELM can further improve the classification accuracy rate of the seizure signals, seizure free signals and healthy signals from the public dataset. Tests of the proposed epilepsy detection approach can achieve the highest 100% detection accuracy with rapid calculation speed.
ER  - 

TY  - JOUR
T1  - Multi-view clustering with extreme learning machine
JO  - Neurocomputing
VL  - 214
IS  - 
SP  - 483
EP  - 494
PY  - 2016/11/19/
T2  - 
AU  - Wang, Qiang
AU  - Dou, Yong
AU  - Liu, Xinwang
AU  - Lv, Qi
AU  - Li, Shijie
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.06.035
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216306737
KW  - Multi-view clustering
KW  - Unsupervised clustering
KW  - Extreme learning machine
AB  - Abstract
Nowadays, data always have multiple representations, and a good feature representation usually leads to a good clustering performance. Existing multi-view clustering works generally integrate multiple complementary information to gain better clustering performance rather than relying on a single view. However, these works usually focus on the combination of information rather than improving the feature representation capability of each view. As a new method, extreme learning machine (ELM) has excellent feature representation capability, easy parameter selection, and promising performance in various clustering tasks. This paper proposes a novel multi-view clustering framework with ELM to further improve clustering performance, and implements three algorithms based on this framework. In this framework, the normalized features of each individual view are mapped onto a higher dimensional feature space by the ELM random mapping. Afterwards, the unsupervised multi-view clustering is performed in this feature space. Thus far, this is the first work on multi-view clustering with ELM. Numerous baseline methods on five real-world datasets are empirically compared to show the effectiveness of the proposed algorithms. As indicated, the proposed algorithms yield superior clustering performance when compared with several state-of-art multi-view clustering methods in recent literatures.
ER  - 

TY  - JOUR
T1  - Efficient modeling of fiber optic gyroscope drift using improved EEMD and extreme learning machine
JO  - Signal Processing
VL  - 128
IS  - 
SP  - 1
EP  - 7
PY  - 2016/11//
T2  - 
AU  - Chen, Xiyuan
AU  - Cui, Bingbo
SN  - 0165-1684
DO  - https://doi.org/10.1016/j.sigpro.2016.03.016
UR  - https://www.sciencedirect.com/science/article/pii/S0165168416300093
KW  - Fiber optics sensors
KW  - Ensemble empirical mode decomposition
KW  - Thermal effects
KW  - Extreme learning machine
AB  - Abstract
In order to model the drift of fiber optic gyroscope (FOG) efficiently, a novel multi-scale prediction method is proposed by utilizing signal decomposition. Analytical expression of thermally induced drift of FOG is given first, which forms our theoretical basis of multi-scale prediction. Newly proposed bounded EEMD is used to decompose drift signal into a series of stationary modes, and then an adaptive feature selection criterion is proposed to construct distinct sub-series. Extreme learning machine is used to train these sub-series respectively, and a hybrid model is then obtained by adding up all the sub-models. Experiments have shown that, compared with the state-of-the-art methods, the proposed method improves prediction accuracy by two orders and achieves much faster speed in training process.
ER  - 

TY  - JOUR
T1  - A systematic design of interval type-2 fuzzy logic system using extreme learning machine for electricity load demand forecasting
JO  - International Journal of Electrical Power & Energy Systems
VL  - 82
IS  - 
SP  - 1
EP  - 10
PY  - 2016/11//
T2  - 
AU  - Hassan, Saima
AU  - Khosravi, Abbas
AU  - Jaafar, Jafreezal
AU  - Khanesar, Mojtaba Ahmadieh
SN  - 0142-0615
DO  - https://doi.org/10.1016/j.ijepes.2016.03.001
UR  - https://www.sciencedirect.com/science/article/pii/S0142061516303271
KW  - Extreme learning machine
KW  - Interval type-2 fuzzy logic systems
KW  - Electricity load forecasting
KW  - Learning algorithm
KW  - Smart grid
AB  - Abstract
This paper presents a novel design of interval type-2 fuzzy logic systems (IT2FLS) by utilizing the theory of extreme learning machine (ELM) for electricity load demand forecasting. ELM has become a popular learning algorithm for single hidden layer feed-forward neural networks (SLFN). From the functional equivalence between the SLFN and fuzzy inference system, a hybrid of fuzzy-ELM has gained attention of the researchers. This paper extends the concept of fuzzy-ELM to an IT2FLS based on ELM (IT2FELM). In the proposed design the antecedent membership function parameters of the IT2FLS are generated randomly, whereas the consequent part parameters are determined analytically by the MooreâPenrose pseudo inverse. The ELM strategy ensures fast learning of the IT2FLS as well as optimality of the parameters. Effectiveness of the proposed design of IT2FLS is demonstrated with the application of forecasting nonlinear and chaotic data sets. Nonlinear data of electricity load from the Australian National Electricity Market for the Victoria region and from the Ontario Electricity Market are considered here. The proposed model is also applied to forecast Mackey-glass chaotic time series data. Comparative analysis of the proposed model is conducted with some traditional models such as neural networks (NN) and adaptive neuro fuzzy inference system (ANFIS). In order to verify the structure of the proposed design of IT2FLS an alternate design of IT2FLS based on Kalman filter (KF) is also utilized for the comparison purposes.
ER  - 

TY  - JOUR
T1  - Ensemble extreme learning machine and sparse representation classification
JO  - Journal of the Franklin Institute
VL  - 353
IS  - 17
SP  - 4526
EP  - 4541
PY  - 2016/11//
T2  - 
AU  - Cao, Jiuwen
AU  - Hao, Jiaoping
AU  - Lai, Xiaoping
AU  - Vong, Chi-Man
AU  - Luo, Minxia
SN  - 0016-0032
DO  - https://doi.org/10.1016/j.jfranklin.2016.08.024
UR  - https://www.sciencedirect.com/science/article/pii/S0016003216303088
AB  - Abstract
Extreme learning machine (ELM) combining with sparse representation classification (ELM-SRC) has been developed for image classification recently. However, employing a single ELM network with random hidden parameters may lead to unstable generalization and data partition performance in ELM-SRC. To alleviate this deficiency, we propose an enhanced ensemble based ELM and SRC algorithm (En-SRC) in this paper. Rather than using the output of a single ELM to decide the threshold for data partition, En-SRC incorporates multiple ensembles to enhance the reliability of the classifier. Different from ELM-SRC, a theoretical analysis on the data partition threshold selection of En-SRC is given. Extension to the ensemble based regularized ELM with SRC (EnR-SRC) is also presented in the paper. Experiments on a number of benchmark classification databases show that the proposed methods win a better classification performance with a lower computational complexity than the ELM-SRC approach.
ER  - 

TY  - JOUR
T1  - A clustering-based sales forecasting scheme by using extreme learning machine and ensembling linkage methods with applications to computer server
JO  - Engineering Applications of Artificial Intelligence
VL  - 55
IS  - 
SP  - 231
EP  - 238
PY  - 2016/10//
T2  - 
AU  - Lu, Chi-Jie
AU  - Kao, Ling-Jing
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2016.06.015
UR  - https://www.sciencedirect.com/science/article/pii/S0952197616301257
KW  - Sales forecasting
KW  - Clustering
KW  - Ensemble learning
KW  - Linkage method
KW  - Extreme learning machine
KW  - Computer server
AB  - Abstract
Sales forecasting has long been crucial for companies since it is important for financial planning, inventory management, marketing, and customer service. In this study, a novel clustering-based sales forecasting scheme that uses an extreme learning machine (ELM) and assembles the results of linkage methods is proposed. The proposed scheme first uses the K-means algorithm to divide the training sales data into multiple disjointed clusters. Then, for each cluster, the ELM is applied to construct a forecasting model. Finally, a test datum is assigned to the most suitable cluster identified according to the result of combining five linkage methods. The constructed ELM model corresponding to the identified cluster is utilized to perform the final prediction. Two real sales datasets of computer servers collected from two multinational electronics companies are used to illustrate the proposed model. Empirical results showed that the proposed clustering-based sales forecasting scheme statistically outperforms eight benchmark models, and hence demonstrates that the proposed approach is an effective alternative for sales forecasting.
ER  - 

TY  - JOUR
T1  - Memetic Extreme Learning Machine
JO  - Pattern Recognition
VL  - 58
IS  - 
SP  - 135
EP  - 148
PY  - 2016/10//
T2  - 
AU  - Zhang, Yongshan
AU  - Wu, Jia
AU  - Cai, Zhihua
AU  - Zhang, Peng
AU  - Chen, Ling
SN  - 0031-3203
DO  - https://doi.org/10.1016/j.patcog.2016.04.003
UR  - https://www.sciencedirect.com/science/article/pii/S003132031630036X
KW  - Extreme Learning Machine
KW  - Self-adaptive
KW  - Memetic Algorithm
KW  - Evolutionary Machine Learning
KW  - Classification
AB  - Abstract
Extreme Learning Machine (ELM) is a promising model for training single-hidden layer feedforward networks (SLFNs) and has been widely used for classification. However, ELM faces the challenge of arbitrarily selected parameters, e.g., the network weights and hidden biases. Therefore, many efforts have been made to enhance the performance of ELM, such as using evolutionary algorithms to explore promising areas of the solution space. Although evolutionary algorithms can explore promising areas of the solution space, they are not able to locate global optimum efficiently. In this paper, we present a new Memetic Algorithm (MA)-based Extreme Learning Machine (M-ELM for short). M-ELM embeds the local search strategy into the global optimization framework to obtain optimal network parameters. Experiments and comparisons on 46 UCI data sets validate the performance of M-ELM. The corresponding results demonstrate that M-ELM significantly outperforms state-of-the-art ELM algorithms.
ER  - 

TY  - JOUR
T1  - Hessian semi-supervised extreme learning machine
JO  - Neurocomputing
VL  - 207
IS  - 
SP  - 560
EP  - 567
PY  - 2016/9/26/
T2  - 
AU  - Krishnasamy, Ganesh
AU  - Paramesran, Raveendran
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.05.039
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216303915
KW  - Extreme learning machine
KW  - Semi-supervised learning
KW  - Manifold learning
KW  - Hessian regularization
AB  - Abstract
Extreme learning machine (ELM) has emerged as an efficient and effective learning algorithm for classification and regression tasks. Most of the existing research on the ELMs mainly focus on supervised learning. Recently, researchers have extended ELMs for semi-supervised learning, in which they exploit both the labeled and unlabeled data in order to enhance the learning performances. They have incorporated Laplacian regularization to determine the geometry of the underlying manifold. However, Laplacian regularization lacks extrapolating power and biases the solution towards a constant function. In this paper, we present a novel algorithm called Hessian semi-supervised ELM (HSS-ELM) to enhance the semi-supervised learning of ELM. Unlike the Laplacian regularization, the Hessian regularization that favors functions whose values vary linearly along the geodesic distance and preserves the local manifold structure well. This leads to good extrapolating power. Furthermore, HSS-ELM maintains almost all the advantages of the traditional ELM such as the significant training efficiency and straight forward implementation for multiclass classification problems. The proposed algorithm is tested on publicly available data sets. The experimental results demonstrate that our proposed algorithm is competitive with the state-of-the-art semi-supervised learning algorithms in term of accuracy. Additionally, HSS-ELM requires remarkably less training time compared to semi-supervised SVMs/regularized least-squares methods.
ER  - 

TY  - JOUR
T1  - ELMVIS+: Fast nonlinear visualization technique based on cosine distance and extreme learning machines
JO  - Neurocomputing
VL  - 205
IS  - 
SP  - 247
EP  - 263
PY  - 2016/9/12/
T2  - 
AU  - Akusok, Anton
AU  - Baek, Stephen
AU  - Miche, Yoan
AU  - BjÃ¶rk, Kaj-Mikael
AU  - Nian, Rui
AU  - Lauren, Paula
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.04.039
UR  - https://www.sciencedirect.com/science/article/pii/S092523121630306X
KW  - Visualization
KW  - Nonlinear Dimensionality Reduction
KW  - Cosine Distance
KW  - Extreme Learning Machines
KW  - Big Data
KW  - Projection
AB  - Abstract
This paper presents a fast algorithm and an accelerated toolbox11
https://github.com/akusok/elmvis
 for data visualization. The visualization is stated as an assignment problem between data samples and the same number of given visualization points. The mapping function is approximated by an Extreme Learning Machine, which provides an error for a current assignment. This work presents a new mathematical formulation of the error function based on cosine similarity. It provides a closed form equation for a change of error for exchanging assignments between two random samples (called a swap), and an extreme speed-up over the original method even for a very large corpus like the MNIST Handwritten Digits dataset. The method starts from random assignment, and continues in a greedy optimization algorithm by randomly swapping pairs of samples, keeping the swaps that reduce the error. The toolbox speed reaches a million of swaps per second, and thousands of model updates per second for successful swaps in GPU implementation, even for very large dataset like MNIST Handwritten Digits.
ER  - 

TY  - JOUR
T1  - Extreme learning machine and adaptive sparse representation for image classification
JO  - Neural Networks
VL  - 81
IS  - 
SP  - 91
EP  - 102
PY  - 2016/9//
T2  - 
AU  - Cao, Jiuwen
AU  - Zhang, Kai
AU  - Luo, Minxia
AU  - Yin, Chun
AU  - Lai, Xiaoping
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2016.06.001
UR  - https://www.sciencedirect.com/science/article/pii/S0893608016300673
KW  - Extreme learning machine
KW  - Sparse representation
KW  - Image classification
KW  - Leave-one-out cross validation
AB  - Abstract
Recent research has shown the speed advantage of extreme learning machine (ELM) and the accuracy advantage of sparse representation classification (SRC) in the area of image classification. Those two methods, however, have their respective drawbacks, e.g., in general, ELM is known to be less robust to noise while SRC is known to be time-consuming. Consequently, ELM and SRC complement each other in computational complexity and classification accuracy. In order to unify such mutual complementarity and thus further enhance the classification performance, we propose an efficient hybrid classifier to exploit the advantages of ELM and SRC in this paper. More precisely, the proposed classifier consists of two stages: first, an ELM network is trained by supervised learning. Second, a discriminative criterion about the reliability of the obtained ELM output is adopted to decide whether the query image can be correctly classified or not. If the output is reliable, the classification will be performed by ELM; otherwise the query image will be fed to SRC. Meanwhile, in the stage of SRC, a sub-dictionary that is adaptive to the query image instead of the entire dictionary is extracted via the ELM output. The computational burden of SRC thus can be reduced. Extensive experiments on handwritten digit classification, landmark recognition and face recognition demonstrate that the proposed hybrid classifier outperforms ELM and SRC in classification accuracy with outstanding computational efficiency.
ER  - 

TY  - JOUR
T1  - Comparative analysis of reference evapotranspiration equations modelling by extreme learning machine
JO  - Computers and Electronics in Agriculture
VL  - 127
IS  - 
SP  - 56
EP  - 63
PY  - 2016/9//
T2  - 
AU  - Gocic, Milan
AU  - PetkoviÄ, Dalibor
AU  - Shamshirband, Shahaboddin
AU  - Kamsin, Amirrudin
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2016.05.017
UR  - https://www.sciencedirect.com/science/article/pii/S016816991630309X
KW  - Reference evapotranspiration
KW  - Estimating
KW  - Limited weather data
KW  - Extreme learning machine
KW  - Serbia
AB  - Abstract
This study presents an extreme learning machine (ELM) approach, for estimating monthly reference evapotranspiration (ET0) in two weather stations in Serbia (Nis and Belgrade stations), for a 31-year period (1980â2010). The data set including minimum and maximum air temperatures, actual vapour pressure, wind speed and sunshine hours was employed for modelling ET0 using the adjusted Hargreaves (ET0,AHARG), PriestleyâTaylor (ET0,PT) and Turc (ET0,T) equations. The reliability of the computational model was accessed based on simulation results and using five statistical tests including mean absolute percentage error (MAPE), mean absolute deviation (MAD), root-mean-square error (RMSE), Pearson correlation coefficient (r) and coefficient of determination (R2). The validity of ELM modelled ET0 are compared with the FAO-56 PenmanâMonteith equation (ET0,PM) which is used as the reference model. For the Belgrade and Nis stations, the ET0,AHARG ELM model with MAPE = 9.353 and 10.299%, MAD = 0.142 and 0.151 mm/day, RMSE = 0.180 and 0.192 mm/day, r = 0.994 and 0.992, R2 = 0.988 and 0.984 in testing period, was found to be superior in modelling monthly ET0 than the other models, respectively.
ER  - 

TY  - JOUR
T1  - A sparse extreme learning machine framework by continuous optimization algorithms and its application in pattern recognition
JO  - Engineering Applications of Artificial Intelligence
VL  - 53
IS  - 
SP  - 176
EP  - 189
PY  - 2016/8//
T2  - 
AU  - Yang, Liming
AU  - Zhang, Siyun
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2016.04.003
UR  - https://www.sciencedirect.com/science/article/pii/S0952197616300707
KW  - Extreme learning machine
KW  - Zero-norm
KW  - DC programming
KW  - Exact penalty technique
KW  - Least absolute deviation
KW  - Hardness of licorice seeds
AB  - Abstract
Extreme learning machine (ELM) has demonstrated great potential in machine learning owing to its simplicity, rapidity and good generalization performance. In this investigation, based on least-squares estimate (LSE) and least absolute deviation (LAD), we propose four sparse ELM formulations with zero-norm regularization to automatically choose the optimal hidden nodes. Furthermore, we develop two continuous optimization methods to solve the proposed problems respectively. The first is DC (difference of convex functions) approximation approach that approximates the zero-norm by a DC function, and the resulting optimizations are posed as DC programs. The second is an exact penalty technique for zero-norm, and the resulting problems are reformulated as DC programs, and the corresponding DCAs converge finitely. Moreover, the proposed framework is applied directly to recognize the hardness of licorice seeds using near-infrared spectral data. Experiments in different spectral regions illustrate that the proposed approaches can reduce the number of hidden nodes (or output features), while either improve or show no significant difference in generalization compared with the traditional ELM methods and support vector machine (SVM). Experiments on several benchmark data sets demonstrate that the proposed framework is competitive with the traditional approaches in generalization, but selects fewer output features.
ER  - 

TY  - JOUR
T1  - Parsimonious kernel extreme learning machine in primal via Cholesky factorization
JO  - Neural Networks
VL  - 80
IS  - 
SP  - 95
EP  - 109
PY  - 2016/8//
T2  - 
AU  - Zhao, Yong-Ping
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2016.04.009
UR  - https://www.sciencedirect.com/science/article/pii/S0893608016300399
KW  - Extreme learning machine
KW  - Kernel method
KW  - Parsimoniousness
KW  - Constructive algorithm
KW  - Destructive algorithm
AB  - Abstract
Recently, extreme learning machine (ELM) has become a popular topic in machine learning community. By replacing the so-called ELM feature mappings with the nonlinear mappings induced by kernel functions, two kernel ELMs, i.e., P-KELM and D-KELM, are obtained from primal and dual perspectives, respectively. Unfortunately, both P-KELM and D-KELM possess the dense solutions in direct proportion to the number of training data. To this end, a constructive algorithm for P-KELM (CCP-KELM) is first proposed by virtue of Cholesky factorization, in which the training data incurring the largest reductions on the objective function are recruited as significant vectors. To reduce its training cost further, PCCP-KELM is then obtained with the application of a probabilistic speedup scheme into CCP-KELM. Corresponding to CCP-KELM, a destructive P-KELM (CDP-KELM) is presented using a partial Cholesky factorization strategy, where the training data incurring the smallest reductions on the objective function after their removals are pruned from the current set of significant vectors. Finally, to verify the efficacy and feasibility of the proposed algorithms in this paper, experiments on both small and large benchmark data sets are investigated.
ER  - 

TY  - JOUR
T1  - Meta-cognitive online sequential extreme learning machine for imbalanced and concept-drifting data classification
JO  - Neural Networks
VL  - 80
IS  - 
SP  - 79
EP  - 94
PY  - 2016/8//
T2  - 
AU  - Mirza, Bilal
AU  - Lin, Zhiping
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2016.04.008
UR  - https://www.sciencedirect.com/science/article/pii/S0893608016300387
KW  - Multi-class imbalance
KW  - Concept drift
KW  - Extreme learning machine
KW  - Meta-cognition
KW  - Sequential learning
AB  - Abstract
In this paper, a meta-cognitive online sequential extreme learning machine (MOS-ELM) is proposed for class imbalance and concept drift learning. In MOS-ELM, meta-cognition is used to self-regulate the learning by selecting suitable learning strategies for class imbalance and concept drift problems. MOS-ELM is the first sequential learning method to alleviate the imbalance problem for both binary class and multi-class data streams with concept drift. In MOS-ELM, a new adaptive window approach is proposed for concept drift learning. A single output update equation is also proposed which unifies various application specific OS-ELM methods. The performance of MOS-ELM is evaluated under different conditions and compared with methods each specific to some of the conditions. On most of the datasets in comparison, MOS-ELM outperforms the competing methods.
ER  - 

TY  - JOUR
T1  - An Extreme Learning Machine based on Cellular Automata of edge detection for remote sensing images
JO  - Neurocomputing
VL  - 198
IS  - 
SP  - 27
EP  - 34
PY  - 2016/7/19/
T2  - Advances in Neural Networks, Intelligent Control and Information ProcessingContaining a selection of papers from the 5th International Conference on Intelligent Control and Information Processing (ICICIP2014)
AU  - Han, Min
AU  - Yang, Xue
AU  - Jiang, Enda
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.08.121
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216003209
KW  - Remote sensing image
KW  - Edge detection
KW  - Extreme Learning Machine
KW  - Cellular Automata
AB  - Abstract
For remote sensing images, whose spectral signatures are intricate, the traditional edge detection methods cannot obtain satisfactory results. This paper takes the space computing capacity of Cellular Automata (CA) and the data pattern search ability of Extreme Learning Machine (ELM) into account and puts forward an Extreme Learning Machine based on Cellular Automata (ELM-CA) of edge detection for remote sensing images. This model can extract evolution rules of Cellular Automata. On the basis of the rules, false edges are removed and purer edge map is obtained. The result of the simulation experiment shows that the performance of the method suggested by this paper is much better compared to other edge detection arithmetic operators. It can prove that ELM-CA is an ideal method of remote sensing image edge detection.
ER  - 

TY  - JOUR
T1  - Preliminary study on Wilcoxon-norm-based robust extreme learning machine
JO  - Neurocomputing
VL  - 198
IS  - 
SP  - 20
EP  - 26
PY  - 2016/7/19/
T2  - Advances in Neural Networks, Intelligent Control and Information ProcessingContaining a selection of papers from the 5th International Conference on Intelligent Control and Information Processing (ICICIP2014)
AU  - Xie, Xiao-Liang
AU  - Bian, Gui-Bin
AU  - Hou, Zeng-Guang
AU  - Feng, Zhen-Qiu
AU  - Hao, Jian-Long
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.12.113
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216003234
KW  - Extreme learning machine
KW  - Wilcoxon neural network
KW  - Wilcoxon-norm based robust extreme learning machine
AB  - Abstract
The fact that the linear estimators using the rank-based Wilcoxon approach in linear regression problems are usually insensitive to outliers is known in statistics. Outliers are the data points that differ greatly from the pattern set by the bulk of the data. Inspired by this fact, Hsieh et al. introduced the Wilcoxon approach into the area of machine learning. They investigated four new learning machines, such as Wilcoxon neural network (WNN), and developed four gradient descent based backpropagation algorithms to train these learning machines. The performances of these machines are better than ordinary nonrobust neural networks in outliers exist tasks. However, it is hard to balance the learning speed and the stability of these algorithms which is inherently the drawback of gradient descent based algorithms. In this paper, a new algorithm is used to train the output weights of single-layer feedforward neural networks (SLFN) with input weights and biases being randomly chosen. This algorithm is called Wilcoxon-norm based robust extreme learning machine or WRELM for short.
ER  - 

TY  - JOUR
T1  - A new pruning method for extreme learning machines via genetic algorithms
JO  - Applied Soft Computing
VL  - 44
IS  - 
SP  - 101
EP  - 107
PY  - 2016/7//
T2  - 
AU  - Alencar, Alisson S.C.
AU  - Rocha Neto, Ajalmar R.
AU  - Gomes, JoÃ£o Paulo P.
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2016.03.019
UR  - https://www.sciencedirect.com/science/article/pii/S1568494616301284
KW  - Extreme learning machines
KW  - Pruning methods
KW  - Genetic algorithms
AB  - Abstract
Extreme learning machine (ELM) is a recently proposed learning algorithm for single hidden layer feedfoward neural networks (SLFN) that achieved remarkable performances in various applications. In ELM, the hidden neurons are randomly assigned and the output layer weights are learned in a single step using the Moore-Penrose generalized inverse. This approach results in a fast learning neural network algorithm with a single hyperparameter (the number of hidden neurons). Despite the aforementioned advantages, using ELM can result in models with a large number of hidden neurons and this can lead to poor generalization. To overcome this drawback, we propose a novel method to prune hidden layer neurons based on genetic algorithms (GA). The proposed approach, referred as GAP-ELM, selects subset of the hidden neurons to optimize a multiobjective fitness function that defines a compromise between accuracy and the number of pruned neurons. The performance of GAP-ELM is assessed on several real world datasets and compared to other SLFN and a well known pruning method called Optimally Pruned ELM (OP-ELM). On the basis of our experiments, we can state that GAP-ELM is a valid alternative for classification tasks.
ER  - 

TY  - JOUR
T1  - Adaptive control of rapidly time-varying discrete-time system using initial-training-free online extreme learning machine
JO  - Neurocomputing
VL  - 194
IS  - 
SP  - 117
EP  - 125
PY  - 2016/6/19/
T2  - 
AU  - Gao, Xiang Hui
AU  - Wong, Ka In
AU  - Wong, Pak Kin
AU  - Vong, Chi Man
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.01.071
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216002319
KW  - Adaptive control
KW  - System identification
KW  - Time-varying discrete systems
KW  - Machine learning
AB  - Abstract
While multiple model adaptive control (MMAC) scheme provides a solution to systems with unknown and rapidly time-varying parameters, many offline samples must be obtained beforehand, and the number of models is difficult to be found if no prior knowledge is given. This paper proposes a new adaptive control strategy to handle such systems. The principle is to use a change detection mechanism to check if there is an abrupt change, and immediately train a new model if a change is detected. A novel online identification algorithm, namely initial-training-free online extreme learning machine (ITF-OELM), is also proposed to allow the model to be trained anytime without concerns on prior data. With this strategy, only one model is necessary as compared to MMAC, resulting in reduction on computational complexity and memory usage. Simulation results show that the proposed strategy is effective. Besides, although the use of forgetting factor in ITF-OELM can accelerate the convergence speed for system identification, sometimes it may lead to ill-conditioned covariance matrix in the recursively updating process. This paper shows that such issue can be solved by the change detection mechanism.
ER  - 

TY  - JOUR
T1  - Efficient Leave-One-Out Cross-Validation-based Regularized Extreme Learning Machine
JO  - Neurocomputing
VL  - 194
IS  - 
SP  - 260
EP  - 270
PY  - 2016/6/19/
T2  - 
AU  - Shao, Zhifei
AU  - Er, Meng Joo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.02.058
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216003052
KW  - Extreme Learning Machine (ELM)
KW  - Regularized ELM (RELM)
KW  - Ridge regression
KW  - LOO-CV
KW  - Leave-One-Out Cross-Validation
AB  - Abstract
It is well known that the Leave-One-Out Cross-Validation (LOO-CV) is a highly reliable procedure in terms of model selection. Unfortunately, it is an extremely tedious method and has rarely been deployed in practical applications. In this paper, a highly efficient Leave-One-Out Cross-Validation (LOO-CV) formula has been developed and integrated with the popular Regularized Extreme Learning Machine (RELM). The main contribution of this paper is the proposed algorithm, termed as Efficient LOO-CV-based RELM (ELOO-RELM), that can effectively and efficiently update the LOO-CV error with every regularization parameter and automatically select the optimal model with limited user intervention. Rigorous analysis of computational complexity shows that the ELOO-RELM, including the tuning process, can achieve similar efficiency as the original RELM with pre-defined parameter, in which both scale linearly with the size of the training data. An early termination criterion is also introduced to further speed up the learning process. Experimentation studies on benchmark datasets show that the ELOO-RELM can achieve comparable generalization performance as the Support Vector Machines (SVM) with significantly higher learning efficiency. More importantly, comparing to the trial and error tuning procedure employed by the original RELM, the ELOO-RELM can provide more reliable results by the virtue of incorporating the LOO-CV procedure.
ER  - 

TY  - JOUR
T1  - Incomplete data classification with voting based extreme learning machine
JO  - Neurocomputing
VL  - 193
IS  - 
SP  - 167
EP  - 175
PY  - 2016/6/12/
T2  - 
AU  - Yan, Yuan-Ting
AU  - Zhang, Yan-Ping
AU  - Chen, Jie
AU  - Zhang, Yi-Wen
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.01.068
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216001855
KW  - Incomplete data
KW  - Extreme learning machine
KW  - Mutual information
KW  - Data subset
KW  - Weighted majority voting
AB  - Abstract
Extreme learning machine (ELM) was proposed as a new efficient learning algorithm for single-hidden layer feedforward neural networks (SLFN) in recent years. It is featured by its much faster training speed and better generalization performance over traditional SLFN learning techniques. However, ELM cannot deal directly with incomplete data which widely exists in real-world applications. In this paper, we propose a new algorithm to handle incomplete data with voting based extreme learning machine (V-ELMI). V-ELMI did not rely on any assumptions about missing values. It first obtains a group of data subsets according to the missing values of the training set. Then, it applies mutual information to measure the importance degree of each data subsets. After that, it trains a group of subclassifiers on these data subsets by applying ELM as base learning algorithm. Finally, for a given test sample with missing values, V-ELMI selects the subclassifiers whose input did not require the missing values to predict it. And final prediction is determined by weighted majority voting according to the mean value of the norms of the output weights and the importance degree of each available subclassifier. Experimental results on 15 UCI incomplete datasets and 5 UCI complete datasets have shown that, V-ELMI generally has better performance than the algorithms compared. Moreover, compared with the classification algorithms based on neural network ensemble (NNE), V-ELMI can greatly improve algorithm computational efficiency.
ER  - 

TY  - JOUR
T1  - Forecasting electricity load by a novel recurrent extreme learning machines approach
JO  - International Journal of Electrical Power & Energy Systems
VL  - 78
IS  - 
SP  - 429
EP  - 435
PY  - 2016/6//
T2  - 
AU  - Ertugrul, Ãmer Faruk
SN  - 0142-0615
DO  - https://doi.org/10.1016/j.ijepes.2015.12.006
UR  - https://www.sciencedirect.com/science/article/pii/S0142061515005578
KW  - Recurrent extreme learning machine
KW  - Electricity load forecasting
KW  - Recurrent neural network
KW  - Context neuron
AB  - Abstract
Growth in electricity demand also gives a rise to the necessity of cheaper and safer electric supply and forecasting electricity load plays a key role in this goal. In this study recurrent extreme learning machine (RELM) was proposed as a novel approach to forecast electricity load more accurately. In RELM, extreme learning machine (ELM), which is a training method for single hidden layer feed forward neural network, was adapted to train a single hidden layer Jordan recurrent neural network. Electricity Load Diagrams 2011â2014 dataset was employed to evaluate and validate the proposed approach. Obtained results were compared with traditional ELM, linear regression, generalized regression neural network and some other popular machine learning methods. Achieved root mean square errors (RMSE) by RELM were nearly twice less than obtained results by other employed machine learning methods. The results showed that the recurrent type ANNs had extraordinary success in forecasting dynamic systems and also time-ordered datasets with comparison to feed forward ANNs. Also, used time in the training stage is similar to ELM and they are extremely fast than the others. This study showed that the proposed approach can be applied to forecast electricity load and RELM has high potential to be utilized in modeling dynamic systems effectively.
ER  - 

TY  - JOUR
T1  - Using self-adaptive evolutionary algorithm to improve the performance of an extreme learning machine for estimating soil temperature
JO  - Computers and Electronics in Agriculture
VL  - 124
IS  - 
SP  - 150
EP  - 160
PY  - 2016/6//
T2  - 
AU  - Nahvi, Behnaz
AU  - Habibi, Jafar
AU  - Mohammadi, Kasra
AU  - Shamshirband, Shahaboddin
AU  - Al Razgan, Othman Saleh
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2016.03.025
UR  - https://www.sciencedirect.com/science/article/pii/S0168169916300977
KW  - Soil temperature
KW  - Extreme Learning Machine (ELM)
KW  - Self-Adaptive Evolutionary Extreme Learning Machine (SaE-ELM)
KW  - Estimation
KW  - Agent
AB  - Abstract
In this study, the self-adaptive evolutionary (SaE) agent is employed to structure the contributing elements to process the management of extreme learning machine (ELM) architecture based on a logical procedure. In fact, the SaE algorithm is utilized for possibility of enhancing the performance of the ELM to estimate daily soil temperature (ST) at 6 different depths of 5, 10, 20, 30, 50 and 100 cm. In the developed SaE-ELM model, the network hidden node parameters of the ELM are optimized using SaE algorithm. The precision of the SaE-ELM is then compared with the ELM model. Daily weather data sets including minimum, maximum and average air temperatures (Tmin, Tmax and Tavg), atmospheric pressure (P) and global solar radiation (RS) collected for two Iranian stations of Bandar Abbas and Kerman with different climate conditions have been utilized. After primary evaluation, Tmin, Tmax and Tavg are considered as final inputs for the ELM and SaE-ELM models due to their high correlations with ST at all depths. The achieved results for both stations reveal that both ELM and SaE-ELM models offer desirable performance to estimate daily ST at all depths; nevertheless, a slightly more precision can be obtained by the SaE-ELM model. The performance of the ELM and SaE-ELM models are verified against genetic programming (GP) and artificial neural network (ANN) models developed in this study. For Bandar Abbass station, the obtained mean absolute bias error (MABE) and correlation coefficient (R) for the ELM model at different depths are in the range of 0.9116â1.5988 Â°C and 0.9023â0.9840, respectively while for the SaE-ELM model they are in the range of 0.8660â1.5338 Â°C and 0.9084â0.9893, respectively. In addition, for Kerman Station the attained MABE and RMSE for the ELM model vary from 1.6567 to 2.4233 Â°C and 0.8661 to 0.9789, respectively while for the SaE-ELM model they vary from 1.5818 to 2.3422 Â°C and 0.8736 to 0.9831, respectively.
ER  - 

TY  - JOUR
T1  - Improvements on parsimonious extreme learning machine using recursive orthogonal least squares
JO  - Neurocomputing
VL  - 191
IS  - 
SP  - 82
EP  - 94
PY  - 2016/5/26/
T2  - 
AU  - Zhao, Yong-Ping
AU  - Huerta, RamÃ³n
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2016.01.005
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216000527
KW  - Single-hidden-layer feedforward network
KW  - Extreme learning machine
KW  - Givens rotation
KW  - Householder transformation
AB  - Abstract
Recently novel constructive and destructive parsimonious extreme learning machines (CP-ELM and DP-ELM) arose to cope with regression problems. With these foundations, several improvements on CP-ELM and DP-ELM are suggested. CP-ELM can be improved by replacing the Givens rotation with the Householder transformation, yielding the improved CP-ELM (ICP-ELM) which results in the acceleration of the training speed without hampering the generalization performance. Subsequently, a hybrid constructiveâdestructive ELM (CDP-ELM) is generated integrating elements from CP-ELM and DP-ELM. The goal is to combine the advantages of training speed and parsimony from CP-ELM and DP-ELM. Finally, experiments on regression data sets and a real-world system identification of robot arm example are done to test the feasibility and efficacy of these variants including ICP-ELM and CDP-ELM.
ER  - 

TY  - JOUR
T1  - Mixed-kernel based weighted extreme learning machine for inertial sensor based human activity recognition with imbalanced dataset
JO  - Neurocomputing
VL  - 190
IS  - 
SP  - 35
EP  - 49
PY  - 2016/5/19/
T2  - 
AU  - Wu, Donghui
AU  - Wang, Zhelong
AU  - Chen, Ye
AU  - Zhao, Hongyu
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.11.095
UR  - https://www.sciencedirect.com/science/article/pii/S0925231216000072
KW  - Human activity recognition
KW  - Imbalanced dataset
KW  - Weighted extreme learning machine
KW  - Inertial sensors
KW  - Mixed kernel
AB  - Abstract
Balanced dataset has been utilized by the previous human activity recognition algorithms to train the classifier. However, imbalanced dataset are ubiquitous in human activity recognition, especially in the case of abnormal activity detection. Though the class imbalance problem exists as a universal phenomenon in human activity recognition, few researches mentioned this problem and solved it. In order to reduce the influence of the imbalance datasets problem, the mixed-kernel based weighted extreme learning machine (MK-WELM) has been proposed in this paper. Considering that the performance of extreme learning machine (ELM) is greatly influenced by the choice of kernel, the mixed kernel method is proposed for ELM. In order to deal with the imbalanced problem, the cost sensitive method is utilized. The main idea of the cost sensitive method is that the cost of minority class increases with the misclassification rate. Considering the cost sensitive function and the mixed kernel method, the MK-WELM is constructed. Comparing with ELM and weighted ELM methods, experimental results over different human activity datasets demonstrate the effectiveness of the proposed method.
ER  - 

TY  - JOUR
T1  - Online fitted policy iteration based on extreme learning machines
JO  - Knowledge-Based Systems
VL  - 100
IS  - 
SP  - 200
EP  - 211
PY  - 2016/5/15/
T2  - 
AU  - Escandell-Montero, Pablo
AU  - Lorente, Delia
AU  - MartÃ­nez-MartÃ­nez, JosÃ© M.
AU  - Soria-Olivas, Emilio
AU  - Vila-FrancÃ©s, Joan
AU  - MartÃ­n-Guerrero, JosÃ© D.
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2016.03.007
UR  - https://www.sciencedirect.com/science/article/pii/S0950705116001209
KW  - Reinforcement learning
KW  - Sequential decision-making
KW  - Fitted policy iteration
KW  - Extreme learning machine
AB  - Abstract
Reinforcement learning (RL) is a learning paradigm that can be useful in a wide variety of real-world applications. However, its applicability to complex problems remains problematic due to different causes. Particularly important among these are the high quantity of data required by the agent to learn useful policies and the poor scalability to high-dimensional problems due to the use of local approximators. This paper presents a novel RL algorithm, called online fitted policy iteration (OFPI), that steps forward in both directions. OFPI is based on a semi-batch scheme that increases the convergence speed by reusing data and enables the use of global approximators by reformulating the value function approximation as a standard supervised problem. The proposed method has been empirically evaluated in three benchmark problems. During the experiments, OFPI has employed a neural network trained with the extreme learning machine algorithm to approximate the value functions. Results have demonstrated the stability of OFPI using a global function approximator and also performance improvements over two baseline algorithms (SARSA and Q-learning) combined with eligibility traces and a radial basis function network.
ER  - 

TY  - JOUR
T1  - Critical Clearing Time prediction within various loads for transient stability assessment by means of the Extreme Learning Machine method
JO  - International Journal of Electrical Power & Energy Systems
VL  - 77
IS  - 
SP  - 345
EP  - 352
PY  - 2016/5//
T2  - 
AU  - Sulistiawati, Irrine Budi
AU  - Priyadi, Ardyono
AU  - Qudsi, Ony Asrarul
AU  - Soeprijanto, Adi
AU  - Yorino, Naoto
SN  - 0142-0615
DO  - https://doi.org/10.1016/j.ijepes.2015.11.034
UR  - https://www.sciencedirect.com/science/article/pii/S0142061515004548
KW  - Critical Clearing Time (CCT)
KW  - Transient Stability Assessment (TSA)
KW  - ELM (Extreme Learning Machine)
KW  - Critical trajectory
KW  - Load changing
AB  - Abstract
The Critical Clearing Time (CCT) is a key issue for Transient Stability Assessment (TSA) in electrical power system operation, security, and maintenance. However, there are some difficulties in obtaining the CCT, which include the accuracy, fast computation, and robustness for TSA online. Therefore, obtaining the CCT is still an interesting topic for investigation. This paper proposes a new technique for obtaining CCT based on numerical calculations and artificial intelligence techniques. First, the CCT is calculated by the critical trajectory method based on critical generation. Second, the CCT is learned by Extreme Learning Machine (ELM). This proposed method has the ability to obtain the CCT with load changes, different fault occurrences, accuracy, and fast computation, and considering the controller. This proposed method is tested by the IEEE 3-machine 9-bus system and Java-Bali 500 kV 54-machine 25-bus system. The proposed method can provide accurate CCTs with an average error of 0.33% for the Neural Network (NN) method and an average error of 0.06% for the ELM method. The simulation result also shows that this method is a robust algorithm that can address several load changes and different locations of faults occurring. There are 29 load changes used to obtain the CCT, with 20 load changes included for the training process and 9 load changes not included.
ER  - 

TY  - JOUR
T1  - A Fast SVD-Hidden-nodes based Extreme Learning Machine for Large-Scale Data Analytics
JO  - Neural Networks
VL  - 77
IS  - 
SP  - 14
EP  - 28
PY  - 2016/5//
T2  - 
AU  - Deng, Wan-Yu
AU  - Bai, Zuo
AU  - Huang, Guang-Bin
AU  - Zheng, Qing-Hua
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2015.09.003
UR  - https://www.sciencedirect.com/science/article/pii/S0893608015001781
KW  - Extreme Learning Machine
KW  - Singular value decomposition
KW  - Big data
KW  - Big dimensional data
KW  - Fast approximation method
AB  - Abstract
Big dimensional data is a growing trend that is emerging in many real world contexts, extending from web mining, gene expression analysis, proteinâprotein interaction to high-frequency financial data. Nowadays, there is a growing consensus that the increasing dimensionality poses impeding effects on the performances of classifiers, which is termed as the âpeaking phenomenonâ in the field of machine intelligence. To address the issue, dimensionality reduction is commonly employed as a preprocessing step on the Big dimensional data before building the classifiers. In this paper, we propose an Extreme Learning Machine (ELM) approach for large-scale data analytic. In contrast to existing approaches, we embed hidden nodes that are designed using singular value decomposition (SVD) into the classical ELM. These SVD nodes in the hidden layer are shown to capture the underlying characteristics of the Big dimensional data well, exhibiting excellent generalization performances. The drawback of using SVD on the entire dataset, however, is the high computational complexity involved. To address this, a fast divide and conquer approximation scheme is introduced to maintain computational tractability on high volume data. The resultant algorithm proposed is labeled here as Fast Singular Value Decomposition-Hidden-nodes based Extreme Learning Machine or FSVD-H-ELM in short. In FSVD-H-ELM, instead of identifying the SVD hidden nodes directly from the entire dataset, SVD hidden nodes are derived from multiple random subsets of data sampled from the original dataset. Comprehensive experiments and comparisons are conducted to assess the FSVD-H-ELM against other state-of-the-art algorithms. The results obtained demonstrated the superior generalization performance and efficiency of the FSVD-H-ELM.
ER  - 

TY  - JOUR
T1  - Extreme learning machine for out-of-sample extension in Laplacian eigenmaps
JO  - Pattern Recognition Letters
VL  - 74
IS  - 
SP  - 68
EP  - 73
PY  - 2016/4/15/
T2  - 
AU  - Mendoza Quispe, Arturo
AU  - Petitjean, Caroline
AU  - Heutte, Laurent
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2016.01.024
UR  - https://www.sciencedirect.com/science/article/pii/S0167865516000362
KW  - Dimensionality reduction
KW  - Manifold learning
KW  - Laplacian eigenmaps
KW  - Out-of-sample extension
KW  - Extreme learning machine
AB  - Abstract
Manifold learning techniques have shown a great potential for computer vision problems; however, they do not extend easily to points different from the ones on which they were trained (out-of-sample). On the other hand, extreme learning machine (ELM) is a powerful method that allows to perform nonlinear, multivariate regression. This paper discusses the effectiveness of ELM for the out-of-sample problem and compares it to the state-of-the-art solution : the NystrÃ¶m extension. Both methods are evaluated through the reconstruction of the manifold learnt using Laplacian eigenmaps, via experiments on a wide range of publicly available image datasets. We show that when reducing the data dimension to its intrinsic dimension, the ELM offers a better approximation of the embedded coordinates, also with reduced computational costs during testing.
ER  - 

TY  - JOUR
T1  - An efficient hybrid kernel extreme learning machine approach for early diagnosis of Parkinson×³s disease
JO  - Neurocomputing
VL  - 184
IS  - 
SP  - 131
EP  - 144
PY  - 2016/4/5/
T2  - RoLoD: Robust Local Descriptors for Computer Vision 2014
AU  - Chen, Hui-Ling
AU  - Wang, Gang
AU  - Ma, Chao
AU  - Cai, Zhen-Nao
AU  - Liu, Wen-Bin
AU  - Wang, Su-Jing
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.07.138
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215019001
KW  - Kernel extreme learning machine
KW  - Feature selection
KW  - Medical diagnosis
KW  - Parkinson×³s disease
AB  - Abstract
In this paper, we explore the potential of extreme learning machine (ELM) and kernel ELM (KELM) for early diagnosis of Parkinsonâs disease (PD). In the proposed method, the key parameters including the number of hidden neuron and type of activation function in ELM, and the constant parameter C and kernel parameter Î³ in KELM are investigated in detail. With the obtained optimal parameters, ELM and KELM manage to train the optimal predictive models for PD diagnosis. In order to further improve the performance of ELM and KELM models, feature selection techniques are implemented prior to the construction of the classification models. The effectiveness of the proposed method has been rigorously evaluated against the PD data set in terms of classification accuracy, sensitivity, specificity and the area under the ROC (receiver operating characteristic) curve (AUC). Compared to the existing methods in previous studies, the proposed method has achieved very promising classification accuracy via 10-fold cross-validation (CV) analysis, with the highest accuracy of 96.47% and average accuracy of 95.97% over 10 runs of 10-fold CV.
ER  - 

TY  - JOUR
T1  - Hardware implementation of real-time Extreme Learning Machine in FPGA: Analysis of precision, resource occupation and performance
JO  - Computers & Electrical Engineering
VL  - 51
IS  - 
SP  - 139
EP  - 156
PY  - 2016/4//
T2  - 
AU  - Frances-Villora, Jose V.
AU  - Rosado-MuÃ±oz, A.
AU  - MartÃ­nez-Villena, JosÃ© M.
AU  - Bataller-Mompean, Manuel
AU  - Guerrero, Juan Fco.
AU  - Wegrzyn, Marek
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2016.02.007
UR  - https://www.sciencedirect.com/science/article/pii/S0045790616300222
KW  - FPGA
KW  - Extreme Learning Machine - ELM
KW  - Neural network training
KW  - Neural network hardware
KW  - On-chip machine learning
KW  - Embedded systems
AB  - Abstract
Extreme Learning Machine (ELM) proposes a non-iterative training method for Single Layer Feedforward Neural Networks that provides an effective solution for classification and prediction problems. Its hardware implementation is an important step towards fast, accurate and reconfigurable embedded systems based on neural networks, allowing to extend the range of applications where neural networks can be used, especially where frequent and fast training, or even real-time training, is required. This work proposes three hardware architectures for on-chip ELM training computation and implementation, a sequential and two parallel. All three are implemented parameterizably on FPGA as an IP (Intellectual Property) core. Results describe performance, accuracy, resources and power consumption. The analysis is conducted parametrically varying the number of hidden neurons, number of training patterns and internal bit-length, providing a guideline on required resources and level of performance that an FPGA based ELM training can provide.
ER  - 

TY  - JOUR
T1  - A Fast Reduced Kernel Extreme Learning Machine
JO  - Neural Networks
VL  - 76
IS  - 
SP  - 29
EP  - 38
PY  - 2016/4//
T2  - 
AU  - Deng, Wan-Yu
AU  - Ong, Yew-Soon
AU  - Zheng, Qing-Hua
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2015.10.006
UR  - https://www.sciencedirect.com/science/article/pii/S0893608015002063
KW  - Extreme learning machine
KW  - Kernel method
KW  - Support vector machine
KW  - RBF network
AB  - Abstract
In this paper, we present a fast and accurate kernel-based supervised algorithm referred to as the Reduced Kernel Extreme Learning Machine (RKELM). In contrast to the work on Support Vector Machine (SVM) or Least Square SVM (LS-SVM), which identifies the support vectors or weight vectors iteratively, the proposed RKELM randomly selects a subset of the available data samples as support vectors (or mapping samples). By avoiding the iterative steps of SVM, significant cost savings in the training process can be readily attained, especially on Big datasets. RKELM is established based on the rigorous proof of universal learning involving reduced kernel-based SLFN. In particular, we prove that RKELM can approximate any nonlinear functions accurately under the condition of support vectors sufficiency. Experimental results on a wide variety of real world small instance size and large instance size applications in the context of binary classification, multi-class problem and regression are then reported to show that RKELM can perform at competitive level of generalized performance as the SVM/LS-SVM at only a fraction of the computational effort incurred.
ER  - 

TY  - JOUR
T1  - Stochastic gradient based extreme learning machines for stable online learning of advanced combustion engines
JO  - Neurocomputing
VL  - 177
IS  - 
SP  - 304
EP  - 316
PY  - 2016/2/12/
T2  - 
AU  - Janakiraman, Vijay Manikandan
AU  - Nguyen, XuanLong
AU  - Assanis, Dennis
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.11.024
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215017439
KW  - Online learning
KW  - Extreme learning machine
KW  - System identification
KW  - Lyapunov stability
KW  - Engine control
KW  - Operating envelope
AB  - Abstract
We propose and develop SG-ELM, a stable online learning algorithm based on stochastic gradients and Extreme Learning Machines (ELM). We propose SG-ELM particularly for systems that are required to be stable during learning; i.e., the estimated model parameters remain bounded during learning. We use a Lyapunov approach to prove both asymptotic stability of estimation error and boundedness in the model parameters suitable for identification of nonlinear dynamic systems. Using the Lyapunov approach, we determine an upper bound for the learning rate of SG-ELM. The SG-ELM algorithm not only guarantees a stable learning but also reduces the computational demand compared to the recursive least squares based OS-ELM algorithm (Liang et al., 2006). In order to demonstrate the working of SG-ELM on a real-world problem, an advanced combustion engine identification is considered. The algorithm is applied to two case studies: An online regression learning for system identification of a Homogeneous Charge Compression Ignition (HCCI) Engine and an online classification learning (with class imbalance) for identifying the dynamic operating envelope. The case studies demonstrate that the accuracy of the proposed SG-ELM is comparable to that of the OS-ELM approach but adds stability and a reduction in computational effort.
ER  - 

TY  - JOUR
T1  - A Robust Extreme Learning Machine for pattern classification with outliers
JO  - Neurocomputing
VL  - 176
IS  - 
SP  - 3
EP  - 13
PY  - 2016/2/2/
T2  - Recent Advancements in Hybrid Artificial Intelligence Systems and its Application to Real-World ProblemsSelected papers from the HAIS 2013 conference
AU  - Barreto, Guilherme A.
AU  - Barros, Ana Luiza B.P.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.10.095
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215005421
KW  - Extreme Learning Machine
KW  - Ordinary least squares
KW  - Least mean squares
KW  - Robust pattern classification
KW  - Outliers
KW  - M-estimation
AB  - Abstract
In this paper we introduce a simple and efficient extension of the Extreme Learning Machine (ELM) network (Huang et al., 2006 [19]), which is very robust to label noise, a type of outlier occurring in classification tasks. Such outliers usually result from mistakes during labeling of the data points (e.g. misjudgment of a specialist) or from typing errors during creation of data files (e.g. by striking an incorrect key on a keyboard). The proposed variant of the ELM, henceforth named Robust ELM (RELM), is designed using M-estimators to compute the output weights instead of the standard ordinary least squares (OLS) method. We evaluate the performance of the RELM using batch and recursive learning rules, and also introduce a model selection strategy based on Particle Swarm Optimization (PSO) to find an optimal architecture for datasets contaminated with non-Gaussian noise and outliers. By means of comprehensive computer simulations using synthetic and real-world datasets, we show that the proposed Robust ELM classifiers consistently outperforms the original version.
ER  - 

TY  - JOUR
T1  - An extreme learning machine approach for modeling evapotranspiration using extrinsic inputs
JO  - Computers and Electronics in Agriculture
VL  - 121
IS  - 
SP  - 385
EP  - 392
PY  - 2016/2//
T2  - 
AU  - Patil, Amit Prakash
AU  - Deka, Paresh Chandra
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2016.01.016
UR  - https://www.sciencedirect.com/science/article/pii/S0168169916000211
KW  - Evapotranspiration
KW  - Limited data
KW  - Extreme learning machine
KW  - Arid region
KW  - Least square support vector machine
AB  - Abstract
Precise estimation of evapotranspiration is crucial for accurate crop-water estimation. Recently machine learning (ML) techniques like artificial neural network (ANN) are being widely used for modeling the process of evapotranspiration. However, ANN faces issues like trapping in local minima, slow learning and tuning of meta-parameters. In this study an improved extreme learning machine (ELM) algorithm was used to estimate weekly reference crop evapotranspiration (ETo). The study was carried out for Jodhpur and Pali meteorological weather stations located in the Thar Desert, India. The study evaluated the performance of three different input combinations. The first input combination used locally available maximum and minimum air temperature data while the second and third combination used ETo values from another station (extrinsic inputs) along with the locally available temperature data as inputs. The performance of ELM models was compared with the empirical Hargreaves equation, ANN and least-square support vector machine (LS-SVM) models. Root mean squared error (RMSE), NashâSutcliffe model efficiency coefficient (NSE) and threshold statistics (TS) were used for comparing the performance of the models. The performance of ELM model was found to be better than the Hargreaves and ANN model. The LS-SVM and ELM displayed similar performance. ELM3 models, with 36 and 33 neurons in hidden layer were found to be the best models (RMSE of 0.43 for Jodhpur and 0.33 for Pali station) for estimating weekly ETo at Jodhpur and Pali stations respectively. The results showed that ELM is a simple yet efficient algorithm which exhibited good performance; hence, can be recommended for estimating weekly ETo. Furthermore, it was also found that use of ETo values from another station can help in improving the efficiency of ML models in limited data scenario.
ER  - 

TY  - JOUR
T1  - Adaptive control algorithm of flexible robotic gripper by extreme learning machine
JO  - Robotics and Computer-Integrated Manufacturing
VL  - 37
IS  - 
SP  - 170
EP  - 178
PY  - 2016/2//
T2  - 
AU  - PetkoviÄ, Dalibor
AU  - Seyed Danesh, Amir
AU  - Dadkhah, Mehdi
AU  - Misaghian, Negin
AU  - Shamshirband, Shahaboddin
AU  - Zalnezhad, Erfan
AU  - PavloviÄ, Nenad D.
SN  - 0736-5845
DO  - https://doi.org/10.1016/j.rcim.2015.09.006
UR  - https://www.sciencedirect.com/science/article/pii/S0736584515000915
KW  - Flexible gripper
KW  - Sensors
KW  - Object detection
KW  - Soft computing
AB  - Abstract
Adaptive grippers should be able to detect and recognize grasping objects. To be able to do it control algorithm need to be established to control gripper tasks. Since the gripper movements are highly nonlinear systems it is desirable to avoid using of conventional control strategies for robotic manipulators. Instead of the conventional control strategies more advances algorithms can be used. In this study several soft computing methods are analyzed for robotic gripper applications. The gripper structure is fully compliant with embedded sensors. The sensors could be used for grasping shape detection. As soft computing methods, extreme learning machine (ELM) and support vector regression (SVR) were established. Also other soft computing methods are analyzed like fuzzy, neuro-fuzzy and artificial neural network approach. The results show the highest accuracy with ELM approach than other soft computing methods.
ER  - 

TY  - JOUR
T1  - Automated detection of epileptic EEGs using a novel fusion feature and extreme learning machine
JO  - Neurocomputing
VL  - 175, Part A
IS  - 
SP  - 383
EP  - 391
PY  - 2016/1/29/
T2  - 
AU  - Song, Jiang-Ling
AU  - Hu, Wenfeng
AU  - Zhang, Rui
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.10.070
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215015295
KW  - Epileptic seizure detection
KW  - Mahalanobis distance
KW  - Discrete wavelet transformation (DWT)
KW  - Sample entropy
KW  - Fusion feature
KW  - Extreme learning machine (ELM)
AB  - Abstract
Automated seizure detection using EEG has gained increasing attraction in recent years and appeared more and more helpful in both diagnosis and treatment. How to design an appropriate feature extraction method and how to select an efficient classifier are recognized to be crucial in the successful realization. This paper first proposes a new Mahalanobis-similarity-based feature extraction method on the basis of the Mahalanobis distance and discrete wavelet transformation (DWT). Then in order to further improve the performance, this paper designs a fusion feature (MS-SE-FF) in the feature-fusion level, where the Mahalanobis-similarity-based feature characterizing the similarity between signals and the sample-entropy-based feature characterizing the complexity of signals are combined together. Finally, an automated seizure detection method FF-ELM-SD has been built, which is integrated between the novel fusion feature MS-SE-FF and extreme learning machine (ELM). Experimental results demonstrate that the proposed method FF-ELM-SD does a good job in the epileptic seizure detection while preserving the efficiency and simplicity.
ER  - 

TY  - JOUR
T1  - Two-hidden-layer extreme learning machine for regression and classification
JO  - Neurocomputing
VL  - 175, Part A
IS  - 
SP  - 826
EP  - 834
PY  - 2016/1/29/
T2  - 
AU  - Qu, B.Y.
AU  - Lang, B.F.
AU  - Liang, J.J.
AU  - Qin, A.K.
AU  - Crisalle, O.D.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.11.009
UR  - https://www.sciencedirect.com/science/article/pii/S092523121501663X
KW  - Extreme learning machine
KW  - Two-hidden-layer
KW  - Regression
KW  - Classification
KW  - Neural network
AB  - Abstract
As a single-hidden-layer feedforward neural network, an extreme learning machine (ELM) randomizes the weights between the input layer and the hidden layer as well as the bias of hidden neurons, and analytically determines the weights between the hidden layer and the output layer using the least-squares method. This paper proposes a two-hidden-layer ELM (denoted TELM) by introducing a novel method for obtaining the parameters of the second hidden layer (connection weights between the first and second hidden layer and the bias of the second hidden layer), hence bringing the actual hidden layer output closer to the expected hidden layer output in the two-hidden-layer feedforward network. Simultaneously, the TELM method inherits the randomness of the ELM technique for the first hidden layer (connection weights between the input weights and the first hidden layer and the bias of the first hidden layer). Experiments on several regression problems and some popular classification datasets demonstrate that the proposed TELM can consistently outperform the original ELM, as well as some existing multilayer ELM variants, in terms of average accuracy and the number of hidden neurons.
ER  - 

TY  - JOUR
T1  - Sparse Bayesian mixed-effects extreme learning machine, an approach for unobserved clustered heterogeneity
JO  - Neurocomputing
VL  - 175, Part A
IS  - 
SP  - 411
EP  - 420
PY  - 2016/1/29/
T2  - 
AU  - Kiaee, Farkhondeh
AU  - Sheikhzadeh, Hamid
AU  - Eftekhari Mahabadi, Samaneh
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.10.073
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215015325
KW  - Extreme learning machine
KW  - Mixed-effect models
KW  - Sparse Bayesian
KW  - Clustered data
KW  - Random effect
AB  - Abstract
The well-known Extreme Learning Machine (ELM) method is widely used to analyse independent random distributed measurements. However, in some applications, the problem of modeling clustered data which contains several correlated groups is of interest. The research presented in this paper utilizes the concept of random effects in the ELM framework to model inter-cluster heterogeneity, provided the inherent correlation among the samples of a particular cluster is taken into account, as well. The proposed random effect model includes an additional variance component to accommodate correlated data and to allow for differences among clusters. Inference techniques based on Bayesian evidence procedure are derived for the estimation of model weights, random effect and residual variance parameters as well as hyperparameters. The proposed model is applied to both synthesis and real world clustered datasets. Experimental results show that our proposed method can achieve better performance in terms of accuracy and model size, compared with the previous ELM-based models (ELM, BELM, and SBELM) with the assumption of independency, in cases where the data actually have within cluster correlation. The generalization performance and sparsity of the proposed model are also superior to those of the ME-LSSVM method.
ER  - 

TY  - JOUR
T1  - Cholesky factorization based online regularized and kernelized extreme learning machines with forgetting mechanism
JO  - Neurocomputing
VL  - 174, Part B
IS  - 
SP  - 1147
EP  - 1155
PY  - 2016/1/22/
T2  - 
AU  - Zhou, Xin-Ran
AU  - Wang, Chun-Sheng
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.10.033
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215014927
KW  - Extreme learning machine
KW  - Online sequential learning algorithms
KW  - Forgetting mechanism
KW  - Cholesky decomposition
AB  - Abstract
In this paper, we propose two alternative schemes of fast online sequential extreme learning machine (ELM) for training the single hidden-layer feedforward neural networks (SLFN), termed as Cholesky factorization based online regularized ELM with forgetting mechanism (CF-FORELM) and Cholesky factorization based online kernelized ELM with forgetting mechanism (CF-FOKELM). First, the solutions of regularized ELM (RELM) and kernelized ELM (KELM) using the matrix Cholesky factorization are introduced; then the recursive method for calculating Cholesky factor of involved matrix in RELM and KELM is designed when RELM and KELM are applied to train SLFN online; consequently, the CF-FORELM and CF-FOKELM are obtained. The numerical simulation results show CF-FORELM demands less computational burden than Dynamic Regression ELM (DR-ELM), and CF-FOKELM also owns higher computational efficiency than both FOKELM and online sequential ELM with kernels (OS-ELMK), and CF-FORELM is less sensitive to model parameters than CF-FOKELM.
ER  - 

TY  - JOUR
T1  - An efficient and effective convolutional auto-encoder extreme learning machine network for 3d feature learning
JO  - Neurocomputing
VL  - 174, Part B
IS  - 
SP  - 988
EP  - 998
PY  - 2016/1/22/
T2  - 
AU  - Wang, Yueqing
AU  - Xie, Zhige
AU  - Xu, Kai
AU  - Dou, Yong
AU  - Lei, Yuanwu
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.10.035
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215014940
KW  - Convolutional
KW  - Extreme learning machine
KW  - Auto-encoder
KW  - Feature learning
AB  - Abstract
3D shape features play a crucial role in graphics applications, such as 3D shape matching, recognition, and retrieval. Various 3D shape descriptors have been developed over the last two decades; however, existing descriptors are handcrafted features that are labor-intensively designed and cannot extract discriminative information for a large set of data. In this paper, we propose a rapid 3D feature learning method, namely, a convolutional auto-encoder extreme learning machine (CAE-ELM) that combines the advantages of the convolutional neuron network, auto-encoder, and extreme learning machine (ELM). This method performs better and faster than other methods. In addition, we define a novel architecture based on CAE-ELM. The architecture accepts two types of 3D shape representation, namely, voxel data and signed distance field data (SDF), as inputs to extract the global and local features of 3D shapes. Voxel data describe structural information, whereas SDF data contain details on 3D shapes. Moreover, the proposed CAE-ELM can be used in practical graphics applications, such as 3D shape completion. Experiments show that the features extracted by CAE-ELM are superior to existing hand-crafted features and other deep learning methods or ELM models. Moreover, the classification accuracy of the proposed architecture is superior to that of other methods on ModelNet10 (91.4%) and ModelNet40 (84.35%). The training process also runs faster than existing deep learning methods by approximately two orders of magnitude.
ER  - 

TY  - JOUR
T1  - Voting based q-generalized extreme learning machine
JO  - Neurocomputing
VL  - 174, Part B
IS  - 
SP  - 1021
EP  - 1030
PY  - 2016/1/22/
T2  - 
AU  - Stosic, Dusan
AU  - Stosic, Darko
AU  - Ludermir, Teresa
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.10.028
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215014873
KW  - Neural networks
KW  - Extreme learning machines
KW  - Tsallis statistics
KW  - Ensemble methods
KW  - Majority voting
AB  - Abstract
A novel approach to extreme learning machine (ELM) ensembles is proposed. It incorporates majority voting into the recently proposed q-generalized random neural network (QRNN) to make the final decision for classification problems. Individual ELMs are trained with q-Gaussian activation functions using different values of the parameter q (called the entropic index). As a result, these classifiers are generally more accurate than traditional ELMs. Simulations on 45 machine learning data sets show that this method, termed voting based q-generalized extreme learning machine (V-QELM), outperforms other extreme learning machine ensembles. Statistical tests (Wilcoxon, Friedman, and Nemenyi) are used to validate statistical differences between our results. Kappa-error diagrams reveal that V-QELM constructs more accurate classifiers than those found in other ensemble methods. This implies that incorporating QRNNs can lead to higher performing ensembles of extreme learning machines.
ER  - 

TY  - JOUR
T1  - Regularized online sequential extreme learning machine with adaptive regulation factor for time-varying nonlinear system
JO  - Neurocomputing
VL  - 174, Part B
IS  - 
SP  - 617
EP  - 626
PY  - 2016/1/22/
T2  - 
AU  - Lu, XinJiang
AU  - Zhou, Chuang
AU  - Huang, MingHui
AU  - Lv, WenBing
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.09.068
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215014010
KW  - Extreme learning machine
KW  - Adaptive regulation factor
KW  - Leave-one-out cross validation
KW  - modeling
AB  - Abstract
In order to more accurately model time-varying nonlinear systems, we propose a regularized online sequential extreme learning machine with adaptive regulation factor (ROSELM-ARF). The construction of a new objective function allows for the online updating of both the model coefficient as well as the regulation factor, while negating the influence of the cumulate error. This differs from the traditional regularized online sequential extreme learning machine (ReOS-ELM) which only updates the model coefficient. The development and application of a two-step solving method is used to determine the optimal parameters, where the optimal regulation factor is derived using the proposed fast and online leave-one-out cross validation (FOLOO) method. The computational performance could be drastically improved by using the proposed FOLOO method as compared to using the existing leave-one-out cross validation (LOO) method. The application of the proposed method in the modeling of two practical cases is done in order to demonstrate its effectiveness. The experimental results indicate that the proposed method provides a more accurate model than several conventional modeling methods, while also improving the computational performance.
ER  - 

TY  - JOUR
T1  - An online sequential extreme learning machine for tidal prediction based on improved GathâGeva fuzzy segmentation
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 85
EP  - 98
PY  - 2016/1/22/
T2  - 
AU  - Yin, Jianchuan
AU  - Wang, Nini
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.02.094
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011340
KW  - Online sequential extreme learning machine
KW  - GathâGeva fuzzy segmentation
KW  - Tidal prediction
KW  - Modular prediction
AB  - Abstract
A novel sampling pool selection scheme is proposed for the online sequential extreme learning machine (OS-ELM) based on improved GathâGeva (IGG) fuzzy segmentation algorithm. Tidal change is a time-varying process whose dynamics vary with changes of internal and environmental factors such as celestial bodies movements, coastal topology and environmental disturbances. When OS-ELM is implemented for identifying time-varying system dynamics, it usually sequentially selects samples with fixed number. Under such circumstance, samples representing different system dynamics are mixed together so that the online representation and prediction abilities of OS-ELM may be deteriorated. To consciously select samples with most representing ability and construct appropriate sampling pool for OS-ELM, in this study, a dynamic sampling pool selection scheme is proposed based on IGG fuzzy segmentation approach. Time series of input and output variables are segmented as per their dynamics characteristics. The change points split up the time series into several segments and the change points themselves represent the changes of system dynamics. Samples within the same segment are considered as possessing homogeneous characteristics. To achieve best representing abilities for current system dynamics, the proposed IGG-based sampling scheme is implemented for selecting sampling pool. The OS-ELM selects homogeneous samples from sampling pool thus possesses better representing ability for current dynamics. In the meantime, conventional harmonic analysis is also applied to represent the influences of celestial bodies and coastal topology. The harmonic method and IGG-based OS-ELM are combined together and the resulted modular prediction scheme is applied for online tidal level prediction of ports of King Point, Mokuoloe and Old Port Tampa in the United States. Simulation results demonstrate the feasibility and effectiveness of the proposed sampling scheme and the modular tidal prediction approach.
ER  - 

TY  - JOUR
T1  - Extreme learning machine based transfer learning for data classification
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 203
EP  - 210
PY  - 2016/1/22/
T2  - 
AU  - Li, Xiaodong
AU  - Mao, Weijie
AU  - Jiang, Wei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.01.096
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011315
KW  - Extreme learning machine
KW  - Transfer learning (TL)
KW  - Classification
AB  - Abstract
The extreme learning machine (ELM) is a new method for using Single-hidden Layer Feed-forward Networks (SLFNs) with a much simpler training method. While conventional extreme learning machine are based on the training and test data which should be under the same distribution, in reality it is often desirable to learn an accurate model using only a tiny amount of new data and a large amount of old data. Transfer learning (TL) aims to solve related but different target domain problems by using plenty of labeled source domain data. When the task from one new domain comes, new domain samples are relabeled costly, and it would be a waste to discard all the old domain data. Therefore, an algorithm called TL-ELM based on the ELM algorithm is proposed, which uses a small amount of target domain tag data and a large number of source domain old data to build a high-quality classification model. The method inherits the advantages of ELM and makes up for the defects that traditional ELM cannot transfer knowledge. Experimental results indicate that the performance of the proposed methods is superior to or at least comparable with existing benchmarking methods. In addition, a novel domain adaptation kernel extreme learning machine (TL-DAKELM) based on the kernel extreme learning machine was proposed with respect to the TL-ELM. Experimental results show the effectiveness of the proposed algorithm.
ER  - 

TY  - JOUR
T1  - Advances in extreme learning machines (ELM2014)
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 1
EP  - 3
PY  - 2016/1/22/
T2  - 
AU  - Lendasse, Amaury
AU  - Man, Vong Chi
AU  - Miche, Yoan
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.08.009
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011431
ER  - 

TY  - JOUR
T1  - Gradient-based no-reference image blur assessment using extreme learning machine
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 310
EP  - 321
PY  - 2016/1/22/
T2  - 
AU  - Wang, Shuigen
AU  - Deng, Chenwei
AU  - Zhao, Baojun
AU  - Huang, Guang-Bin
AU  - Wang, Baoxian
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.12.117
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011467
KW  - No-reference blur metric
KW  - Extreme learning machine
KW  - Gradient magnitude
KW  - Generalized Gaussian distribution
AB  - Abstract
The increasing number of demanding consumer digital multimedia applications has boosted interest in no-reference (NR) image quality assessment (IQA). In this paper, we propose a perceptual NR blur evaluation method using a new machine learning technique, i.e., extreme learning machine (ELM). The proposed metric, Blind Image Blur quality Evaluator (BIBE), exploits scene statistics of gradient magnitudes to model the properties of blurred images, and then the underlying blur features are derived by fitting gradient magnitudes distribution. The resultant feature is finally mapped into an associated quality score using ELM. As subjective evaluation scores by human beings are integrated into training, machine learning techniques can predict image quality more accurately than those traditional methods. Compared with other learning techniques such as support vector machine (SVM), ELM has better learning performance and faster learning speed. Experimental results on public databases show that the proposed BIBE correlates well with human perceived blurriness, and outperforms the state-of-the-art specific NR blur evaluation metrics as well as generic NR IQA methods. Moreover, the application of automatic focusing system for digital cameras further confirms the capability of BIBE.
ER  - 

TY  - JOUR
T1  - Online sequential reduced kernel extreme learning machine
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 72
EP  - 84
PY  - 2016/1/22/
T2  - 
AU  - Deng, Wan-Yu
AU  - Ong, Yew-Soon
AU  - Tan, Puay Siew
AU  - Zheng, Qing-Hua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.06.087
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011303
KW  - Extreme learning machine
KW  - Support vector machine
KW  - Online sequential learning
KW  - Big data
AB  - Abstract
In this paper, we present an Online Sequential Reduced Kernel Extreme Learning Machine (OS-RKELM). In OS-RKELM, only a small part of the instances in the original training samples is employed for training the kernel neurons, while the output weights are attained analytically. Similar to the Online Sequential Extreme Learning Machine (OS-ELM), OS-RKELM learns data samples in a chunk-by-chunk or one-by-one mode and does not require an archival of the data sample once it has been learned. OS-RKELM also contains few control parameters, thus avoiding the need for cumbersome fine-tuning of the algorithm. OS-RKELM supports a widespread types of kernels as hidden neurons and is capable of addressing the singular problem that arises when the initial training samples are smaller than the neuron size. A comprehensive performance evaluation of the OS-RKELM against other state-of-the-art sequential learning algorithms, including OS-ELM, Large-scale Active Support Vector Machine (LASVM) and Budgeted Stochastic Gradient Descent Support Vector Machine (BSGD) using popular time series, regression and classification benchmarks have been conducted. Experimental results obtained indicate that the proposed OS-RKELM showcases improved prediction accuracy and efficiency over the OS-ELM, LASVM and BSGD in many cases.
ER  - 

TY  - JOUR
T1  - Dynamic texture video classification using extreme learning machine
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 278
EP  - 285
PY  - 2016/1/22/
T2  - 
AU  - Wang, Liuyang
AU  - Liu, Huaping
AU  - Sun, Fuchun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.114
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011480
KW  - Extreme learning machine
KW  - Dynamic texture classification
KW  - Linear dynamical systems
KW  - Bag-of-systems
AB  - Abstract
Recognition of complex dynamic texture is a difficult task and captures the attention of the computer vision community for several decades. Essentially the dynamic texture recognition is a multi-class classification problem that has become a real challenge for computer vision and machine learning techniques. Due to the reason that the dynamic textures lie in non-Euclidean manifold, existing classifier such as extreme learning machine cannot effectively deal with this problem. In this paper, we propose a new approach to tackle the dynamic texture recognition problem. First, we utilize the affinity propagation clustering technology to design a codebook, and then construct a soft coding feature to represent the whole dynamic texture sequence. This new coding strategy preserves spatial and temporal characteristics of dynamic texture. Finally, by evaluating the proposed approach on the DynTex dataset, we show the effectiveness of the proposed strategy.
ER  - 

TY  - JOUR
T1  - A semi-supervised online sequential extreme learning machine method
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 168
EP  - 178
PY  - 2016/1/22/
T2  - 
AU  - Jia, Xibin
AU  - Wang, Runyuan
AU  - Liu, Junfa
AU  - Powers, David M.W.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.102
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011212
KW  - Online Sequential ELM (OS-ELM)
KW  - Semi-supervised ELM (SS-ELM)
KW  - Semi-supervised online sequential ELM (SOS-ELM)
AB  - Abstract
This paper proposes a learning algorithm called Semi-supervised Online Sequential ELM, denoted as SOS-ELM. It aims to provide a solution for streaming data applications by learning from just the newly arrived observations, called a chunk. In addition, SOS-ELM can utilize both labeled and unlabeled training data by combining the advantages of two existing algorithms: Online Sequential ELM (OS-ELM) and Semi-Supervised ELM (SS-ELM). The rationale behind our algorithm exploits an optimal condition to alleviate empirical risk and structure risk used by SS-ELM, in combination with block calculation of matrices similar to OS-ELM. Efficient implementation of the SOS-ELM algorithm is made viable by an additional assumption that there is negligible structural relationship between chunks from different times. Experiments have been performed on standard benchmark problems for regression, balanced binary classification, unbalanced binary classification and multi-class classification by comparing the performance of the proposed SOS-ELM with OS-ELM and SS-ELM. The experimental results show that the SOS-ELM outperforms OS-ELM in generalization performance with similar training speed, and in addition outperforms SS-ELM with much lower supervision overheads.
ER  - 

TY  - JOUR
T1  - Parallel ensemble of online sequential extreme learning machine based on MapReduce
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 352
EP  - 367
PY  - 2016/1/22/
T2  - 
AU  - Huang, Shan
AU  - Wang, Botao
AU  - Qiu, Junhao
AU  - Yao, Jitao
AU  - Wang, Guoren
AU  - Yu, Ge
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.105
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011662
KW  - Parallel learning
KW  - Ensemble
KW  - Extreme learning machine
KW  - MapReduce
KW  - Sequential learning
AB  - Abstract
In this era of big data, analyzing large scale data efficiently and accurately has become a challenging problem. As one of the ELM variants, online sequential extreme learning machine (OS-ELM) provides a method to analyze incremental data. Ensemble methods provide a way to learn from data more accurately. MapReduce, which provides a simple, scalable and fault-tolerant framework, can be utilized for large scale learning. In this paper, we first propose an ensemble OS-ELM framework which supports any combination of bagging, subspace partitioning and cross validation. Then we design a parallel ensemble of online sequential extreme learning machine (PEOS-ELM) algorithm based on MapReduce for large scale learning. PEOS-ELM algorithm is evaluated with real and synthetic data with the maximum number of training data 5120K and the maximum number of attributes 512. The speedup of this algorithm reaches as high as 40 on a cluster with maximum 80 cores. The accuracy of PEOS-ELM algorithm is at the same level as that of ensemble OS-ELM executing on a single machine, which is higher than that of the original OS-ELM.
ER  - 

TY  - JOUR
T1  - Building feature space of extreme learning machine with sparse denoising stacked-autoencoder
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 60
EP  - 71
PY  - 2016/1/22/
T2  - 
AU  - Cao, Le-le
AU  - Huang, Wen-bing
AU  - Sun, Fu-chun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.02.096
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011674
KW  - Extreme learning machine (ELM)
KW  - Ridge regression
KW  - Feature space
KW  - Stacked autoencoder (SAE)
KW  - Classification
KW  - Regression
AB  - Abstract
The random-hidden-node extreme learning machine (ELM) is a much more generalized cluster of single-hidden-layer feed-forward neural networks (SLFNs) which has three parts: random projection, non-linear transformation, and ridge regression (RR) model. Networks with deep architectures have demonstrated state-of-the-art performance in a variety of settings, especially with computer vision tasks. Deep learning algorithms such as stacked autoencoder (SAE) and deep belief network (DBN) are built on learning several levels of representation of the input. Beyond simply learning features by stacking autoencoders (AE), there is a need for increasing its robustness to noise and reinforcing the sparsity of weights to make it easier to discover interesting and prominent features. The sparse AE and denoising AE was hence developed for this purpose. This paper proposes an approach: SSDAE-RR (stacked sparse denoising autoencoder â ridge regression) that effectively integrates the advantages in SAE, sparse AE, denoising AE, and the RR implementation in ELM algorithm. We conducted experimental study on real-world classification (binary and multiclass) and regression problems with different scales among several relevant approaches: SSDAE-RR, ELM, DBN, neural network (NN), and SAE. The performance analysis shows that the SSDAE-RR tends to achieve a better generalization ability on relatively large datasets (large sample size and high dimension) that were not pre-processed for feature abstraction. For 16 out of 18 tested datasets, the performance of SSDAE-RR is more stable than other tested approaches. We also note that the sparsity regularization and denoising mechanism seem to be mandatory for constructing interpretable feature representations. The fact that a SSDAE-RR approach often has a comparable training time to ELM makes it useful in some real applications.
ER  - 

TY  - JOUR
T1  - An efficient active set method for optimization extreme learning machines
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 187
EP  - 193
PY  - 2016/1/22/
T2  - 
AU  - Zhao, Ming-hua
AU  - Ding, Xiao-feng
AU  - Shi, Zheng-hao
AU  - Yao, Quan-zhu
AU  - Yuan, Yong-qin
AU  - Mo, Rui-yang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.01.092
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011194
KW  - Optimization extreme learning machines
KW  - Quadratic programming
KW  - Active set
KW  - Piecewise projected gradient
AB  - Abstract
In this paper an efficient active set algorithm is presented for fast training of Optimization Extreme Learning Machines (OELMs). This algorithm suggests the use of an efficient identification technique of active set and the value reassignment technique for quadratic programming problem. With these strategies, this algorithm is able to drop many constraints from the active set at each iteration, and it can converge to the optimal solution with less iterations. The global convergence properties of the algorithm as well as its theoretical properties are analyzed. The effectiveness of the algorithm is demonstrated via benchmark datasets from many sources. Experiment results indicate that the quadratic programming problem which keeps the number of constraints in the active set as small as possible is computationally most efficient.
ER  - 

TY  - JOUR
T1  - Regression and classification using extreme learning machine based on L1-norm and L2-norm
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 179
EP  - 186
PY  - 2016/1/22/
T2  - 
AU  - Luo, Xiong
AU  - Chang, Xiaohui
AU  - Ban, Xiaojuan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.112
UR  - https://www.sciencedirect.com/science/article/pii/S092523121501139X
KW  - Extreme learning machine
KW  - Ridge regression
KW  - Elastic net
KW  - Model selection
KW  - Bayesian information criterion (BIC)
AB  - Abstract
Extreme learning machine (ELM) is a very simple machine learning algorithm and it can achieve a good generalization performance with extremely fast speed. Therefore it has practical significance for data analysis in real-world applications. However, it is implemented normally under the empirical risk minimization scheme and it may tend to generate a large-scale and over-fitting model. In this paper, an ELM model based on L1-norm and L2-norm regularizations is proposed to handle regression and multiple-class classification problems in a unified framework. The proposed model called L1âL2-ELM combines the grouping effect benefits of L2 penalty and the tendency towards sparse solution of L1 penalty, thus it can control the complexity of the network and prevent over-fitting. To solve the mixed penalty problem, the separate elastic net algorithm and Bayesian information criterion (BIC) are adopted to find the optimal model for each response variable. We test the L1âL2-ELM algorithm on one artificial case and nine benchmark data sets to evaluate its performance. Simulation results have shown that the proposed algorithms outperform the original ELM as well as other advanced ELM algorithms in terms of prediction accuracy, and it is more robust in both regression and classification applications.
ER  - 

TY  - JOUR
T1  - Inductive bias for semi-supervised extreme learning machine
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 154
EP  - 167
PY  - 2016/1/22/
T2  - 
AU  - Bisio, Federica
AU  - Decherchi, Sergio
AU  - Gastaldo, Paolo
AU  - Zunino, Rodolfo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.104
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011479
KW  - Extreme Learning Machine
KW  - Semi-supervised learning
KW  - Inductive bias
AB  - Abstract
This research shows that inductive bias provides a valuable method to effectively tackle semi-supervised classification problems. In the learning theory framework, inductive bias provides a powerful tool, and allows one to shape the generalization properties of a learning machine. The paper formalizes semi-supervised learning as a supervised learning problem biased by an unsupervised reference solution. The resulting semi-supervised classification framework can apply any clustering algorithm to derive the reference function, thus ensuring maximum flexibility. In this context, the paper derives the biased version of Extreme Learning Machine (br-ELM). The experimental session involves several real world problems and proves the reliability of the semi-supervised classification scheme.
ER  - 

TY  - JOUR
T1  - Random Fourier extreme learning machine with -norm regularization
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 143
EP  - 153
PY  - 2016/1/22/
T2  - 
AU  - Zhou, Sihang
AU  - Liu, Xinwang
AU  - Liu, Qiang
AU  - Wang, Siqi
AU  - Zhu, Chengzhang
AU  - Yin, Jianping
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.113
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011455
KW  - Extreme learning machine
KW  - â    2  ,  1    -norm regularization
KW  - Random Fourier mapping
KW  - Kernel learning
AB  - Abstract
This paper proposes a novel algorithm, termed random Fourier extreme learning machine with â 2 , 1 -norm regularization, to improve the robustness and compactness of the widely used extreme learning machine. In specific, we firstly introduce the random Fourier mappings as activation functions to approximate the Gaussian kernel, with the aim to improve the extendibility of the powerful kernel ELM algorithms. We then adopt the â 2 , 1 -norm to eliminate the potential irrelevant neurons, resulting in a more compact and discriminative hidden layer. After that, we propose an efficient algorithm with proved convergence to solve the resultant optimization problem. Extensive experiments have been conducted on 30 benchmark data sets to compare the proposed algorithm with six popular extreme learning algorithms. As observed, our algorithm outperforms the enumerated hidden layer reinforcement algorithms. In addition, it significantly improves the computational efficiency of Gaussian kernel extreme learning machine with comparable classification and regression performance in large scale learning scenarios.
ER  - 

TY  - JOUR
T1  - Sparse Bayesian extreme learning committee machine for engine simultaneous fault diagnosis
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 331
EP  - 343
PY  - 2016/1/22/
T2  - 
AU  - Wong, Pak Kin
AU  - Zhong, Jianhua
AU  - Yang, Zhixin
AU  - Vong, Chi Man
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.02.097
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011765
KW  - Automotive engine
KW  - Multi-signal fusion
KW  - Simultaneous-fault diagnosis
KW  - Sparse Bayesian extreme learning machine
KW  - Probabilistic committee machine
AB  - Abstract
The automotive engine is prone to various faults due to its complex structure and running conditions. Development of a fast response and accurate intelligent system for fault diagnosis of automotive engines is therefore greatly urged. The engine fault diagnosis faces challenges because of the existence of simultaneous-faults which are multiple single-faults appear concurrently. Another challenge is the high cost in acquiring the exponentially increased simultaneous-fault signals. Traditional signal-based engine fault diagnostic systems may not give reliable diagnostic results because they usually rely on single classifier and one kind of engine signal. To enhance the reliability of fault diagnosis and the number of detectable faults, this research proposes a new diagnostic framework namely probabilistic committee machine (PCM). The framework combines feature extraction (empirical mode decomposition and sample entropy), a parameter optimization algorithm, and multiple sparse Bayesian extreme learning machines (SBELM) to form an intelligent diagnostic framework. Multiple SBELM networks are built to form different domain committee members. The members are individually trained using air ratio, ignition pattern and engine sound signals. The diagnostic result from each fault detection member is then combined by using a new probabilistic ensemble method, which can improve the overall diagnostic accuracy and increase the number of detectable faults as compared to individual classifier. Experimental results show the proposed framework is superior to the existing single probabilistic classifier. Moreover, the proposed system can diagnose both single and simultaneous-faults for automotive engines while the system is trained by single-fault patterns only.
ER  - 

TY  - JOUR
T1  - An algorithm for classification over uncertain data based on extreme learning machine
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 194
EP  - 202
PY  - 2016/1/22/
T2  - 
AU  - Cao, Keyan
AU  - Wang, Guoren
AU  - Han, Donghong
AU  - Bai, Mei
AU  - Li, Shuoru
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.05.121
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011376
KW  - Extreme learning machine
KW  - Classification
KW  - Uncertain data
KW  - Single hidden layer feedforward neural networks
AB  - Abstract
In recent years, along with the generation of uncertain data, more and more attention is paid to the mining of uncertain data. In this paper, we study the problem of classifying uncertain data using Extreme Learning Machine (ELM). We first propose the UU-ELM algorithm for classification of uncertain data which is uniformly distributed. Furthermore, the NU-ELM algorithm is proposed for classifying uncertain data which are non-uniformly distributed. By calculating bounds of the probability, the efficiency of the algorithm can be improved. Finally, the performances of our methods are verified through a large number of simulated experiments. The experimental results show that our methods are effective ways to solve the problem of uncertain data classification, reduce the execution time and improve the efficiency.
ER  - 

TY  - JOUR
T1  - Brain MRI morphological patterns extraction tool based on Extreme Learning Machine and majority vote classification
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 344
EP  - 351
PY  - 2016/1/22/
T2  - 
AU  - Termenon, Maite
AU  - GraÃ±a, Manuel
AU  - Savio, Alexandre
AU  - Akusok, Anton
AU  - Miche, Yoan
AU  - BjÃ¶rk, Kaj-Mikael
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.111
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011388
KW  - ELM
KW  - MRI
KW  - Classification
AB  - Abstract
The aim of this paper is to build a tool that able to extract the regions from a brain magnetic resonance image that discriminate healthy controls from subjects with probable dementia of the Alzheimer type. We propose the use of an Extreme Learning Machine method to select the most discriminant regions and thereafter to perform the final classification according to a majority vote decision based strategy. We are selecting the optimal number of votes required to put a subject into the class âAlzheimerâ by maximizing the global accuracy and minimizing the number of false positives. The discriminative regions selected in the case study are located in the hippocampus, amygdala, thalamus and putamen, among others. These locations are closely related with a Alzheimer disease according to the medical literature.
ER  - 

TY  - JOUR
T1  - Extreme learning machine for time sequence classification
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 322
EP  - 330
PY  - 2016/1/22/
T2  - 
AU  - Liu, Huaping
AU  - Yu, Lianzhi
AU  - Wang, Wen
AU  - Sun, Fuchun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.01.093
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011200
KW  - Extreme learning machine
KW  - Time sequence classification
KW  - Linear dynamical systems
KW  - Bag-of-systems
AB  - Abstract
In this paper, a new framework to effectively classify the time sequence is developed. The whole time sequence is divided into several smaller sub-sequence by means of the sliding time window technique. The sub-sequence is modeled as a linear dynamic model by appropriate dimension reduction and the whole time sequence is represented as a bag-of-systems model. Such a model is very flexible to describe time sequence originated from different sensor source. To construct the bag-of-systems model, we design the codebook by using the K-medoids clustering algorithm and Martin distance between linear dynamic systems. Such a technology avoids the problem that linear dynamic systems lie in non-Euclidean manifold. After obtaining the represented of time sequence, an extreme learning machine is utilized for classification. Finally, the proposed method is verified on some benchmark and shows that it obtains promising results.
ER  - 

TY  - JOUR
T1  - A-ELMâ: Adaptive Distributed Extreme Learning Machine with MapReduce
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 368
EP  - 374
PY  - 2016/1/22/
T2  - 
AU  - Xin, Junchang
AU  - Wang, Zhiqiong
AU  - Qu, Luxuan
AU  - Yu, Ge
AU  - Kang, Yan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.01.094
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011273
KW  - Extreme Learning Machine
KW  - MapReduce
KW  - Incremental hidden nodes
KW  - Decremental hidden nodes
AB  - Abstract
Due to the outstanding advantage, such as generalization performance and fast convergence, Extreme Learning Machine (ELM) and its variants have been widely used for many applications. The distributed ELM with MapReduce could handle large-scale training dataset efficiently, but how to cope with its updated hidden nodes number which aims to get the higher accuracy is still a challenging task. In this paper, we propose a novel Adaptive Distributed Extreme Learning Machine with MapReduce (A-ELMâ). It could overcome the weakness of ELMâ in learning massive training dataset for updating hidden nodes number. Firstly, we found that through partial adjustment of incremental hidden nodes and decremental hidden nodes, matrix multiplication (the most computation-expensive part in A-ELMâ) can be calculated. Next, A-ELMâ based on MapReduce framework is proposed. A-ELMâ first calculates the intermediate matrix multiplications of the updated hidden nodes subset, and then update the matrix multiplications by modifying the old matrix multiplications with the intermediate ones. Then, based on the updated matrix multiplications, there could obtain the corresponding new output weight vector with centralized computing. Therefore, it is effective for learning large scale training dataset, in which the hidden nodes update rapidly. Finally, we verify the effectiveness and efficiency of our proposed A-ELMâ, using synthetic data with extensive experiments, in learning updated hidden nodes.
ER  - 

TY  - JOUR
T1  - Uncertain XML documents classification using Extreme Learning Machine
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 375
EP  - 382
PY  - 2016/1/22/
T2  - 
AU  - Zhao, Xiangguo
AU  - Bi, Xin
AU  - Wang, Guoren
AU  - Zhang, Zhen
AU  - Yang, Hongbo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.02.095
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011443
KW  - Extreme Learning Machine
KW  - Classification
KW  - XML
KW  - Uncertain Data
AB  - Abstract
Driven by the emerging network data exchange and storage, XML documents classification has become increasingly important. Most existing representation model and conventional learning algorithm are defined on certain XML documents. However, in many real-world applications, XML datasets contain inherent uncertainty, which brings greater challenges to classification problem. In this paper, we propose a novel solution to classify uncertain XML documents, including uncertain XML documents representation and two uncertain learning algorithms based on Extreme Learning Machine. Experimental results show that our approaches exhibit prominent performance for uncertain XML documents classification problem.
ER  - 

TY  - JOUR
T1  - An unsupervised discriminative extreme learning machine and its applications to data clustering
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 250
EP  - 264
PY  - 2016/1/22/
T2  - 
AU  - Peng, Yong
AU  - Zheng, Wei-Long
AU  - Lu, Bao-Liang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.11.097
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011686
KW  - Extreme learning machine (ELM)
KW  - Unsupervised learning
KW  - Manifold information
KW  - Discriminative information
KW  - Image clustering
KW  - EEG
AB  - Abstract
Extreme Learning Machine (ELM), which was initially proposed for training single-layer feed-forward networks (SLFNs), provides us a unified efficient and effective framework for regression and multiclass classification. Though various ELM variants were proposed in recent years, most of them focused on the supervised learning scenario while little effort was made to extend it into unsupervised learning paradigm. Therefore, it is of great significance to put ELM into learning tasks with only unlabeled data. One popular approach for mining knowledge from unlabeled data is based on the manifold assumption, which exploits the geometrical structure of data by assuming that nearby points will also be close to each other in transformation space. However, considering the manifold information only is insufficient for discriminative tasks. In this paper, we propose an improved unsupervised discriminative ELM (UDELM) model, whose main advantage is to combine the local manifold learning with global discriminative learning together. UDELM can be efficiently optimized by solving a generalized eigen-value decomposition problem. Extensive comparisons over several state-of-the-art models on clustering image and emotional EEG data demonstrate the efficacy of UDELM.
ER  - 

TY  - JOUR
T1  - Deep extreme learning machines: supervised autoencoding architecture for classification
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 42
EP  - 49
PY  - 2016/1/22/
T2  - 
AU  - Tissera, Migel D.
AU  - McDonnell, Mark D.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.110
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011327
KW  - Extreme learning machine
KW  - Supervised learning
KW  - Autoencoder
KW  - Classifier
KW  - MNIST
KW  - Deep neural network
AB  - Abstract
We present a method for synthesising deep neural networks using Extreme Learning Machines (ELMs) as a stack of supervised autoencoders. We test the method using standard benchmark datasets for multi-class image classification (MNIST, CIFAR-10 and Google Streetview House Numbers (SVHN)), and show that the classification error rate can progressively improve with the inclusion of additional autoencoding ELM modules in a stack. Moreover, we found that the method can correctly classify up to 99.19% of MNIST test images, which surpasses the best error rates reported for standard 3-layer ELMs or previous deep ELM approaches when applied to MNIST. The approach simultaneously offers a significantly faster training algorithm to achieve its best performance (in the order of 5 min on a four-core CPU for MNIST) relative to a single ELM with the same total number of hidden units as the deep ELM, hence offering the best of both worlds: lower error rates and fast implementation.
ER  - 

TY  - JOUR
T1  - Online Sequential Extreme Learning Machine for watermarking in DWT domain
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 238
EP  - 249
PY  - 2016/1/22/
T2  - 
AU  - Singh, Ram Pal
AU  - Dabas, Neelam
AU  - Chaudhary, Vikash
AU  - Nagendra
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.115
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011492
KW  - BER
KW  - ELM
KW  - OSELM
KW  - PSNR
KW  - SIM  (  X  ,    X    â    )
KW  - WELM
AB  - Abstract
Protecting and securing an information of digital media is very crucial due to illegal reproduction and modification of media has become an acute problem for copyright protection now a day. A Discrete Wavelet Transform (DWT) domain based robust watermarking scheme with Extreme Learning Machine (ELM), Online Sequential Extreme Learning Machine (OSELM) and Weighted Extreme Learning Machine (WELM) have been implemented on different color images. The proposed scheme which combine DWT with ELM, OSELM and WELM machine learning methods and a watermark or a tag or a sequence is embedded as an ownership information. Experimental results demonstrate that the proposed watermarking scheme is imperceptible/transparent and robust against image processing and attacks such as blurring, cropping, JPEG, noise addition, rotation, scaling, scalingâcropping, and sharpening. Performance and efficacy of algorithms of watermarking scheme is determined by measuring Peak Signal to Noise Ratio (PSNR), Bit Error Rate (BER) and Similarity parameter SIM ( X , X â ) and calibrated results are compared with other existing machine learning methods. As a watermark detector, machine learning techniques are used to learn neighbors relationship among pixels in a natural image has high relevance to its neighbors, so this relationship can be predicted by its neighbors using machine learning methods and watermark image can be extracted and detected and thereby ownership can be verified.
ER  - 

TY  - JOUR
T1  - Incremental regularized extreme learning machine and it×³s enhancement
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 134
EP  - 142
PY  - 2016/1/22/
T2  - 
AU  - Xu, Zhixin
AU  - Yao, Min
AU  - Wu, Zhaohui
AU  - Dai, Weihui
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.01.097
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011510
KW  - Extreme Learning Machine
KW  - Regularization
KW  - Incremental learning
KW  - Neural networks
AB  - Abstract
Extreme Learning Machine (ELM) proposed by Huang et al. [2] is a novel algorithm for single hidden layer feedforward neural networks (SLFNs) with extremely fast learning speed and good generalization performance. When new hidden nodes are added to the existing network, retraining the network would be time consuming, and EM-ELM [13] was proposed to calculate the output weights incrementally. However there are still two issues in EM-ELM: first, the initial hidden layer output matrix may be rank deficient thus the computation will loss accuracy; second, EM-ELM cannot always get good generalization performance due to overfitting. So we propose the improved version of EM-ELM based on regularization method called Incremental Regularized Extreme Learning Machine (IR-ELM). When new hidden node is added one by one, IR-ELM can update output weights recursively in a fast way. Enhancement of IR-ELM (EIR-ELM) that has a selection of hidden nodes to be added to the network is also introduced in this paper. Empirical studies on benchmark data sets for regression and classification problems have shown that IR-ELM (EIR-ELM) always gets better generalization performance than EM-ELM with the similar training time.
ER  - 

TY  - JOUR
T1  - Discriminative manifold extreme learning machine and applications to image and EEG signal classification
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 265
EP  - 277
PY  - 2016/1/22/
T2  - 
AU  - Peng, Yong
AU  - Lu, Bao-Liang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.118
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011704
KW  - Extreme learning machine
KW  - Discriminative information
KW  - Manifold information
KW  - Image classification
KW  - EEG
KW  - Emotion recognition
AB  - Abstract
Extreme learning machine (ELM) uses a non-iterative method to train single-hidden-layer feed-forward networks (SLFNs), which has been proven to be an efficient and effective learning model for both classification and regression. The main advantage of ELM lies in that the input weights as well as the hidden layer biases can be randomly generated, which contributes to the analytical solution of output weights. In this paper, we propose a discriminative manifold ELM (DMELM) by simultaneously considering the discriminative information and geometric structure of data; specifically, we exploit the discriminative information in the local neighborhood around each data point. To this end, a graph regularizer based on a newly designed graph Laplacian to characterize both properties is formulated and incorporated into the ELM objective. In DMELM, the output weights can also be obtained in analytical form. Extensive experiments are conducted on image and EEG signal classification to evaluate the effectiveness of DMELM. The results show that DMELM consistently achieves better performance than original ELM and yields promising results in comparison with several state-of-the-art algorithms, which suggests that both the discriminative as well as manifold information are beneficial to classification.
ER  - 

TY  - JOUR
T1  - Manifold learning in local tangent space via extreme learning machine
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 18
EP  - 30
PY  - 2016/1/22/
T2  - 
AU  - Wang, Qian
AU  - Wang, Weiguo
AU  - Nian, Rui
AU  - He, Bo
AU  - Shen, Yue
AU  - BjÃ¶rk, Kaj-Mikael
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.116
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011522
KW  - Extreme learning machine
KW  - Manifold learning
KW  - Local tangent space alignment
KW  - High-dimensional space
AB  - Abstract
In this paper, we propose a fast manifold learning strategy to estimate the underlying geometrical distribution and develop the relevant mathematical criterion on the basis of the extreme learning machine (ELM) in the high-dimensional space. The local tangent space alignment (LTSA) method has been used to perform the manifold production and the single hidden layer feedforward network (SLFN) is established via ELM to simulate the low-dimensional representation process. The scheme of the ELM ensemble then combines the individual SLFN for the model selection, where the manifold regularization mechanism has been brought into ELM to preserve the local geometrical structure of LTSA. Some developments have been done to evaluate the inherent representation embedding in the ELM learning. The simulation results have shown the excellent performance in the accuracy and efficiency of the developed approach.
ER  - 

TY  - JOUR
T1  - Extreme learning machine for missing data using multiple imputations
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 220
EP  - 231
PY  - 2016/1/22/
T2  - 
AU  - Sovilj, DuÅ¡an
AU  - Eirola, Emil
AU  - Miche, Yoan
AU  - BjÃ¶rk, Kaj-Mikael
AU  - Nian, Rui
AU  - Akusok, Anton
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.108
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011182
KW  - Extreme Learning Machine
KW  - Missing data
KW  - Multiple imputation
KW  - Gaussian mixture model
KW  - Mixture of Gaussians
KW  - Conditional distribution
AB  - Abstract
In the paper, we examine the general regression problem under the missing data scenario. In order to provide reliable estimates for the regression function (approximation), a novel methodology based on Gaussian Mixture Model and Extreme Learning Machine is developed. Gaussian Mixture Model is used to model the data distribution which is adapted to handle missing values, while Extreme Learning Machine enables to devise a multiple imputation strategy for final estimation. With multiple imputation and ensemble approach over many Extreme Learning Machines, final estimation is improved over the mean imputation performed only once to complete the data. The proposed methodology has longer running times compared to simple methods, but the overall increase in accuracy justifies this trade-off.
ER  - 

TY  - JOUR
T1  - Comparison of combining methods using Extreme Learning Machines under small sample scenario
JO  - Neurocomputing
VL  - 174, Part A
IS  - 
SP  - 4
EP  - 17
PY  - 2016/1/22/
T2  - 
AU  - Sovilj, DuÅ¡an
AU  - BjÃ¶rk, Kaj-Mikael
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.109
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011224
KW  - Extreme Learning Machine
KW  - Small sample data
KW  - Model selection
KW  - Model combining
KW  - Mallow×³s Model Averaging
KW  - Jackknife Model Averaging
AB  - Abstract
Making accurate predictions is a difficult task that is encountered throughout many research domains. In certain cases, the number of available samples is so scarce that providing reliable estimates is a challenging problem. In this paper, we are interested in giving as accurate predictions as possible based on the Extreme Learning Machine type of a neural network in small sample data scenarios. Most of the Extreme Learning Machine literature is focused on choosing a particular model from a pool of candidates, but such approach usually ignores model selection uncertainty and has inferior performance compared to combining methods. We empirically examine several model selection criteria coupled with new model combining approaches that were recently proposed. The results obtained indicate that a careful choice among the combinations must be performed in order to have the most accurate and stable predictions.
ER  - 

TY  - JOUR
T1  - ODOC-ELM: Optimal decision outputs compensation-based extreme learning machine for classifying imbalanced data
JO  - Knowledge-Based Systems
VL  - 92
IS  - 
SP  - 55
EP  - 70
PY  - 2016/1/15/
T2  - 
AU  - Yu, Hualong
AU  - Sun, Changyin
AU  - Yang, Xibei
AU  - Yang, Wankou
AU  - Shen, Jifeng
AU  - Qi, Yunsong
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2015.10.012
UR  - https://www.sciencedirect.com/science/article/pii/S0950705115003998
KW  - Extreme learning machine
KW  - Class imbalance learning
KW  - Decision outputs compensation
KW  - Prior data distributions
KW  - Optimization
AB  - Abstract
Extreme learning machine (ELM) has been one widely used learning paradigm to train single hidden layer feedforward network (SLFN). However, like many other classification algorithms, ELM may learn undesirable class boundaries from data with unbalanced classes. This paper first tries to analyze the reason of the damage caused by class imbalance for ELM, and then discusses the influence of several data distribution factors for the damage. Next, we present an optimal decision outputs compensation strategy to deal with the class imbalance problem in the context of ELM. Specifically, the outputs of the minority classes in ELM are properly compensated. For a binary-class problem, the compensation can be regarded as a single variable optimization problem, thus the golden section search algorithm is adopted to find the optimal compensation value. For a multi-class problem, the particle swarm optimization (PSO) algorithm is used to solve the multivariate optimization problem and to provide the optimal combination of compensations. Experimental results on lots of imbalanced data sets demonstrate the superiority of the proposed algorithm. Statistical results indicate that the proposed approach not only outperforms the original ELM, but also yields better or at least competitive results compared with several widely used and state-of-the-art class imbalance learning methods.
ER  - 

TY  - JOUR
T1  - PR-ELM: Parallel regularized extreme learning machine based on cluster
JO  - Neurocomputing
VL  - 173, Part 3
IS  - 
SP  - 1073
EP  - 1081
PY  - 2016/1/15/
T2  - 
AU  - Wang, Yueqing
AU  - Dou, Yong
AU  - Liu, Xinwang
AU  - Lei, Yuanwu
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.08.066
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215012461
KW  - Parallel
KW  - Extreme learning machine
KW  - Cluster
KW  - Data
KW  - Model
AB  - Abstract
Extreme learning machine (ELM) has been intensively studied during the last decade due to its high efficiency, effectiveness and easy-to-implementation. Recently, many variants, such as parallel ELM (P-ELM) incremental ELM and online sequential ELM(OS-ELM), have been proposed to improve its timing performance and enable its ability of incremental learning. In this paper, we propose two parallel variants, termed as data parallel regularized ELM (DPR-ELM) and model parallel regularized ELM (MPR-ELM), to further improve the computational efficiency of ELM in handling large scale learning tasks. Collectively, these two variants are called as parallel regularized ELM (PR-ELM). Specifically, our proposed algorithms are implemented on cluster with Message Passing Interface (MPI) environment. In summary, the advantages of the proposed PR-ELM algorithms over existing variants are highlighted as follows: (1) They have better parallelism since they train each data block or each sub-model independently. (2) They dramatically reduce the requirement of huge runtime memory since the whole datasets or the whole model are split into small chunks or sub-models. (3) Both DPR-ELM and MPR-ELM have better scalability since they are able to be configured on clusters with many more computing nodes. Extensive experiments have been conducted to validate the effectiveness of the proposed algorithms. As shown, DPR-ELM and MPR-ELM achieve 5.15Ã and 3.5Ã speedup on cluster with six nodes, respectively. Moreover, the speedup of DPR-ELM increases to 5.85Ã with the increase of the size of dataset, and this quantity is increased to 4Ã for MPR-ELM with the increase of the number of hidden nodes.
ER  - 

TY  - JOUR
T1  - Sequential active learning using meta-cognitive extreme learning machine
JO  - Neurocomputing
VL  - 173, Part 3
IS  - 
SP  - 835
EP  - 844
PY  - 2016/1/15/
T2  - 
AU  - Zhang, Yong
AU  - Er, Meng Joo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.08.037
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215012072
KW  - Active learning
KW  - Extreme learning machine
KW  - Meta-cognition
KW  - Sequential learning
AB  - Abstract
This paper proposes a fast and effective sequential active learning method using meta-cognitive extreme learning machine (SEAL-ELM). The proposed algorithm consists of two components, namely the cognitive component and the meta-cognitive component. The cognitive component is an online sequential extreme learning machine while the meta-cognitive component controls the learning process of the cognitive component using a self-regulating mechanism to decide what to learn, when to learn and how to learn the arriving samples. Active learning is employed to select different strategies, namely sample deletion, sample reserve and sample learning strategy to determine whether the data will be deleted directly, reserved for later use or used immediately. This is the first time the similarity of meta-cognitive machine learning and active learning is exploited. The meta-cognition mechanism and active learning principle are utilized to reduce the labeling efforts and costs. The use of ELM greatly reduces the computation complexity of the learning process. The new algorithm is evaluated on a set of real-world benchmark classification problems. Simulation results demonstrate the usefulness and effectiveness of sequential active learning and show that the SEAL-ELM can achieve similar or better learning accuracy with a much faster learning speed compared with the state-of-the-arts algorithms.
ER  - 

TY  - JOUR
T1  - An online sequential learning algorithm for regularized Extreme Learning Machine
JO  - Neurocomputing
VL  - 173, Part 3
IS  - 
SP  - 778
EP  - 788
PY  - 2016/1/15/
T2  - 
AU  - Shao, Zhifei
AU  - Er, Meng Joo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.08.029
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215011820
KW  - Extreme Learning Machine (ELM)
KW  - Regularized ELM (RELM)
KW  - Ridge regression
KW  - Online Sequential RELM (OS-RELM)
AB  - Abstract
The Extreme Learning Machine (ELM) is a novel learning scheme for single hidden layer feedforward neural networks, and it has attracted a great deal of research attention since the last decade because of its extremely fast learning speed. One popular variant of ELM is the Online Sequential ELM (OS-ELM), which can deal with sequential learning tasks. However, limitations exist in the OS-ELM such as requiring the initialization phase, pre-defined important parameters, running into singularity problem, inconsistent and potentially unreliable performance. In this paper, an Online Sequential Regularized ELM (OS-RELM) is proposed to address the aforementioned issues. The main idea is to incorporate the regularization method to further improve its generalization performance, and a new update formula is used to eliminate the initialization phase. To enable the OS-RELM to adapt to new data in an effective and reliable manner, an efficient Leave-One-Out Cross-Validation method is implemented. Finally, a matrix reconstruction method is employed to address the unstable update issue. Unlike some ELM variants that greatly jeopardize the speed advantage of the ELM, we strive to limit the computational load from the proposed scheme. Simulation results on benchmark problems show that the OS-RELM is a reliable and efficient algorithm with superior generalization performance than the OS-ELM.
ER  - 

TY  - JOUR
T1  - Breast mass classification in digital mammography based on extreme learning machine
JO  - Neurocomputing
VL  - 173, Part 3
IS  - 
SP  - 930
EP  - 941
PY  - 2016/1/15/
T2  - 
AU  - Xie, Weiying
AU  - Li, Yunsong
AU  - Ma, Yide
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.08.048
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215012205
KW  - Mammography CAD
KW  - Level set method
KW  - Feature selection
KW  - Extreme learning machine
KW  - Support vector machine
AB  - Abstract
This paper presents a novel computer-aided diagnosis (CAD) system for the diagnosis of breast cancer based on extreme learning machine (ELM). In view of a mammographic image, it is first eliminated interference in the preprocessing stages. Then, the preprocessed images are segmented by the level set model we proposed. Subsequently, a model of multidimensional feature vectors is built. Since not every feature vector contributes to the improvement of performance, feature selection is done by the combination of support vector machine (SVM) and extreme learning machine (ELM). Finally, an optimal subset of feature vectors is inputted into the classifiers for distinguishing malignant masses from benign ones. We also compare our breast mass classification approach based on ELM with several state-of-the-art classification models, and the results show that the proposed CAD system not only has good performance in terms of specificity, sensitivity and accuracy, but also achieves a significant reduction in training time compared with SVM and particle swarm optimization-support vector machine (PSO-SVM). Ultimately, our system achieves the better performance with average accuracy of 96.02% which indicates that the proposed segmentation model, the utilization of selected feature vectors and the effective classifier ELM provide satisfactory system.
ER  - 

TY  - JOUR
T1  - MI-ELM: Highly efficient multi-instance learning based on hierarchical extreme learning machine
JO  - Neurocomputing
VL  - 173, Part 3
IS  - 
SP  - 1044
EP  - 1053
PY  - 2016/1/15/
T2  - 
AU  - Liu, Qiang
AU  - Zhou, Sihang
AU  - Zhu, Chengzhang
AU  - Liu, Xinwang
AU  - Yin, Jianping
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.08.061
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215012333
KW  - Multi-instance learning
KW  - Hierarchical extreme learning machine
KW  - Optimization
KW  - Double-hidden layers feedforward network
AB  - Abstract
Multi-instance learning (MIL) is one of promising paradigms in the supervised learning aiming to handle real world classification problems where a classification target contains several featured sections, e.g., an image typically contains several salient regions. In this paper, we propose a highly efficient learning method for MI classification based on hierarchical extreme learning machine (ELM), called MI-ELM. Specifically, a double-hidden layers feedforward network (DLFN) is designed to serve as the MI classifier. Then, the MI classification is formulated as an optimization problem. Moreover, the output weights of DLFN can be analytically determined by solving the aforementioned optimization problem. The merits of MI-ELM are as follows: (i) MI-ELM extends the single-layer ELM to be a hierarchical one that well fits for training DLFNs in MI classification. (ii) The input and hidden-layer parameters of DLFNs are assigned randomly rather than tuned iteratively, and the output weights of DLFNs can be determined analytically in one step. Therefore, MI-ELM significantly enhances the efficiency of the DLFN without notable loss of the classification accuracy. Experimental results over several real-world data sets demonstrate that the proposed MI-ELM method significantly outperforms existing kernel methods for MI classification in terms of the classification accuracy and the classification time.
ER  - 

TY  - JOUR
T1  - A fast training algorithm for extreme learning machine based on matrix decomposition
JO  - Neurocomputing
VL  - 173, Part 3
IS  - 
SP  - 1951
EP  - 1958
PY  - 2016/1/15/
T2  - 
AU  - Li, Junpeng
AU  - Hua, Changchun
AU  - Tang, Yinggan
AU  - Guan, Xinping
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.09.067
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215014009
KW  - Extreme learning machine
KW  - Decomposition
KW  - Machine learning
KW  - Regression
KW  - Classification
AB  - Abstract
Extreme Learning Machine (ELM), a competitive machine learning technique for single-hidden-layer feedforward neural networks (SLFNNs), has proven to be efficient and effective algorithm for regression and classification problems. However, traditional ELM involves a large number of hidden nodes for complex real world regression and classification problems which increasing the computation burden. In this paper, a decomposition based fast ELM (DFELM) algorithm is proposed to effectively reduce the computational burden for large number of hidden nodes condition. Compared with ELM algorithm, DFELM algorithm has faster training time with a large number of hidden nodes maintaining the same accuracy performance. Experiment on three regression problems, six classification problems and a complex blast furnace modeling problem are carried out to verify the performance of DFELM algorithm. Moreover, the decomposition method can be extended to other modified ELM algorithms to further reduce the training time.
ER  - 

TY  - JOUR
T1  - Hybrid approach using fuzzy sets and extreme learning machine for classifying clinical datasets
JO  - Informatics in Medicine Unlocked
VL  - 2
IS  - 
SP  - 1
EP  - 11
PY  - 2016///
T2  - 
AU  - Nahato, Kindie Biredagn
AU  - Nehemiah, Khanna H.
AU  - Kannan, A.
SN  - 2352-9148
DO  - https://doi.org/10.1016/j.imu.2016.01.001
UR  - https://www.sciencedirect.com/science/article/pii/S2352914816000022
KW  - Extreme learning machine
KW  - Fuzzification
KW  - Fuzzy set
KW  - Classification
KW  - Euclidean distance
KW  - Membership function
AB  - Abstract
Data mining techniques play a major role in developing computer aided diagnosis systems and expert systems that will aid a physician in clinical decision making. In this work, a classifier that combines the relative merits of fuzzy sets and extreme learning machine (FELM) for clinical datasets is proposed. The three major subsystems in the FELM framework are preprocessing subsystem, fuzzification subsystem and classification subsystem. Missing value imputation and outlier elimination are handled by the preprocessing subsystem. The fuzzification subsystem maps each feature to a fuzzy set and the classification subsystem uses extreme learning machine for classification.

Cleveland heart disease (CHD), Statlog heart disease (SHD) and Pima Indian diabetes (PID) datasets from the University of California Irvine (UCI) machine learning repository have been used for experimentation. The CHD and SHD datasets have been experimented with two class labels one indicating the absence and the other indicating the presence of heart disease. The CHD dataset has also been experimented with five class labels, one class label indicating the absence of heart disease and the other four class labels indicating the severity of heart disease namely low risk, medium risk, high risk and serious. The PID data set has been experimented with two class labels one indicating the absence and the other indicating the presence of gestational diabetes.

The classifier has achieved an accuracy of 93.55% for CHD data set with two class labels; 73.77% for CHD data set with five class labels; 94.44% for SHD data set and 92.54% for PID dataset.
ER  - 

TY  - JOUR
T1  - Classification Based on Multilayer Extreme Learning Machine for Motor Imagery Task from EEG Signals
JO  - Procedia Computer Science
VL  - 88
IS  - 
SP  - 176
EP  - 184
PY  - 2016///
T2  - 7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA
AU  - Duan, Lijuan
AU  - Bao, Menghu
AU  - Miao, Jun
AU  - Xu, Yanhui
AU  - Chen, Juncheng
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2016.07.422
UR  - https://www.sciencedirect.com/science/article/pii/S1877050916316787
KW  - Electroencephalogram Classification
KW  - Motor Imagery
KW  - Extreme Learning Machine
KW  - Multilayer Extreme Learning Machine
AB  - Abstract
Classification of motor imagery electroencephalogram (EEG) is one of the most important technologies for BCI. To improve the accuracy, this paper introduces a classification system based on Multilayer Extreme Learning Machine (ML-ELM). In the system, the combination of PCA and LDA is chosen as the method of feature extraction and the ML-ELM is used to classify. The ML-ELM has not only the advantage which ELM has but also better performance than ELM. In the experiment, our method is compared with the methods based on ELM, such as kernel-ELM, Constrained-ELM and V-ELM, and some state-ofâthe-art methods on the same dataset. The experimental results show that ML-ELM is much more suitable for motor imagery EEG data and has better performance than the others.
ER  - 

TY  - JOUR
T1  - Denoising Laplacian multi-layer extreme learning machine
JO  - Neurocomputing
VL  - 171
IS  - 
SP  - 1066
EP  - 1074
PY  - 2016/1/1/
T2  - 
AU  - Zhang, Nan
AU  - Ding, Shifei
AU  - Shi, Zhongzhi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.07.058
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215010644
KW  - Extreme learning machine
KW  - Semi-supervised learning
KW  - Deep learning
KW  - Denoising
KW  - Manifold regularization
AB  - Abstract
Most of semi-supervised learning algorithms based on manifold regularization framework are surface learning algorithms, such as semi-supervised ELM (SS-ELM) and Laplacian smooth twin support vector machine (Lap-STSVM). Multi-layer extreme learning machine (ML-ELM) stacks extreme learning machine based auto encoder (ELM-AE) to create a multi-layer neural network. ML-ELM not only approximates the complicated function but also achieves fast training time. The outputs of ELM-AE are the same as inputs, which cannot guarantee the effectiveness of the learning feature representations. We put forward extreme learning machine based denoising auto encoder (ELM-DAE) which introduces local denoising criterion into ELM-AE and is used as the basic component for Denoising ML-ELM. Resembling ML-ELM, Denoising ML-ELM stacks ELM-DAE to create a deep network. And then we introduce manifold regularization into the model of Denoising ML-ELM and propose denoising Laplacian ML-ELM (Denoising Lap-ML-ELM). Denoising Lap-ML-ELM is more efficient than SS-ELM in classification and does not need to spend too much time. Experimental results show that Denoising ML-ELM and Denoising Lap-ML-ELM are effective learning algorithms.
ER  - 

TY  - JOUR
T1  - A Constrained Optimization based Extreme Learning Machine for noisy data regression
JO  - Neurocomputing
VL  - 171
IS  - 
SP  - 1431
EP  - 1443
PY  - 2016/1/1/
T2  - 
AU  - Yuong Wong, Shen
AU  - Siah Yap, Keem
AU  - Jen Yap, Hwa
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.07.065
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215010723
KW  - Extreme Learning Machine (ELM)
KW  - Noisy data regression
KW  - Constrained Optimization
KW  - Kernel function
AB  - Abstract
Most of the existing Artificial Intelligence (AI) models for data regression commonly assume that the data samples are completely clean without noise or worst yet, only the symmetrical noise is in considerations. However in the real world applications, this is often not the case. This paper addresses a significant note of inefficiency in methods for regression when dealing with outliers, especially for cases with polarity of noise involved (i.e., one sided noise with either only positive noise or negative noise). Using soft margin loss function concept, we propose Constrained Optimization method based Extreme Learning Machine for Regression, hereafter denoted as CO-ELM-R. The proposed method incorporates the two Lagrange multipliers that mimic Support Vector Regression (SVR) into the basis of ELM to cope with infeasible constraints of the regression optimization problem. Thus, CO-ELM-R will complement the recursive iterations of SVR in the training phase due to the fact that ELM is much simpler in structure and faster in implementation. The proposed CO-ELM-R is evaluated empirically on a few benchmark data sets and a real world application of NOx gas emission data set collected from one of the power plant in Malaysia. The obtained results have demonstrated its validity and efficacy in handling noisy data regression problems.
ER  - 

TY  - JOUR
T1  - A novel decomposition ensemble model with extended extreme learning machine for crude oil price forecasting
JO  - Engineering Applications of Artificial Intelligence
VL  - 47
IS  - 
SP  - 110
EP  - 121
PY  - 2016/1//
T2  - Artificial Intelligence Techniques in Product Engineering
AU  - Yu, Lean
AU  - Dai, Wei
AU  - Tang, Ling
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2015.04.016
UR  - https://www.sciencedirect.com/science/article/pii/S0952197615001037
KW  - Crude oil price forecasting
KW  - New production development
KW  - Artificial intelligence
KW  - Decomposition-and-ensemble learning paradigm
KW  - Extended extreme learning machine
AB  - Abstract
As one of the most important energy resources, an accurate prediction for crude oil price can effectively guarantee a rapid new production development with higher production quality and less production cost. Accordingly, a novel decomposition-and-ensemble learning paradigm integrating ensemble empirical mode decomposition (EEMD) and extended extreme learning machine (EELM) is proposed for crude oil price forecasting, based on the principle of âdecomposition and ensembleâ. This novel learning model makes contribution to literature by introducing the current powerful artificial intelligent (AI) technique of EELM in the ensemble model formulation. In the proposed method, EEMD, a competitive decomposition method, is first applied to divide the original data of crude oil price time series into a number of relatively regular components, for simplicity. Second, EELM, a currently proposed, powerful, effective and stable forecasting tool, is implemented to predict all components independently. Finally, these predicted results are aggregated into an ensemble result as final prediction, using simple addition ensemble method. For illustration and verification purposes, the proposed learning paradigm is used to predict the crude oil spot price of WTI. Empirical results demonstrate that the proposed novel ensemble learning paradigm statistically outperforms all considered benchmark models (including popular single models and similar ensemble models) in both prediction accuracy (in terms of level and directional measurement) and effectiveness (in terms of time saving and robustness), indicating that it is a promising tool to predict complicated time series with high volatility and irregularity.
ER  - 

TY  - JOUR
T1  - GPU-Accelerated Extreme Learning Machines for Imbalanced Data Streams with Concept Drift
JO  - Procedia Computer Science
VL  - 80
IS  - 
SP  - 1692
EP  - 1701
PY  - 2016///
T2  - International Conference on Computational Science 2016, ICCS 2016, 6-8 June 2016, San Diego, California, USA
AU  - Krawczyk, Bartosz
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2016.05.509
UR  - https://www.sciencedirect.com/science/article/pii/S1877050916309966
KW  - Data streams
KW  - Imbalanced data
KW  - Concept drift
KW  - Big data
KW  - Extreme learning machines
KW  - GPU.
AB  - Abstract
Mining data streams is one of the most vital fields in the current era of big data. Continuously arriving data may pose various problems, connected to their volume, variety or velocity. In this paper we focus on two important difficulties embedded in the nature of data streams: non- stationary nature and skewed class distributions. Such a scenario requires a classifier that is able to rapidly adapt itself to concept drift and displays robustness to class imbalance problem. We propose to use online version of Extreme Learning Machine that is enhanced by an efficient drift detector and method to alleviate the bias towards the majority class. We investigate three approaches based on undersampling, oversampling and cost-sensitive adaptation. Additionally, to allow for a rapid updating of the proposed classifier we show how to implement online Extreme Learning Machines with the usage of GPU. The proposed approach allows for a highly efficient mining of high-speed, drifting and imbalanced data streams with significant acceleration offered by GPU processing.
ER  - 

TY  - JOUR
T1  - An adaptive ensemble of on-line Extreme Learning Machines with variable forgetting factor for dynamic system prediction
JO  - Neurocomputing
VL  - 171
IS  - 
SP  - 693
EP  - 707
PY  - 2016/1/1/
T2  - 
AU  - Soares, Symone G.
AU  - AraÃºjo, Rui
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.07.035
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215010164
KW  - On-line Extreme Learning Machines
KW  - On-line ensemble
KW  - Ordered aggregation
KW  - Variable forgetting factor
AB  - Abstract
A demand for predictive models for on-line estimation of variables is increasing in industry. As industrial processes are time-varying, on-line learning algorithms should be adaptive to capture process changes. On-line ensemble methods have been shown to provide better generalization performance than single models in changing environments. However, most on-line ensembles do not include and exclude models during on-line operation. As a result, the ensembles have limited adaptation capability. Moreover, a higher performance can be obtained by combining a selected set of most relevant models of the ensemble for the current situation, rather than combining all the models. This paper proposes a new on-line learning ensemble of regressor models using an ordered aggregation (OA) technique which is able to provide on-line predictions of variables in changing environments. OA dynamically selects an optimal size and composition of a subset of models based on the minimization of the ensemble error on the newest sample. The proposed strategy overcomes the problem of defining the optimal ensemble size, and in most cases it obtains better performance than aggregating all the models. Models are added or removed for assuring adaptation of the ensemble in changing environments. Furthermore, this paper proposes and integrates a new on-line Extreme Learning Machine (ELM) neural network model with variable forgetting factor (FF) using the directional FF method which shows superior performance in industrial applications when compared to the well-known On-line Sequential ELM (OS-ELM) algorithm. Experiments are reported to demonstrate the performance and effectiveness of the proposed methods.
ER  - 

TY  - JOUR
T1  - On the kernel Extreme Learning Machine speedup
JO  - Pattern Recognition Letters
VL  - 68, Part 1
IS  - 
SP  - 205
EP  - 210
PY  - 2015/12/15/
T2  - 
AU  - Iosifidis, Alexandros
AU  - Gabbouj, Moncef
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2015.09.015
UR  - https://www.sciencedirect.com/science/article/pii/S0167865515003256
KW  - Kernel extreme learning machine
KW  - NystrÃ¶m approximation
KW  - Graph-based regularization
AB  - Abstract
In this paper, we describe an approximate method for reducing the time and memory complexities of the kernel Extreme Learning Machine variants. We show that, by adopting a NystrÃ¶m-based kernel ELM matrix approximation, we can define an ELM space exploiting properties of the kernel ELM space that can be subsequently used to apply several optimization schemes proposed in the literature for ELM network training. The resulted ELM network can achieve good performance, which is comparable to that of its standard kernel ELM counterpart, while overcoming the time and memory restrictions on kernel ELM algorithms that render their application in large-scale learning problems prohibitive.
ER  - 

TY  - JOUR
T1  - Dataset structure as prior information for parameter-free regularization of extreme learning machines
JO  - Neurocomputing
VL  - 169
IS  - 
SP  - 288
EP  - 294
PY  - 2015/12/2/
T2  - Learning for Visual Semantic Understanding in Big DataESANN 2014Industrial Data Processing and AnalysisSelected papers from the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)Selected papers from the 11th World Congress on Intelligent Control and Automation (WCICA2014)
AU  - Silvestre, Leonardo JosÃ©
AU  - Lemos, AndrÃ© Paim
AU  - Braga, JoÃ£o Pedro
AU  - Braga, AntÃ´nio PÃ¡dua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.11.080
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215003677
KW  - Regularization
KW  - Extreme learning machines
KW  - Affinity matrices
AB  - Abstract
This paper proposes a novel regularization approach for Extreme Learning Machines. Regularization is performed using a priori spatial information expressed by an affinity matrix. We show that the use of this type of a priori information is similar to perform Tikhonov regularization. Furthermore, if a parameter free affinity matrix is used, like the cosine similarity matrix, regularization is performed without any need for parameter tuning. Experiments are performed using classification problems to validate the proposed approach.
ER  - 

TY  - JOUR
T1  - A new method for constructing granular neural networks based on rule extraction and extreme learning machine
JO  - Pattern Recognition Letters
VL  - 67, Part 2
IS  - 
SP  - 138
EP  - 144
PY  - 2015/12/1/
T2  - Granular Mining and Knowledge Discovery
AU  - Xu, Xinzheng
AU  - Wang, Guanying
AU  - Ding, Shifei
AU  - Jiang, Xiangying
AU  - Zhao, Zuopeng
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2015.05.006
UR  - https://www.sciencedirect.com/science/article/pii/S0167865515001518
KW  - Granular neural networks
KW  - Single-hidden layer feedforward neural networks
KW  - Rough set
KW  - Rule extraction
KW  - Rough rule granular extreme learning machine
AB  - Abstract
This paper introduces a framework of granular neural networks named rough rule granular extreme learning machine (RRGELM), and develops its comprehensive design process. The proposed granular neural networks are formed on the basis of rough decision rules extracted from training samples through rough set theory. Firstly, Sample data are reduced by the algorithms of attributes reduction and attributes values reduction in rough set theory, and then they are compressed to an irredundant data set. In this data set, each sample can represent a rough rule, and is expressed as an If-Then rule which indicates the relationship between the input and output pattern. Moreover, the confidence level and the coverage level of each rule are calculated. Secondly, granular-neurons can be constructed through the If-Then rules, and all the granular-neurons constitute rule matching layer which is regarded as the hidden layer of the RRGELM. The linked weights between the input neurons and granular-neurons can be determined by the confidences of rough decision rules, while the linked weights between the output neurons and granular-neurons can be initialized as the contributions of the rough rules to the classification. Finally, the extreme learning machine (ELM) algorithm is introduced to improve the learning speed of the RRGELM, rather than the BP algorithm used by other traditional GNN models. Good performance of the proposed RRGELM is demonstrated on several well-known benchmark data sets.
ER  - 

TY  - JOUR
T1  - Extreme Learning Machines for spatial environmental data
JO  - Computers & Geosciences
VL  - 85, Part B
IS  - 
SP  - 64
EP  - 73
PY  - 2015/12//
T2  - Statistical learning in geoscience modelling: Novel algorithms and challenging case studies
AU  - Leuenberger, Michael
AU  - Kanevski, Mikhail
SN  - 0098-3004
DO  - https://doi.org/10.1016/j.cageo.2015.06.020
UR  - https://www.sciencedirect.com/science/article/pii/S0098300415300054
KW  - Extreme Learning Machine
KW  - Spatial environmental data
AB  - Abstract
The use of machine learning algorithms has increased in a wide variety of domains (from finance to biocomputing and astronomy), and nowadays has a significant impact on the geoscience community. In most real cases geoscience data modelling problems are multivariate, high dimensional, variable at several spatial scales, and are generated by non-linear processes. For such complex data, the spatial prediction of continuous (or categorical) variables is a challenging task. The aim of this paper is to investigate the potential of the recently developed Extreme Learning Machine (ELM) for environmental data analysis, modelling and spatial prediction purposes. An important contribution of this study deals with an application of a generic self-consistent methodology for environmental data driven modelling based on Extreme Learning Machine. Both real and simulated data are used to demonstrate applicability of ELM at different stages of the study to understand and justify the results.
ER  - 

TY  - JOUR
T1  - An intrusion detection system using network traffic profiling and online sequential extreme learning machine
JO  - Expert Systems with Applications
VL  - 42
IS  - 22
SP  - 8609
EP  - 8624
PY  - 2015/12/1/
T2  - 
AU  - Singh, Raman
AU  - Kumar, Harish
AU  - Singla, R.K.
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2015.07.015
UR  - https://www.sciencedirect.com/science/article/pii/S0957417415004753
KW  - Intrusion detection system
KW  - Feature selection technique
KW  - Network traffic dataset
KW  - Network traffic profiling
KW  - Online sequential extreme learning machine (OS-ELM)
AB  - Abstract
Anomaly based Intrusion Detection Systems (IDS) learn normal and anomalous behavior by analyzing network traffic in various benchmark datasets. Common challenges for IDSs are large amounts of data to process, low detection rates and high rates of false alarms. In this paper, a technique based on the Online Sequential Extreme Learning Machine (OS-ELM) is presented for intrusion detection. The proposed technique uses alpha profiling to reduce the time complexity while irrelevant features are discarded using an ensemble of Filtered, Correlation and Consistency based feature selection techniques. Instead of sampling, beta profiling is used to reduce the size of the training dataset. For performance evaluation of proposed technique the standard NSL-KDD 2009 (Network Security Laboratory-Knowledge Discovery and Data Mining) dataset is used. In this paper time and space complexity of the proposed technique is also discussed. The experimental results yielded an accuracy of 98.66% with a false positive rate of 1.74% and a detection time of 2.43 s for binary class NSL-KDD dataset. The proposed IDS achieve 97.67% of accuracy with 1.74% of false positive rate in 2.65 s of detection time for multi-class NSL-KDD dataset. The Kyoto University benchmark dataset is also used to test the proposed IDS. Accuracy of 96.37% with false positive rate of 5.76% is yielded by the proposed technique. The proposed technique outperforms other published techniques in terms of accuracy, false positive rate and detection time. Based on the experimental results achieved, we conclude that the proposed technique is an efficient method for network intrusion detection.
ER  - 

TY  - JOUR
T1  - An extreme learning machine based fast and accurate adaptive distance relaying scheme
JO  - International Journal of Electrical Power & Energy Systems
VL  - 73
IS  - 
SP  - 1002
EP  - 1014
PY  - 2015/12//
T2  - 
AU  - Dubey, Rahul
AU  - Samantaray, S.R.
AU  - Panigrahi, B.K.
SN  - 0142-0615
DO  - https://doi.org/10.1016/j.ijepes.2015.06.024
UR  - https://www.sciencedirect.com/science/article/pii/S014206151500280X
KW  - Adaptive distance relaying scheme (ADRS)
KW  - Fast adaptive distance relaying scheme (FADRS)
KW  - Power swing
KW  - Artificial neural networks (ANNs)
KW  - Extreme learning machine (ELM)
AB  - Abstract
The ideal trip characteristics of the distance relay is greatly affected by pre-fault system conditions, ground fault resistance, shunt capacitance and mutual coupling of transmission network. This paper presents an extreme learning machine (ELM) based fast and accurate adaptive relaying scheme for stand-alone distance protection of transmission network. The proposed ELM based fast adaptive distance relaying scheme (FADRS) is extensively validated on the two terminal transmission lines with complex mutual coupling and shunt capacitance and, the performance is compared with the conventional artificial neural networks (ANNs) based adaptive distance relaying scheme (ADRS). The simulation results show significant improvement in the performance indices such as relay speed and selectivity. Further, the performance of proposed FADRS is tested for stressed condition such as power swing and found to be effective and reliable.
ER  - 

TY  - JOUR
T1  - Efficient large-scale action recognition in videos using extreme learning machines
JO  - Expert Systems with Applications
VL  - 42
IS  - 21
SP  - 8274
EP  - 8282
PY  - 2015/11/30/
T2  - 
AU  - Varol, GÃ¼l
AU  - Salah, Albert Ali
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2015.06.013
UR  - https://www.sciencedirect.com/science/article/pii/S0957417415004078
KW  - Action recognition
KW  - Extreme learning machine
KW  - Fisher vector
KW  - Multimedia mining
AB  - Abstract
In this paper, we propose a novel and efficient system for large-scale action recognition from realistic video clips. Our approach combines several recent advances in this area. We use improved dense trajectory features in combination with Fisher vector encoding, and perform learning and classification with extreme learning machine classifiers. The resulting system is a fast and accurate alternative to more traditional action classification approaches like bag of words and support vector machines. Additionally, we use mid-level features that encode information about presence of humans in the videos, as well as color distributions. We extensively evaluate each step of our pipeline in a comparative manner, and report results on the recently published THUMOS 2014 benchmark, which was introduced as a challenge dataset with temporally untrimmed videos and 101 action classes. We achieve 63.37% mean average precision using the challenge protocol (i.e. sequestered test labels and limited system submissions), and got the third rank among eleven participants. The results show that it is possible to obtain a high accuracy with extreme learning machines in an efficient way, without using the extensively trained and computationally heavy deep neural networks that the top performing systems of the challenge incorporated.
ER  - 

TY  - JOUR
T1  - A novel extreme learning machine using privileged information
JO  - Neurocomputing
VL  - 168
IS  - 
SP  - 823
EP  - 828
PY  - 2015/11/30/
T2  - 
AU  - Zhang, Wenbo
AU  - Ji, Hongbing
AU  - Liao, Guisheng
AU  - Zhang, Yongquan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.05.042
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215007183
KW  - Extreme learning machine (ELM)
KW  - ELM+
KW  - Privileged information
KW  - Hidden information
KW  - Radar emitter recognition
AB  - Abstract
Extreme learning machine (ELM) is a competitive machine learning technique, which is much more efficient and usually lead to better generalization performance compared to the traditional classifiers. In order to further improve its performance, we proposed a novel ELM called ELM+ which introduces the privileged information to the traditional ELM method. This privileged information, which is ignored by the classical ELM but often exists in human teaching and learning, will optimize the training stage by constructing a set of correcting functions. We demonstrate the performance of ELM+ on datasets from UCI machine learning repository, MackeyâGlass time series and radar emitter recognition and also present the comparison with SVM, ELM and SVM+. The experimental results indicate the validity and advantage of our method.
ER  - 

TY  - JOUR
T1  - Universal consistency of extreme learning machine for RBFNs case
JO  - Neurocomputing
VL  - 168
IS  - 
SP  - 1132
EP  - 1137
PY  - 2015/11/30/
T2  - 
AU  - Liu, Xia
AU  - Wan, Anhua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.05.010
UR  - https://www.sciencedirect.com/science/article/pii/S092523121500627X
KW  - Extreme learning machine
KW  - Radial basis function networks
KW  - Universal consistency
AB  - Abstract
This paper concerns the universal consistency of extreme learning machine (ELM) for radial basis function networks (RBFNs). That is, the estimator constructed by ELM for RBFNs learning system can approximate an arbitrary regression function to any accuracy, as long as the number of the training samples is sufficiently large. Furthermore, we also give the conditions for the kernel functions, with which the corresponding ELM-RBFNs estimator is strongly universal consistency. These results not only underlie the feasibility of ELM for RBFNs case, but also provide guidance of practical selection for kernel functions in ELM application.
ER  - 

TY  - JOUR
T1  - Multi-channel descriptors and ensemble of Extreme Learning Machines for classification of remote sensing images
JO  - Signal Processing: Image Communication
VL  - 39, Part A
IS  - 
SP  - 111
EP  - 120
PY  - 2015/11//
T2  - 
AU  - CvetkoviÄ, Stevica
AU  - StojanoviÄ, MiloÅ¡ B.
AU  - NikoliÄ, SaÅ¡a V.
SN  - 0923-5965
DO  - https://doi.org/10.1016/j.image.2015.09.004
UR  - https://www.sciencedirect.com/science/article/pii/S0923596515001447
KW  - Scene classification
KW  - Multi-channel descriptor
KW  - Extreme learning machine
KW  - Ensemble of classifiers
AB  - Abstract
We present a method for real-time scene classification which achieves high accuracy without a time consuming descriptor learning step and kernelized classifiers. Robustness of the classification is achieved by combining the powerful multi-channel Gabor-based descriptors and an ensemble of Extreme Learning Machines (ELM). We first extend the recently introduced Binary Gabor Patterns (BGP) to multi-channel images. This is done by extracting BGP over several color channels and embedding an additional compact color layout descriptor. Then we propose an effective method for the aggregation of multiple ELMs into a single classification system, which leads to significant classification accuracy improvements. The experimental evaluation demonstrates that multi-channel color information constantly improves classification results. The integration of multiple ELMs into an ensemble using the proposed aggregation strategy significantly outperforms linear SVM in terms of accuracy, and reaches results similar to the non-linear SVM while operating in real time. Therefore, an ensemble of ELMs with the proposed aggregation strategy could be used as an efficient alternative to the non-linear SVM for remote sensing image classification tasks.
ER  - 

TY  - JOUR
T1  - An accelerating scheme for destructive parsimonious extreme learning machine
JO  - Neurocomputing
VL  - 167
IS  - 
SP  - 671
EP  - 687
PY  - 2015/11/1/
T2  - 
AU  - Zhao, Yong-Ping
AU  - Li, Bing
AU  - Li, Ye-Bo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.002
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215003926
KW  - Single-hidden layer feedforward network
KW  - Extreme learning machine
KW  - Destructive algorithm
KW  - Constructive algorithms
KW  - Sparseness
AB  - Abstract
Constructive and destructive parsimonious extreme learning machines (CP-ELM and DP-ELM) were recently proposed to sparsify ELM. In comparison with CP-ELM, DP-ELM owns the advantage in the number of hidden nodes, but it loses the edge with respect to the training time. Hence, in this paper an equivalent measure is proposed to accelerate DP-ELM (ADP-ELM). As a result, ADP-ELM not only keeps the same hidden nodes as DP-ELM but also needs less training time than CP-ELM, which is especially important for the training time sensitive scenarios. The similar idea is extended to regularized ELM (RELM), yielding ADP-RELM. ADP-RELM accelerates the training process of DP-RELM further, and it works better than CP-RELM in terms of the number of hidden nodes and the training time. In addition, the computational complexity of the proposed accelerating scheme is analyzed in theory. From reported results on ten benchmark data sets, the effectiveness and usefulness of the proposed accelerating scheme in this paper is confirmed experimentally.
ER  - 

TY  - JOUR
T1  - Generalization ability of extreme learning machine with uniformly ergodic Markov chains
JO  - Neurocomputing
VL  - 167
IS  - 
SP  - 528
EP  - 534
PY  - 2015/11/1/
T2  - 
AU  - Yuan, Peipei
AU  - Chen, Hong
AU  - Zhou, Yicong
AU  - Deng, Xiaoyan
AU  - Zou, Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.041
UR  - https://www.sciencedirect.com/science/article/pii/S092523121500510X
KW  - Generalization ability
KW  - Extreme learning machine
KW  - Uniformly ergodic Markov chain
AB  - Abstract
Extreme learning machine (ELM) has gained increasing attention for its computation feasibility on various applications. However, the previous generalization analysis of ELM relies on the independent and identically distributed (i.i.d) samples. In this paper, we go far beyond this restriction by investigating the generalization bound of the ELM classification associated with the uniform ergodic Markov chains (u.e.M.c) samples. The upper bound of the misclassification error is estimated for the ELM classification showing that the satisfactory learning rate can be achieved even for the dependent samples. Empirical evaluations on real-word datasets are provided to compare the predictive performance of ELM with independent and Markov sampling.
ER  - 

TY  - JOUR
T1  - Extreme learning machine based supervised subspace learning
JO  - Neurocomputing
VL  - 167
IS  - 
SP  - 158
EP  - 164
PY  - 2015/11/1/
T2  - 
AU  - Iosifidis, Alexandros
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.083
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215006335
KW  - Extreme Learning Machine
KW  - Supervised subspace learning
KW  - Network targets calculation
AB  - Abstract
This paper proposes a novel method for supervised subspace learning based on Single-hidden Layer Feedforward Neural networks. The proposed method calculates appropriate network target vectors by formulating a Bayesian model exploiting both the labeling information available for the training data and geometric properties of the training data, when represented in the feature space determined by the network×³s hidden layer outputs. After the calculation of the network target vectors, Extreme Learning Machine-based neural network training is applied and classification is performed using a Nearest Neighbor classifier. Experimental results on publicly available data sets show that the proposed approach consistently outperforms the standard ELM approach, as well as other standard methods.
ER  - 

TY  - JOUR
T1  - Nonlinear regression in environmental sciences using extreme learning machines: A comparative evaluation
JO  - Environmental Modelling & Software
VL  - 73
IS  - 
SP  - 175
EP  - 188
PY  - 2015/11//
T2  - 
AU  - Lima, Aranildo R.
AU  - Cannon, Alex J.
AU  - Hsieh, William W.
SN  - 1364-8152
DO  - https://doi.org/10.1016/j.envsoft.2015.08.002
UR  - https://www.sciencedirect.com/science/article/pii/S1364815215300281
KW  - Extreme learning machines
KW  - Support vector machine
KW  - Artificial neural network
KW  - Regression
KW  - Environmental science
KW  - Machine learning
AB  - Abstract
The extreme learning machine (ELM), a single-hidden layer feedforward neural network algorithm, was tested on nine environmental regression problems. The prediction accuracy and computational speed of the ensemble ELM were evaluated against multiple linear regression (MLR) and three nonlinear machine learning (ML) techniques â artificial neural network (ANN), support vector regression and random forest (RF). Simple automated algorithms were used to estimate the parameters (e.g. number of hidden neurons) needed for model training. Scaling the range of the random weights in ELM improved its performance. Excluding large datasets (with large number of cases and predictors), ELM tended to be the fastest among the nonlinear models. For large datasets, RF tended to be the fastest. ANN and ELM had similar skills, but ELM was much faster than ANN except for large datasets. Generally, the tested ML techniques outperformed MLR, but no single method was best for all the nine datasets.
ER  - 

TY  - JOUR
T1  - QR factorization based Incremental Extreme Learning Machine with growth of hidden nodes
JO  - Pattern Recognition Letters
VL  - 65
IS  - 
SP  - 177
EP  - 183
PY  - 2015/11/1/
T2  - 
AU  - Ye, Yibin
AU  - Qin, Yang
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2015.07.031
UR  - https://www.sciencedirect.com/science/article/pii/S0167865515002408
KW  - Extreme Learning Machine(ELM)
KW  - Incremental learning
KW  - QR factorization
AB  - Abstract
In this paper, a computationally competitive incremental algorithm based on QR factorization is proposed, to automatically determine the number of hidden nodes in generalized single-hidden-layer feedforward networks (SLFNs). This approach, QR factorization based Incremental Extreme Learning Machine (QRI-ELM), is able to add random hidden nodes to SLFNs one by one. The computational complexity of this approach is analyzed in this paper as well. Simulation results show and verify that our new approach is fast and effective with good generalization and accuracy performance.
ER  - 

TY  - JOUR
T1  - Sparse extreme learning machine classifier exploiting intrinsic graphs
JO  - Pattern Recognition Letters
VL  - 65
IS  - 
SP  - 192
EP  - 196
PY  - 2015/11/1/
T2  - 
AU  - Iosifidis, Alexandros
AU  - Tefas, Anastasios
AU  - Pitas, Ioannis
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2015.07.036
UR  - https://www.sciencedirect.com/science/article/pii/S0167865515002457
KW  - Sparse extreme learning machine
KW  - Intrinsic graphs
KW  - Single-hidden layer neural networks
AB  - Abstract
This paper presents an analysis of the recently proposed sparse extreme learning machine (S-ELM) classifier and describes an optimization scheme that can be used to calculate the network output weights. This optimization scheme exploits intrinsic graph structures in order to describe geometric data relationships in the so-called ELM space. Kernel formulations of the approach operating in ELM spaces of arbitrary dimensions are also provided. It is shown that the application of the optimization scheme exploiting geometric data relationships in the original ELM space is equivalent to the application of the original S-ELM to a transformed ELM space. The experimental results show that the incorporation of geometric data relationships in S-ELM can lead to enhanced performance.
ER  - 

TY  - JOUR
T1  - Extreme learning machine with parallel layer perceptrons
JO  - Neurocomputing
VL  - 166
IS  - 
SP  - 164
EP  - 171
PY  - 2015/10/20/
T2  - 
AU  - Tavares, L.D.
AU  - Saldanha, R.R.
AU  - Vieira, D.A.G.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.018
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215004622
KW  - Parallel layer perceptrons
KW  - Extreme learning machine
KW  - Structural risk minimization
KW  - Least square estimate
AB  - Abstract
This paper proposes using the Parallel Layer Perceptron (PLP) network, instead of the Single Layer Feedforward neural network (SLFN) in the Extreme Learning Machine (ELM) framework. Differently from the SLFNs which consider cascade layers, the PLP is designed to accomplish also parallel layers, being the SLFN its particular case. This paper explores a particular PLP configuration which considers a nonlinear layer in parallel with a linear layer. For n inputs and m nonlinear neurons, it provides ( n + 1 ) m linear parameters, while the SLFN would have only m linear parameters (one for each hidden neuron). Since the ELM is based on adjusting only the linear parameters using the least squares estimate (LSE), the PLP network provides more freedom for the proper adjustment. Results from 12 regression and 6 classification problems are presented considering the training and test errors, the linear vector norm and the system condition number. They point out that the PLP-ELM framework is more efficient than the SLFN-ELM approach.
ER  - 

TY  - JOUR
T1  - AL-ELM: One uncertainty-based active learning algorithm using extreme learning machine
JO  - Neurocomputing
VL  - 166
IS  - 
SP  - 140
EP  - 150
PY  - 2015/10/20/
T2  - 
AU  - Yu, Hualong
AU  - Sun, Changyin
AU  - Yang, Wankou
AU  - Yang, Xibei
AU  - Zuo, Xin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.019
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215004646
KW  - Active learning
KW  - Extreme learning machine
KW  - Uncertainty measure
KW  - Uncertainty sampling
KW  - Pool-based active learning
AB  - Abstract
It is well known that in supervised learning, active learning could effectively decrease the complexity of training instances without obvious loss of the classification performance. Generally, active learning is applied in the scenario that lots of instances are easy to be acquired, but labeling them is expensive and/or time-consuming. In this study, we try to implement active learning by using extreme learning machine (ELM) classifier based on three reasons as follows: (1) ELM has light computational costs, (2) ELM has strong generalization ability which is even comparable with support vector machine (SVM) and (3) ELM could be directly applied on both binary-class and multiclass problems. Specifically, an active learning algorithm based on ELM classifier named AL-ELM is proposed in this paper. During active learning, AL-ELM estimates the uncertainty of each unlabeled instance by creating a mapping relation between the actual outputs of the instance in ELM and the approximated membership probability of the same instance. In other words, ELM is converted as the equivalent Bayes classifier. On each iteration, those most uncertain instances are extracted and labeled to promote the quality of classification model. The learning procedure stops until it satisfies a pre-designed criterion. Experimental results on 20 benchmark data sets show that AL-ELM is better than or at least comparable to several state-of-the-art uncertainty-based active learning algorithms. Also, in contrast with several other algorithms, AL-ELM could effectively decrease the running time of learning procedure.
ER  - 

TY  - JOUR
T1  - Semi-supervised deep extreme learning machine for Wi-Fi based localization
JO  - Neurocomputing
VL  - 166
IS  - 
SP  - 282
EP  - 293
PY  - 2015/10/20/
T2  - 
AU  - Gu, Yang
AU  - Chen, Yiqiang
AU  - Liu, Junfa
AU  - Jiang, Xinlong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.04.011
UR  - https://www.sciencedirect.com/science/article/pii/S092523121500418X
KW  - Wi-Fi indoor localization
KW  - Semi-supervised learning
KW  - Deep learning
KW  - Extreme Learning Machine (ELM)
AB  - Abstract
Along with the proliferation of mobile devices and wireless signal coverage, indoor localization based on Wi-Fi gets great popularity. Fingerprint based method is the mainstream approach for Wi-Fi indoor localization, for it can achieve high localization performance as long as labeled data are sufficient. However, the number of labeled data is always limited due to the high cost of data acquisition. Nowadays, crowd sourcing becomes an effective approach to gather large number of data; meanwhile, most of them are unlabeled. Therefore, it is worth studying the use of unlabeled data to improve localization performance. To achieve this goal, a novel algorithm Semi-supervised Deep Extreme Learning Machine (SDELM) is proposed, which takes the advantages of semi-supervised learning, Deep Leaning (DL), and Extreme Learning Machine (ELM), so that the localization performance can be improved both in the feature extraction procedure and in the classifier. The experimental results in real indoor environments show that the proposed SDELM not only outperforms other compared methods but also reduces the calibration effort with the help of unlabeled data.
ER  - 

TY  - JOUR
T1  - Discriminative clustering via extreme learning machine
JO  - Neural Networks
VL  - 70
IS  - 
SP  - 1
EP  - 8
PY  - 2015/10//
T2  - 
AU  - Huang, Gao
AU  - Liu, Tianchi
AU  - Yang, Yan
AU  - Lin, Zhiping
AU  - Song, Shiji
AU  - Wu, Cheng
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2015.06.002
UR  - https://www.sciencedirect.com/science/article/pii/S0893608015001239
KW  - Discriminative clustering
KW  - Extreme learning machine
KW  - k  -means
KW  - Linear discriminant analysis
AB  - Abstract
Discriminative clustering is an unsupervised learning framework which introduces the discriminative learning rule of supervised classification into clustering. The underlying assumption is that a good partition (clustering) of the data should yield high discrimination, namely, the partitioned data can be easily classified by some classification algorithms. In this paper, we propose three discriminative clustering approaches based on Extreme Learning Machine (ELM). The first algorithm iteratively trains weighted ELM (W-ELM) classifier to gradually maximize the data discrimination. The second and third methods are both built on Fisherâs Linear Discriminant Analysis (LDA); but one approach adopts alternative optimization, while the other leverages kernel k -means. We show that the proposed algorithms can be easily implemented, and yield competitive clustering accuracy on real world data sets compared to state-of-the-art clustering methods.
ER  - 

TY  - JOUR
T1  - Landmark recognition with sparse representation classification and extreme learning machine
JO  - Journal of the Franklin Institute
VL  - 352
IS  - 10
SP  - 4528
EP  - 4545
PY  - 2015/10//
T2  - 
AU  - Cao, Jiuwen
AU  - Zhao, Yanfei
AU  - Lai, Xiaoping
AU  - Ong, Marcus Eng Hock
AU  - Yin, Chun
AU  - Koh, Zhi Xiong
AU  - Liu, Nan
SN  - 0016-0032
DO  - https://doi.org/10.1016/j.jfranklin.2015.07.002
UR  - https://www.sciencedirect.com/science/article/pii/S0016003215002768
AB  - Abstract
Along with the rapid development of intelligent mobile terminals, applications on landmark recognition attract increasingly attentions by world wide researchers in the past several years. Although promising achievements have been presented, designing a robust recognition system with an accurate recognition rate and fast response speed is still challenging. To address these issues, we propose a novel landmark recognition algorithm in this paper using the spatial pyramid kernel based bag-of-words (SPK-BoW) histogram approach with the feedforward artificial neural networks (FNN) and the sparse representation classifier (SRC). In the proposed algorithm, the SPK-BoW approach is first employed to extract features and construct an overcomplete dictionary for landmark image representation. Then, the FNN trained with the extreme learning machine (ELM) algorithm combined with the SRC is implemented for landmark image recognition. We conduct experiments using the Nanyang Technological University (NTU) campus landmark database to show that the proposed method achieves a high recognition rate than ELM and a lower response time than the sparse representation technique.
ER  - 

TY  - JOUR
T1  - An improved cuckoo search based extreme learning machine for medical data classification
JO  - Swarm and Evolutionary Computation
VL  - 24
IS  - 
SP  - 25
EP  - 49
PY  - 2015/10//
T2  - 
AU  - Mohapatra, P.
AU  - Chakravarty, S.
AU  - Dash, P.K.
SN  - 2210-6502
DO  - https://doi.org/10.1016/j.swevo.2015.05.003
UR  - https://www.sciencedirect.com/science/article/pii/S2210650215000413
KW  - Extreme learning machine (ELM)
KW  - Online sequential extreme learning machine (OSELM)
KW  - Cuckoo search (CS)
KW  - Cuckoo search based extreme learning machine (CSELM)
KW  - Improved cuckoo search based extreme learning machine (ICSELM)
AB  - Abstract
Machine learning techniques are being increasingly used for detection and diagnosis of diseases for its accuracy and efficiency in pattern classification. In this paper, improved cuckoo search based extreme learning machine (ICSELM) is proposed to classify binary medical datasets. Extreme learning machine (ELM) is widely used as a learning algorithm for training single layer feed forward neural networks (SLFN) in the field of classification. However, to make the model more stable, an evolutionary algorithm improved cuckoo search (ICS) is used to pre-train ELM by selecting the input weights and hidden biases. Like ELM, MooreâPenrose (MP) generalized inverse is used in ICSELM to analytically determines the output weights. To evaluate the effectiveness of the proposed model, four benchmark datasets, i.e. Breast Cancer, Diabetes, Bupa and Hepatitis from the UCI Repository of Machine Learning are used. A number of useful performance evaluation measures including accuracy, sensitivity, specificity, confusion matrix, Gmean, F-score and norm of the output weights as well as the area under the receiver operating characteristic (ROC) curve are computed. The results are analyzed and compared with both ELM based models like ELM, on-line sequential extreme learning algorithm (OSELM), CSELM and other artificial neural networks i.e. multi-layered perceptron (MLP), MLPCS, MLPICS and radial basis function neural network (RBFNN), RBFNNCS, RBFNNICS. The experimental results demonstrate that the ICSELM model outperforms other models.
ER  - 

TY  - JOUR
T1  - Positive and negative correlation input attributes oriented subnets based double parallel extreme learning machine (PNIAOS-DPELM) and its application to monitoring chemical processes in steady state
JO  - Neurocomputing
VL  - 165
IS  - 
SP  - 171
EP  - 181
PY  - 2015/10/1/
T2  - 
AU  - He, Yanlin
AU  - Geng, ZhiQiang
AU  - Zhu, QunXiong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.03.007
UR  - https://www.sciencedirect.com/science/article/pii/S0925231215002775
KW  - Extreme learning machine
KW  - Single-hidden-layer feed-forward neural networks
KW  - Auto-associative neural network
KW  - Correlation coefficient analysis
KW  - Steady state regression
AB  - Abstract
Extreme learning machine (ELM) is an effective learning algorithm for single-hidden-layer feed-forward neural networks (SLFNNs). Due to its easiness in theory and implementation, ELM has been widely used in many fields. In order to further enhance the generalization performance of ELM, a positive and negative correlation input attributes oriented subnets based double parallel extreme learning machine (PCNCIAOS-DPELM) is proposed in this paper. A salient feature in the PNIAOS-DPELM is that there are two special subnets. In one of the two subnets, the input attributes have a positive correlation to the outputs. In another subnet, the input attributes have a negative correlation to the outputs. The two kinds of input attributes can be obtained by separating the input attributes into two categories using the correlation coefficient analysis. Then according to the categories, the two subnets can be established. The two subnets are based on well-trained auto-associative neural networks (AANNs), which can extract the nonlinear information of the input attributes and remove the redundant information. An advantage in PNIAOS-DPELM is that the proper number of the nodes in the hidden layer can be determined. To test the validity of PNIAOS-DPELM, it is applied to monitoring three chemical processes in steady state. Meanwhile, ELM, double parallel ELM (DP-ELM), and ELM with kernel (ELMK) were developed for comparisons. Experimental results demonstrated that PNIAOS-DPELM could achieve better regression precision and have better stable ability than ELM, DP-ELM, and ELMK did during the generalization phase.
ER  - 

TY  - JOUR
T1  - Extreme learning machine based prediction of daily dew point temperature
JO  - Computers and Electronics in Agriculture
VL  - 117
IS  - 
SP  - 214
EP  - 225
PY  - 2015/9//
T2  - 
AU  - Mohammadi, Kasra
AU  - Shamshirband, Shahaboddin
AU  - Motamedi, Shervin
AU  - PetkoviÄ, Dalibor
AU  - Hashim, Roslan
AU  - Gocic, Milan
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2015.08.008
UR  - https://www.sciencedirect.com/science/article/pii/S0168169915002343
KW  - Dew point temperature
KW  - Extreme learning machine (ELM)
KW  - Prediction
AB  - Abstract
The dew point temperature is a significant element particularly required in various hydrological, climatological and agronomical related researches. This study proposes an extreme learning machine (ELM)-based model for prediction of daily dew point temperature. As case studies, daily averaged measured weather data collected for two Iranian stations of Bandar Abass and Tabass, which enjoy different climate conditions, were used. The merit of the ELM model is evaluated against support vector machine (SVM) and artificial neural network (ANN) techniques. The findings from this research work demonstrate that the proposed ELM model enjoys much greater prediction capability than the SVM and ANN models so that it is capable of predicting daily dew point temperature with very favorable accuracy. For Tabass station, the mean absolute bias error (MABE), root mean square error (RMSE) and correlation coefficient (R) achieved for the ELM model are 0.3240 Â°C, 0.5662 Â°C and 0.9933, respectively, while for the SVM model the values are 0.7561 Â°C, 1.0086 Â°C and 0.9784, respectively and for the ANN model are 1.0324 Â°C, 1.2589 Â°C and 0.9663, respectively. For Bandar Abass station, the MABE, RMSE and R for the ELM model are 0.5203 Â°C, 0.6709 Â°C and 0.9877, respectively whereas for the SVM model the values are 1.0413 Â°C, 1.2105 Â°C and 0.9733, and for the ANN model are 1.3205 Â°C, 1.5530 Â°C and 0.9617, respectively. The study results convincingly advocate that ELM can be employed as an efficient method to predict daily dew point temperature with much higher precision than the SVM and ANN techniques.
ER  - 

TY  - JOUR
T1  - Kalman filter-based method for Online Sequential Extreme Learning Machine for regression problems
JO  - Engineering Applications of Artificial Intelligence
VL  - 44
IS  - 
SP  - 101
EP  - 110
PY  - 2015/9//
T2  - 
AU  - Nobrega, Jarley Palmeira
AU  - Oliveira, Adriano L.I.
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2015.05.010
UR  - https://www.sciencedirect.com/science/article/pii/S0952197615001219
KW  - Online sequential learning
KW  - Extreme learning machine
KW  - Online Sequential Extreme Learning Machine
KW  - Kalman filter regression
KW  - Multicollinearity
AB  - Abstract
In this paper, a new sequential learning algorithm is constructed by combining the Online Sequential Extreme Learning Machine (OS-ELM) and Kalman filter regression. The Kalman Online Sequential Extreme Learning Machine (KOSELM) handles the problem of multicollinearity of the OS-ELM, which can generate poor predictions and unstable models. The KOSELM learns the training data one-by-one or chunk-by-chunk by adjusting the variance of the output weights through the Kalman filter. The performance of the proposed algorithm has been validated on benchmark regression datasets, and the results show that KOSELM can achieve a higher learning accuracy than OS-ELM and its related extensions. A statistical validation for the differences of the accuracy for all algorithms is performed, and the results confirm that KOSELM has better stability than ReOS-ELM, TOSELM and LS-IELM.
ER  - 

TY  - JOUR
T1  - A hybrid method based on extreme learning machine and k-nearest neighbor for cloud classification of ground-based visible cloud image
JO  - Neurocomputing
VL  - 160
IS  - 
SP  - 238
EP  - 249
PY  - 2015/7/21/
T2  - 
AU  - Xia, Min
AU  - Lu, Weitao
AU  - Yang, Jun
AU  - Ma, Ying
AU  - Yao, Wen
AU  - Zheng, Zichen
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2015.02.022
UR  - https://www.sciencedirect.com/science/article/pii/S092523121500171X
KW  - Cloud classification
KW  - Extreme learning machine
KW  - Sky cloud image
KW  - Cloud detection
KW  - k Nearest neighbor
AB  - Abstract
A classification scheme based on extreme learning machine and k nearest neighbor is proposed for cloud classification. In this work, 21 characteristic parameters of texture features, color features and shape features are selected from four different sky conditions (cumulus, stratus, cirrus and clear sky) for classification. The results show that the new scheme using texture features, color features and shape features together can get better performance than using these features alone or any two of them together. When all 21 features are used for classification, the accurate identification rates of cumulus, stratus, cirrus and clear sky are 84.56%, 78.06%, 76.67% and 100.00% respectively, with an average of 84.82%. The proposed model can benefit from the merits of the k-nearest neighbor and the extreme learning machine through its novel structure with high robustness particularly for cloud classification. The simulation results demonstrate that the proposed model in this work is practical for cloud classification and outperforms extreme learning machine (ELM) models, artificial neural network (ANN), k-nearest neighbor (KNN), hybrid method based on KNN and ANN ( KNN â ANN ), and support vector machine (SVM).
ER  - 

TY  - JOUR
T1  - Prediction of dynamic voltage stability status based on Hopf and limit induced bifurcations using extreme learning machine
JO  - International Journal of Electrical Power & Energy Systems
VL  - 69
IS  - 
SP  - 150
EP  - 159
PY  - 2015/7//
T2  - 
AU  - Velayati, Mohammad Hossein
AU  - Amjady, Nima
AU  - Khajevandi, Issa
SN  - 0142-0615
DO  - https://doi.org/10.1016/j.ijepes.2015.01.005
UR  - https://www.sciencedirect.com/science/article/pii/S0142061515000241
KW  - Hopf Bifurcation (HB)
KW  - Limit Induced Bifurcation (LIB)
KW  - Forecast process
KW  - Extreme learning machine
AB  - Abstract
Evaluation of voltage stability status considering its dynamic boundaries is a key issue for saving global stability of power systems. However, this evaluation is a computationally demanding task and its implementation is very hard (if not impossible) for on-line environments such as dispatching centers of power systems. In this paper, a new viewpoint for the problem based on modeling it as a forecast process is proposed, which can be implemented with a low computation burden for practical power systems. For this purpose, a voltage stability classification model considering Hopf and limit induced bifurcations is proposed and a new forecast strategy to predict voltage stability class label based on the proposed classification is suggested. The suggested forecast strategy is composed of an information theoretic feature selection technique, extreme learning machine (ELM) as the forecast engine and a line search procedure to fine-tune the settings. The effectiveness of the proposed classification model and forecast strategy is extensively illustrated on the New England 39-bus and IEEE 145-bus test systems.
ER  - 

TY  - JOUR
T1  - Parsimonious regularized extreme learning machine based on orthogonal transformation
JO  - Neurocomputing
VL  - 156
IS  - 
SP  - 280
EP  - 296
PY  - 2015/5/25/
T2  - 
AU  - Zhao, Yong-Ping
AU  - Wang, Kang-Kang
AU  - Li, Ye-Bo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.12.046
UR  - https://www.sciencedirect.com/science/article/pii/S092523121401710X
KW  - Extreme learning machine
KW  - Sparseness
KW  - Tikhonov regularization
KW  - Orthogonal transformation
KW  - Condition number
AB  - Abstract
Recently, two parsimonious algorithms were proposed to sparsify extreme learning machine (ELM), i.e., constructive parsimonious ELM (CP-ELM) and destructive parsimonious ELM (DP-ELM). In this paper, the ideas behind CP-ELM and DP-ELM are extended to the regularized ELM (RELM), thus obtaining CP-RELM and DP-RELM. For CP-RELM(DP-RELM), there are two schemes to realize it, viz. CP-RELM-I and CP-RELM-II(DP-RELM-I and DP-RELM-II). Generally speaking, CP-RELM-II(DP-RELM-II) outperforms CP-RELM-I(DP-RELM-I) in terms of parsimoniousness. Under nearly the same generalization, compared with CP-ELM(DP-ELM), CP-RELM-II(DP-RELM-II) usually needs fewer hidden nodes. In addition, different from CP-ELM and DP-ELM, for CP-RELM and DP-RELM the number of candidate hidden nodes may be larger than the number of training samples, which assists the selection of much better hidden nodes for constructing more compact networks. Finally, eleven benchmark data sets divided into two groups are utilized to do experiments and the usefulness of the proposed algorithms is reported.
ER  - 

TY  - JOUR
T1  - Sequential extreme learning machine incorporating survival error potential
JO  - Neurocomputing
VL  - 155
IS  - 
SP  - 194
EP  - 204
PY  - 2015/5/1/
T2  - 
AU  - Sun, Lei
AU  - Chen, Badong
AU  - Toh, Kar-Ann
AU  - Lin, Zhiping
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.12.029
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214016932
KW  - Sequential learning machine
KW  - Extreme learning machine
KW  - Information measure
AB  - Abstract
A sequential extreme learning machine incorporating a noise compensation scheme via an information measure is developed. In this design, the computationally simple extreme learning machine architecture is maintained while survival error information potential function provides a mechanism for noise compensation. The error compensation is updated online via an error codebook design where an error tolerant and stable solution is obtained. The developed method is tested on chaotic time sequence as well as benchmark data sets. Experimental results show potential applications for the developed method.
ER  - 

TY  - JOUR
T1  - A data-attribute-space-oriented double parallel (DASODP) structure for enhancing extreme learning machine: Applications to regression datasets
JO  - Engineering Applications of Artificial Intelligence
VL  - 41
IS  - 
SP  - 65
EP  - 74
PY  - 2015/5//
T2  - 
AU  - He, Yan-Lin
AU  - Geng, Zhi-Qiang
AU  - Zhu, Qun-Xiong
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2015.02.001
UR  - https://www.sciencedirect.com/science/article/pii/S0952197615000317
KW  - Extreme learning machine
KW  - Single-hidden-layer feed-forward neural network
KW  - Neural networks
KW  - Regressions
KW  - Extension theory
AB  - Abstract
Extreme learning machine (ELM), a simple single-hidden-layer feed-forward neural network with fast implementation, has been successfully applied in many fields. This paper proposes an ELM with a constructional structure (CS-ELM) for improving the performance of ELM in dealing with regression problems. In the CS-ELM, there are some partial input subnets (PISs). The first step in designing the PISs is to divide the data-attribute-space into several sub-spaces through using an improved extension clustering algorithm (IECA). The input data attributes in the same sub-space can build a PIS and the similar information of the data attributes is stored in the corresponding PIS. Additionally, a double parallel structure is applied in the CS-ELM, in which there is a special channel that directly connects the input layer neurons to the output layer neurons. In this regard, the proposed procedure can be called ELM with a data-attribute-space-oriented double parallel (DASODP) structure (DASODPâELM). To test the validity of the proposed method, it is applied to 4 regression applications. The experimental results indicate that, compared with ELM, DASODPâELM with less number of parameters can achieve higher regression precision in the generalization phase.
ER  - 

TY  - JOUR
T1  - Application of complex extreme learning machine to multiclass classification problems with high dimensionality: A THz spectra classification problem
JO  - Digital Signal Processing
VL  - 40
IS  - 
SP  - 40
EP  - 52
PY  - 2015/5//
T2  - 
AU  - Yin, X.-X.
AU  - Hadjiloucas, S.
AU  - He, J.
AU  - Zhang, Y.
AU  - Wang, Y.
AU  - Zhang, D.
SN  - 1051-2004
DO  - https://doi.org/10.1016/j.dsp.2015.01.007
UR  - https://www.sciencedirect.com/science/article/pii/S1051200415000421
KW  - Complex extreme learning machine
KW  - Reproducing Kernel Hilbert Space
KW  - Quaternary classification
KW  - Lagrangian
KW  - Multiclass classification
AB  - Abstract
We extend extreme learning machine (ELM) classifiers to complex Reproducing Kernel Hilbert Spaces (RKHS) where the input/output variables as well as the optimization variables are complex-valued. A new family of classifiers, called complex-valued ELM (CELM) suitable for complex-valued multiple-inputâmultiple-output processing is introduced. In the proposed method, the associated Lagrangian is computed using induced RKHS kernels, adopting a Wirtinger calculus approach formulated as a constrained optimization problem similarly to the conventional ELM classifier formulation. When training the CELM, the KarushâKhunâTuker (KKT) theorem is used to solve the dual optimization problem that consists of satisfying simultaneously smallest training error as well as smallest norm of output weights criteria. The proposed formulation also addresses aspects of quaternary classification within a Clifford algebra context. For 2D complex-valued inputs, user-defined complex-coupled hyper-planes divide the classifier input space into four partitions. For 3D complex-valued inputs, the formulation generates three pairs of complex-coupled hyper-planes through orthogonal projections. The six hyper-planes then divide the 3D space into eight partitions. It is shown that the CELM problem formulation is equivalent to solving six real-valued ELM tasks, which are induced by projecting the chosen complex kernel across the different user-defined coordinate planes. A classification example of powdered samples on the basis of their terahertz spectral signatures is used to demonstrate the advantages of the CELM classifiers compared to their SVM counterparts. The proposed classifiers retain the advantages of their ELM counterparts, in that they can perform multiclass classification with lower computational complexity than SVM classifiers. Furthermore, because of their ability to perform classification tasks fast, the proposed formulations are of interest to real-time applications.
ER  - 

TY  - JOUR
T1  - Improved extreme learning machine for multivariate time series online sequential prediction
JO  - Engineering Applications of Artificial Intelligence
VL  - 40
IS  - 
SP  - 28
EP  - 36
PY  - 2015/4//
T2  - 
AU  - Wang, Xinying
AU  - Han, Min
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2014.12.013
UR  - https://www.sciencedirect.com/science/article/pii/S0952197614003054
KW  - Online prediction
KW  - Multivariate time series
KW  - Extreme Learning Machine
KW  - LM algorithm
AB  - Abstract
Multivariate time series has attracted increasing attention due to its rich dynamic information of the underlying systems. This paper presents an improved extreme learning machine for online sequential prediction of multivariate time series. The multivariate time series is first phase-space reconstructed to form the input and output samples. Extreme learning machine, which has simple structure and good performance, is used as prediction model. On the basis of the specific network function of extreme learning machine, an improved LevenbergâMarquardt algorithm, in which Hessian matrix and gradient vector are calculated iteratively, is developed to implement online sequential prediction. Finally, simulation results of artificial and real-world multivariate time series are provided to substantiate the effectiveness of the proposed method.
ER  - 

TY  - JOUR
T1  - Hybridizing Extreme Learning Machines and Genetic Algorithms to select acoustic features in vehicle classification applications
JO  - Neurocomputing
VL  - 152
IS  - 
SP  - 58
EP  - 68
PY  - 2015/3/25/
T2  - 
AU  - Alexandre, E.
AU  - Cuadra, L.
AU  - Salcedo-Sanz, S.
AU  - Pastor-SÃ¡nchez, A.
AU  - Casanova-Mateo, C.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.11.019
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214015057
KW  - Vehicle classification
KW  - Feature selection
KW  - Genetic Algorithm
KW  - Extreme learning machine
AB  - Abstract
Currently traffic noise has become an important factor that affects human health, and thus, an application able to classify vehicles on the basis of the sound they produce becomes important in the effort of fulfilling recommendations that aim at reducing traffic noise and improving intelligent transportation systems. This paper focuses on the problem of selecting those sound-describing features that make the vehicle classifier work properly. In particular, the goal of this paper is to evaluate the feasibility of a novel feature selection method based on a special class of Genetic Algorithm (with restricted search) hybridized with a Extreme Learning Machine. Because of its great generalization performance at a very fast learning speed, the Extreme Learning Machine plays the key role of providing the fitness of candidate solutions in each generation of the Genetic Algorithm. After a number of experiments comparing its performance to that of other fast learning algorithms, our approach has been found to be the most feasible for the application at hand. The proposed method helps the Extreme Learning Machine-based classifier to increase its performance from a mean probability of correct classification of 74.83% (with no feature selection) up to 93.74% (when using the optimum subset of selected features).
ER  - 

TY  - JOUR
T1  - An oscillation bound of the generalization performance of extreme learning machine and corresponding analysis
JO  - Neurocomputing
VL  - 151, Part 2
IS  - 
SP  - 883
EP  - 890
PY  - 2015/3/5/
T2  - 
AU  - Wang, Di
AU  - Wang, Ping
AU  - Ji, Yan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.10.006
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214012776
KW  - Extreme learning machine
KW  - Oscillation bound
KW  - Generalization performance
KW  - Theoretical research
KW  - Infinite hidden nodes
AB  - Abstract
Extreme Learning Machine (ELM), proposed by Huang et al. in 2004 for the first time, performs better than traditional learning machines such as BP networks and SVM in some applications. This paper attempts to give an oscillation bound of the generalization performance of ELM and a reason why ELM is not sensitive to the number of hidden nodes, which are essential open problems proposed by Huang et al. in 2011. The derivation of the bound is in the framework of statistical learning theory and under the assumption that the expectation of the ELM kernel exists. It turns out that our bound is consistent with the experimental results about ELM obtained before and predicts that overfitting can be avoided even when the number of hidden nodes approaches infinity. The prediction is confirmed by our experiments on 15 data sets using one kind of activation function with every parameter independently drawn from the same Guasssian distribution, which satisfies the assumption above. The experiments also showed that when the number of hidden nodes approaches infinity, the ELM kernel with the activation is insensitive to the kernel parameter.
ER  - 

TY  - JOUR
T1  - A robust safety-oriented autonomous cruise control scheme for electric vehicles based on model predictive control and online sequential extreme learning machine with a hyper-level fault tolerance-based supervisor
JO  - Neurocomputing
VL  - 151, Part 2
IS  - 
SP  - 845
EP  - 856
PY  - 2015/3/5/
T2  - 
AU  - Mozaffari, Ahmad
AU  - Vajedi, Mahyar
AU  - Azad, Nasser L.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.10.011
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214012831
KW  - Electric vehicles
KW  - Autonomous cruise control
KW  - Model predictive control
KW  - Online sequential extreme learning machine
KW  - Hyper-level fault-tolerance based supervisor
AB  - Abstract
In this investigation, an advanced modeling method, called online sequential extreme learning machine with a hyper-level fault tolerance-based supervisor (OSELMâFTS), is utilized to develop a robust safety-oriented autonomous cruise control based on the model predictive control (MPC) technique. The resulting MPC-based cruise controller is used to improve the driving safety and reduce the energy consumption of an electric vehicle (EV). The structural flexibility of OSELMâFTS allows us to not only improve the operating features of the EV, but also develop an intelligent supervisor which can detect any operating fault and send proper commands for the adaption of the MPC controller. This introduces a degree of robustness to the devised controller, as OSELMâFTS automatically detects and filters any operating faults which may undermine the performance of the MPC controller. To ascertain the veracity of the devised controller, three well-known MPC formulations, i.e. linear MPC (LMPC) and nonlinear MPC (NMPC) and diagonal recurrent neural network MPC (DRNN-MPC), are applied to the baseline EV and their performances are compared with OSELMâFTS-MPC. To further elaborate on the computational advantages of OSELM, a well-known chunk-by-chunk incremental machine learning approach, namely selective negative correlation learning (SNCL), is taken into account. The results of the comparative study indicate that OSELMâFTS-MPC is a very promising control scheme and can be reliably used for safety-oriented autonomous cruise control of the EVs.
ER  - 

TY  - JOUR
T1  - An effective semi-cross-validation model selection method for extreme learning machine with ridge regression
JO  - Neurocomputing
VL  - 151, Part 2
IS  - 
SP  - 933
EP  - 942
PY  - 2015/3/5/
T2  - 
AU  - Shao, Zhifei
AU  - Er, Meng Joo
AU  - Wang, Ning
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.10.002
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214012715
KW  - Extreme learning machine
KW  - Ridge regression
KW  - Regularized ELM
AB  - Abstract
Extreme Learning Machine (ELM) has attracted comprehensive attentions as a universal function approximator with its extremely fast learning speed and good generalization performance. Compared to other learning methods for Single Layer Feedforward Networks (SLFNs), the unique feature of the ELM is that the input parameters of hidden neurons are randomly generated rather than being iteratively tuned, and thereby dramatically reducing the computational burden. However, it has been pointed out that the randomness of the ELM parameters would result in fluctuating performance. In this paper, we systematically investigate the performance stabilization effect brought by a regularized variant of the ELM, named Regularized ELM (RELM). Furthermore, by using the PREdiction Sum of Squares (PRESS) statistics formula and a unique property of the RELM, we propose a semi-cross-validation algorithm to effectively realize a robust RELM-based model selection for SLFNs, termed as Automatic Regularized Extreme Learning Machine with Leave-One-Out cross-validation (AR-ELM-LOO). The simulation results show that the AR-ELM-LOO can significantly reduce the randomness performance of the ELM and it can produce nearly identical results as the full cross-validation procedure.
ER  - 

TY  - JOUR
T1  - A modular extreme learning machine with linguistic interpreter and accelerated chaotic distributor for evaluating the safety of robot maneuvers in laparoscopic surgery
JO  - Neurocomputing
VL  - 151, Part 2
IS  - 
SP  - 913
EP  - 932
PY  - 2015/3/5/
T2  - 
AU  - Mozaffari, Ahmad
AU  - Behzadipour, Saeed
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.10.003
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214012727
KW  - Laparoscopic surgery
KW  - Medical robotics
KW  - Soft tissue modeling
KW  - Clustering
KW  - System identification
KW  - Fuzzy inference system
AB  - Abstract
In this investigation, a systematic sequential intelligent system is proposed to provide the surgeon with an estimation of the state of the tool-tissue interaction force in laparoscopic surgery. To train the proposed intelligent system, a 3D model of an in vivo porcine liver was built for different probing tasks. To capture the required knowledge, three different geometric features, i.e. Y displacement of the nodes on the upper surface and slopes on the closest node to the deforming area of the upper edge in both XâY and ZâY planes, were extracted experimentally. The numerical simulations are conducted in three independent successive stages. At the first step, a well-known partition-based clustering technique called accelerated chaotic particle swarm optimization (ACPSO) is used to cluster the information of database into a number of partitions. Thereafter, a modular extreme learning machine (M-ELM) is used to model the characteristics of each cluster. Finally, the output of M-ELM is fed to a Mamdani fuzzy inference system (MFIS) to interpret the safety of robot maneuvers in laparoscopic surgery. The proposed intelligent framework is used for real-time applications so that the surgeon can adjust the movements of the robot to avoid operational hazards. Based on a rigor comparative study, it is indicated that not only the proposed intelligent technique can effectively handle the considered problem but also is a reliable alternative to physical sensors and measurement tools.
ER  - 

TY  - JOUR
T1  - Outlier-robust extreme learning machine for regression problems
JO  - Neurocomputing
VL  - 151, Part 3
IS  - 
SP  - 1519
EP  - 1527
PY  - 2015/3/3/
T2  - 
AU  - Zhang, Kai
AU  - Luo, Minxia
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.09.022
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214012053
KW  - Extreme learning machine
KW  - â1-norm
KW  - Augmented Lagrange multipliers method
KW  - Outlier robustness
AB  - Abstract
Extreme learning machine (ELM), as one of the most useful techniques in machine learning, has attracted extensive attentions due to its unique ability for extremely fast learning. In particular, it is widely recognized that ELM has speed advantage while performing satisfying results. However, the presence of outliers may give rise to unreliable ELM model. In this paper, our study addresses the outlier robustness of ELM in regression problems. Based on the sparsity characteristic of outliers, this work proposes an outlier-robust ELM where the â1-norm loss function is used to enhance the robustness. Specially, the fast and accurate augmented Lagrangian multiplier method is applied to guarantee the effectiveness and efficiency. According to the experiments on function approximation and some real-world applications, the proposed approach not only maintains the advantages from original ELM, but also shows notable and stable accuracy in handling data with outliers.
ER  - 

TY  - JOUR
T1  - On the kernel Extreme Learning Machine classifier
JO  - Pattern Recognition Letters
VL  - 54
IS  - 
SP  - 11
EP  - 17
PY  - 2015/3/1/
T2  - 
AU  - Iosifidis, Alexandros
AU  - Tefas, Anastastios
AU  - Pitas, Ioannis
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2014.12.003
UR  - https://www.sciencedirect.com/science/article/pii/S0167865514003705
KW  - Extreme learning machine
KW  - Single-hidden layer networks
KW  - Infinite networks,
AB  - Abstract
In this paper, we discuss the connection of the kernel versions of the ELM classifier with infinite Single-hidden Layer Feedforward Neural networks and show that the original ELM kernel definition can be adopted for the calculation of the ELM kernel matrix for two of the most common activation functions, i.e., the RBF and the sigmoid functions. In addition, we show that a low-rank decomposition of the kernel matrix defined on the input training data can be exploited in order to determine an appropriate ELM space for input data mapping. The ELM space determined from this process can be subsequently used for network training using the original ELM formulation. Experimental results denote that the adoption of the low-rank decomposition-based ELM space determination leads to enhanced performance, when compared to the standard choice, i.e., random input weights generation.
ER  - 

TY  - JOUR
T1  - Discriminative graph regularized extreme learning machine and its application to face recognition
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 340
EP  - 353
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Peng, Yong
AU  - Wang, Suhang
AU  - Long, Xianzhong
AU  - Lu, Bao-Liang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.12.065
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011357
KW  - Extreme learning machine
KW  - Graph Laplacian
KW  - Manifold regularization
KW  - Face recognition
AB  - Abstract
Extreme Learning Machine (ELM) has been proposed as a new algorithm for training single hidden layer feed forward neural networks. The main merit of ELM lies in the fact that the input weights as well as hidden layer bias are randomly generated and thus the output weights can be obtained analytically, which can overcome the drawbacks incurred by gradient-based training algorithms such as local optima, improper learning rate and low learning speed. Based on the consistency property of data, which enforces similar samples to share similar properties, we propose a discriminative graph regularized Extreme Learning Machine (GELM) for further enhancing its classification performance in this paper. In the proposed GELM model, the label information of training samples are used to construct an adjacent graph and correspondingly the graph regularization term is formulated to constrain the output weights to learn similar outputs for samples from the same class. The proposed GELM model also has a closed form solution as the standard ELM and thus the output weights can be obtained efficiently. Experiments on several widely used face databases show that our proposed GELM can achieve much performance gain over standard ELM and regularized ELM. Moreover, GELM also performs well when compared with the state-of-the-art classification methods for face recognition.
ER  - 

TY  - JOUR
T1  - Adaptive neural control for a class of MIMO nonlinear systems with extreme learning machine
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 405
EP  - 414
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Rong, Hai-Jun
AU  - Wei, Jin-Tao
AU  - Bai, Jian-Ming
AU  - Zhao, Guang-She
AU  - Liang, Yong-Qi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.01.066
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011369
KW  - Single-hidden layer feedforward network
KW  - Extreme learning machine
KW  - MIMO nonlinear systems
AB  - Abstract
This paper presents two adaptive neural control schemes for a class of uncertain continuous-time multi-input multi-output (MIMO) nonlinear dynamic systems. Within these schemes, the single-hidden layer feedforward networks (SLFNs) are applied to approximate the unknown nonlinear functions of the systems and then the neural controller is built based on the approximated neural models. The parameters of the SLFNs are modified using the recently proposed neural algorithm named extreme learning machine (ELM), where the parameters of the hidden nodes are assigned randomly. Different from the original ELM algorithm, the output weights are updated using the adaptive laws derived based on the Lyapunov stability theorem and Barbalat×³s lemma so that the asymptotical stability of the system can be guaranteed. The robustifying control term is also constructed to compensate for approximation errors of the SLFNs. In order to avoid the requirement of the approximation error bounds, the estimation laws derived based on the Lyapunov stability theorem and Barbalat×³s lemma are employed to estimate the error bounds in the second adaptive control scheme. Finally the proposed control schemes are applied to control a two-link robot manipulator. The simulation results demonstrate the effectiveness of the proposed control schemes for the MIMO nonlinear system.
ER  - 

TY  - JOUR
T1  - Multiple kernel extreme learning machine
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 253
EP  - 264
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Liu, Xinwang
AU  - Wang, Lei
AU  - Huang, Guang-Bin
AU  - Zhang, Jian
AU  - Yin, Jianping
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.09.072
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011199
KW  - Extreme learning machine
KW  - Multiple kernel learning
KW  - Support vector machines
AB  - Abstract
Extreme learning machine (ELM) has been an important research topic over the last decade due to its high efficiency, easy-implementation, unification of classification and regression, and unification of binary and multi-class learning tasks. Though integrating these advantages, existing ELM algorithms pay little attention to optimizing the choice of kernels, which is indeed crucial to the performance of ELM in applications. More importantly, there is the lack of a general framework for ELM to integrate multiple heterogeneous data sources for classification. In this paper, we propose a general learning framework, termed multiple kernel extreme learning machines (MK-ELM), to address the above two issues. In the proposed MK-ELM, the optimal kernel combination weights and the structural parameters of ELM are jointly optimized. Following recent research on support vector machine (SVM) based MKL algorithms, we first design a sparse MK-ELM algorithm by imposing an â1-norm constraint on the kernel combination weights, and then extend it to a non-sparse scenario by substituting the â1-norm constraint with an âp-norm ( p &gt; 1 ) constraint. After that, a radius-incorporated MK-ELM algorithm which incorporates the radius of the minimum enclosing ball (MEB) is introduced. Three efficient optimization algorithms are proposed to solve the corresponding kernel learning problems. Comprehensive experiments have been conducted on Protein, Oxford Flower17, Caltech101 and Alzheimer×³s disease data sets to evaluate the performance of the proposed algorithms in terms of classification accuracy and computational efficiency. As the experimental results indicate, our proposed algorithms can achieve comparable or even better classification performance than state-of-the-art MKL algorithms, while incurring much less computational cost.
ER  - 

TY  - JOUR
T1  - Ensemble of extreme learning machine for remote sensing image classification
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 65
EP  - 70
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Han, Min
AU  - Liu, Ben
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.09.070
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214009503
KW  - Remote sensing classification
KW  - Nonnegative matrix factorization (NMF)
KW  - Extreme learning machine (ELM)
KW  - Ensemble learning
KW  - Feature extraction
AB  - Abstract
There are only a few of labeled training samples in the remote sensing image classification. Therefore, it is a highly challenging problem that finds a good classification method which could achieve high accuracy to deal with these data. In this paper, we propose a new remote sensing image classification method based on extreme learning machine (ELM) ensemble. In order to promote the diversity within the ensemble, we adopt feature segmentation and then feature extraction with nonnegative matrix factorization (NMF) to the original data firstly. Then ELM is chosen as base classifier to improve the classification efficiency. The experimental results show that the proposed algorithm not only has high classification accuracy, but also handles the adverse impact of a few of labeled training samples in the classification of remote sensing image well both on the remote sensing image and UCI data.
ER  - 

TY  - JOUR
T1  - Skeleton-based action recognition with extreme learning machines
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 387
EP  - 396
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Chen, Xi
AU  - Koskela, Markus
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.10.046
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011321
KW  - Action and gesture recognition
KW  - Extreme learning machine
KW  - Support vector machine
KW  - Motion capture
KW  - RGB-D
KW  - HDM05
AB  - Abstract
Action and gesture recognition from motion capture and RGB-D camera sequences has recently emerged as a renowned and challenging research topic. The current methods can usually be applied only to small datasets with a dozen or so different actions, and the systems often require large amounts of time to train the models and to classify new sequences. In this paper, we first extract simple but effective frame-level features from the skeletal data and build a recognition system based on the extreme learning machine. We then propose three modeling methods for post-processing the classification outputs to obtain the recognition results on the action sequence level. We test the proposed method on three public datasets ranging from 11 to 40 action classes. For all datasets, the method can classify the sequences with accuracies reaching 96â99% and with the average classification time for one sequence on a single computer core around 4 ms. Fast training and testing and the high accuracy make the proposed method readily applicable for online recognition applications.
ER  - 

TY  - JOUR
T1  - Advances in Extreme Learning Machines (ELM2013)
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 158
EP  - 159
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Lendasse, Amaury
AU  - He, Qing
AU  - Miche, Yoan
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.08.059
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011163
ER  - 

TY  - JOUR
T1  - Semi-supervised extreme learning machine with manifold and pairwise constraints regularization
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 180
EP  - 186
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Zhou, Yong
AU  - Liu, Beizuo
AU  - Xia, Shixiong
AU  - Liu, Bing
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.01.073
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011734
KW  - Semi-supervised learning
KW  - Extreme learning machine (ELM)
KW  - Pairwise constraints
KW  - Regularization
AB  - Abstract
Traditional kernel-based semi-supervised learning (SSL) algorithms usually have high computational complexity. Moreover, few SSL methods have been proposed to utilize both the manifold of unlabeled data and pairwise constraints effectively. In this paper, we first construct a unified SSL framework to combine the manifold regularization and the terms based on the pairwise constraints for semi-supervised classification tasks. Motivated by the effectiveness of extreme learning machine (ELM), we further utilize ELM to approximate the established kernel-based SSL framework. Finally, we present a fast semi-supervised extreme learning machine with manifold regularization and pairwise constraints. Experimental results on a variety of real-world data sets demonstrate the effectiveness of the proposed fast SSL algorithm.
ER  - 

TY  - JOUR
T1  - Sparse Bayesian extreme learning machine and its application to biofuel engine performance prediction
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 397
EP  - 404
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Wong, Ka In
AU  - Vong, Chi Man
AU  - Wong, Pak Kin
AU  - Luo, Jiahua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.09.074
UR  - https://www.sciencedirect.com/science/article/pii/S092523121401128X
KW  - Extreme learning machine
KW  - Sparse Bayesian
KW  - Biofuel
KW  - Dual-fuel engine
KW  - Engine performance
AB  - Abstract
Biofuels are important for the reduction of engine exhaust emissions and fossil fuel consumption. To use different blends of biofuels, the electronic control unit (ECU) of the engine must be modified and calibrated. However, the calibration process of ECU is very costly and time-consuming. Therefore, most of the engines can only use one specific biofuel blend; otherwise the engines cannot run properly. To alleviate this problem, a mathematical engine model can be used for predicting the engine performance at different ECU settings and biofuel blends so that the ECU can be re-calibrated in real-time via some controllers. The prediction of the engine model must be very fast and accurate for such online control purpose. It must also be very compact due to the limited memory size of the ECU. As a result, a new method called sparse Bayesian extreme learning machine (SBELM) is proposed in this paper to fulfill these requirements of the mathematical engine model for fast engine performance prediction and ECU online re-calibration. Experiments were conducted to compare SBELM with conventional ELM, Bayesian ELM (BELM) and back-propagated neural network (BPNN). Evaluation results show that SBELM can perform at least similar to, but mostly better than, ELM, BELM and BPNN, in terms of prediction accuracy. In terms of execution time, model size, and insensitivity to hidden neuron number, SBELM completely outperforms the other three methods. By these results, SBELM is verified to better fulfill the practical requirements of mathematical engine model for online engine performance prediction.
ER  - 

TY  - JOUR
T1  - Learning deep representations via extreme learning machines
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 308
EP  - 315
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Yu, Wenchao
AU  - Zhuang, Fuzhen
AU  - He, Qing
AU  - Shi, Zhongzhi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.03.077
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011461
KW  - Extreme learning machine
KW  - Deep learning
KW  - Representation learning
KW  - Stacked ELMs
KW  - Stacked generalization
KW  - DrELM
AB  - Abstract
Extreme learning machine (ELM) as an emerging technology has achieved exceptional performance in large-scale settings, and is well suited to binary and multi-class classification, as well as regression tasks. However, existing ELM and its variants predominantly employ single hidden layer feedforward networks, leaving the popular and potentially powerful stacked generalization principle unexploited for seeking predictive deep representations of input data. Deep architectures can find higher-level representations, thus can potentially capture relevant higher-level abstractions. But most of current deep learning methods require solving a difficult and non-convex optimization problem. In this paper, we propose a stacked model, DrELM, to learn deep representations via extreme learning machine according to stacked generalization philosophy. The proposed model utilizes ELM as a base building block and incorporates random shift and kernelization as stacking elements. Specifically, in each layer, DrELM integrates a random projection of the predictions obtained by ELM into the original feature, and then applies kernel functions to generate the resultant feature. To verify the classification and regression performance of DrELM, we conduct the experiments on both synthetic and real-world data sets. The experimental results show that DrELM outperforms ELM and kernel ELMs, which appear to demonstrate that DrELM could yield predictive features that are suitable for prediction tasks. The performances of the deep models (i.e. Stacked Auto-encoder) are comparable. However, due to the utilization of ELM, DrELM is easier to learn and faster in testing.
ER  - 

TY  - JOUR
T1  - Distributed Extreme Learning Machine with kernels based on MapReduce
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 456
EP  - 463
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Bi, Xin
AU  - Zhao, Xiangguo
AU  - Wang, Guoren
AU  - Zhang, Pan
AU  - Wang, Chao
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.01.070
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011473
KW  - Extreme Learning Machine
KW  - Extreme Learning Machine with kernels
KW  - Massive data learning
KW  - MapReduce
AB  - Abstract
Extreme Learning Machine (ELM) has shown its good generalization performance and extremely fast learning speed in many learning applications. Recently, it has been proved that ELM outperforms Support Vector Machine (SVM) with less constraints from the optimization point of view. ELM provides unified learning schemes with a widespread type of feature mappings. Among these unified algorithms, ELM with kernels applies kernels instead of random feature mappings. However, with the exponentially increasing volume of training data in massive learning applications, centralized ELM with kernels suffers from the great memory consumption of large matrix operations. Besides, due to the high communication cost, some of these matrix operations cannot be directly implemented on shared-nothing distributed computing model like MapReduce. This paper proposes a distributed solution named Distributed Kernelized ELM (DK-ELM), which realizes an implementation of ELM with kernels on MapReduce. Distributed kernel matrix calculation and multiplication of matrix with vector are also applied to realize parallel calculation of DK-ELM. Extensive experiments on massive datasets are conducted to verify both the scalability and training performance of DK-ELM. Experimental results show that DK-ELM has good scalability for massive learning applications.
ER  - 

TY  - JOUR
T1  - Parallel online sequential extreme learning machine based on MapReduce
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 224
EP  - 232
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Wang, Botao
AU  - Huang, Shan
AU  - Qiu, Junhao
AU  - Liu, Yu
AU  - Wang, Guoren
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.03.076
UR  - https://www.sciencedirect.com/science/article/pii/S092523121401145X
KW  - Extreme learning machine
KW  - Large scale learning
KW  - Online sequential learning
KW  - Mapreduce
KW  - Parallel classification
AB  - Abstract
In this age of big data, analyzing big data is a very challenging problem. MapReduce is a simple, scalable and fault-tolerant data processing framework that enables us to process a massive volume of data. Many machine learning algorithms have been designed based on MapReduce, but there are only a few works related to parallel extreme learning machine (ELM) which is a fast and accurate learning algorithm.

Online sequential extreme learning machine (OS-ELM) is one of improved ELM algorithms to support online sequential learning efficiently. In this paper, we first analyze the dependency relationships of matrix calculations of OS-ELM, then propose a parallel online sequential extreme learning machine (POS-ELM) based on MapReduce.

POS-ELM is evaluated with real and synthetic data with the maximum number of training data 1280 K and the maximum number of attributes 128. The experimental results show that the training accuracy and testing accuracy of POS-ELM are at the same level as those of OS-ELM and ELM, and it has good scalability with regard to the number of training data and the number of attributes. Compared to original ELM and OS-ELM where the capability to process large scale data is bounded by the limitation of resources within a single processing unit, POS-ELM can deal with much larger scale data. The larger the number of training data is, the higher the speedup of POS-ELM is. It can be concluded that POS-ELM has more powerful capability than both ELM and OS-ELM for large scale learning.
ER  - 

TY  - JOUR
T1  - Facial age range estimation with extreme learning machines
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 364
EP  - 372
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Sai, Phyo-Kyaw
AU  - Wang, Jian-Gang
AU  - Teoh, Eam-Khwang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.03.074
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011400
KW  - Facial age range estimation
KW  - Extreme learning machines
KW  - ECOC
KW  - Boosting
AB  - Abstract
Face image based age estimation is an approach to classify face images into one of several pre-defined age-groups. It is challenging because facial aging variation is specific to a given individual and is determined by the person's gene and many external factors, such as exposure, weather, gender, and living style. Age estimation is a multiclass problem and the number of classes to predict is quite large. There surely is facial aging trend and faces from closed age range have some similar facial aging features. It is difficult to say there are distinct facial aging features for an age. Facial aging features are found to be overlapped among nearby age groups along the aging life and are continuous in nature. In this paper, we emphasised our work on age range estimation with four pre-defined classes. We applied a fast and efficient machine learning method: extreme learning machines, to solve the age categorization problem. Local Gabor Binary Patterns, Biologically Inspired Feature and Gabor were adopted to represent face image. Age estimation was performed on three different aging datasets and experimental results are reported to demonstrate its effectiveness and robustness.
ER  - 

TY  - JOUR
T1  - Ensemble of subset online sequential extreme learning machine for class imbalance and concept drift
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 316
EP  - 329
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Mirza, Bilal
AU  - Lin, Zhiping
AU  - Liu, Nan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.03.075
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011448
KW  - Class imbalance
KW  - Concept drift
KW  - Extreme learning machine
KW  - Online learning
KW  - Recurring environments
AB  - Abstract
In this paper, a computationally efficient framework, referred to as ensemble of subset online sequential extreme learning machine (ESOS-ELM), is proposed for class imbalance learning from a concept-drifting data stream. The proposed framework comprises a main ensemble representing short-term memory, an information storage module representing long-term memory and a change detection mechanism to promptly detect concept drifts. In the main ensemble of ESOS-ELM, each OS-ELM network is trained with a balanced subset of the data stream. Using ELM theory, a computationally efficient storage scheme is proposed to leverage the prior knowledge of recurring concepts. A distinctive feature of ESOS-ELM is that it can learn from new samples sequentially in both the chunk-by-chunk and one-by-one modes. ESOS-ELM can also be effectively applied to imbalanced data without concept drift. On most of the datasets used in our experiments, ESOS-ELM performs better than the state-of-the-art methods for both stationary and non-stationary environments.
ER  - 

TY  - JOUR
T1  - Spatially regularized semisupervised Ensembles of Extreme Learning Machines for hyperspectral image segmentation
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 373
EP  - 386
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Ayerdi, Borja
AU  - MarquÃ©s, Ion
AU  - GraÃ±a, Manuel
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.01.068
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011424
KW  - Hyperspectral images
KW  - Spatial-spectral segmentation
KW  - Extreme Learning Machine
KW  - Semisupervised learning
AB  - Abstract
This paper explores the performance of Ensembles of Extreme Learning Machine classifiers for hyperspectral image classification and segmentation in a semisupervised and spatially regularized process. The approach assumes that we have available only a small training set of labeled samples, which we enrich with a set of guessed labelings on selected samples from the vast pool of unlabeled image pixels. Selection and label guessing is conditioned to an unsupervised classification of the image pixel spectra, and to the spatial proximity to the labeled samples in the image domain. Unlabeled pixels falling in the spatial neighborhood of a labeled training sample, and belonging to the same unsupervised class, acquire its label. Unsupervised classification can be performed by any clustering technique, in this paper we have resorted to the classical K-means. The classifier built from the enriched training dataset is applied to the entire hyperspectral image. Finally, we perform a spatial regularization of the classification label image, maximizing a rather general prior smoothness criterion, by the selection of the most frequent class in each pixel neighborhood. This paper reports experiments with homogeneous ensembles of ELM, rELM, and OP-ELM classifiers, including a sensitivity analysis over the ensemble size and the number of hidden nodes. Computational experiments on four well known benchmarking hyperspectral images give state-of-the-art results.
ER  - 

TY  - JOUR
T1  - LARSEN-ELM: Selective ensemble of extreme learning machines using LARS for blended data
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 285
EP  - 294
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Han, Bo
AU  - He, Bo
AU  - Nian, Rui
AU  - Ma, Mengmeng
AU  - Zhang, Shujing
AU  - Li, Minghui
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.01.069
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011436
KW  - Extreme learning machine
KW  - LARS algorithm
KW  - Selective ensemble
KW  - LARSEN-ELM
KW  - Robustness
AB  - Abstract
Extreme learning machine (ELM) as a neural network algorithm has shown its good performance, such as fast speed, simple structure etc, but also, weak robustness is an unavoidable defect in original ELM for blended data. We present a new machine learning framework called âLARSEN-ELMâ to overcome this problem. In our paper, we would like to show two key steps in LARSEN-ELM. In the first step, preprocessing, we select the input variables highly related to the output using least angle regression (LARS). In the second step, training, we employ Genetic Algorithm (GA) based selective ensemble and original ELM. In the experiments, we apply a sum of two sines and four datasets from UCI repository to verify the robustness of our approach. The experimental results show that compared with original ELM and other methods such as OP-ELM, GASEN-ELM and LSBoost, LARSEN-ELM significantly improves robustness performance while keeping a relatively high speed.
ER  - 

TY  - JOUR
T1  - Improved incremental Regularized Extreme Learning Machine Algorithm and its application in two-motor decoupling control
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 215
EP  - 223
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Ding, Jin-Lin
AU  - Wang, Feng
AU  - Sun, Hong
AU  - Shang, Li
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.02.071
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011333
KW  - II-RELM
KW  - Decoupling control
KW  - Cholesky factorization without square root
KW  - Generalized inverse
KW  - Vector mode
KW  - Changing rate of learning error
AB  - Abstract
Regularized Extreme Learning Machine (RELM) is an ideal algorithm for regression and classification due to its fast training speed and good generalization performance. However, how to obtain the suitable number of hidden nodes is still a challenging task. In order to solve the problem, a new incremental algorithm based on Cholesky factorization without square root is proposed in this paper, which is called the improved incremental RELM (II-RELM). The method can automatically determine optimal network structure through gradually adding new hidden nodes one by one. It achieves less computational cost and better accuracy through updating output weights. Finally, neural network generalized inverse (NNGI) based on II-RELM is applied to two-motor synchronous decoupling control. Simulation indicates that the proposed algorithm has excellent performance in prediction control. It realizes the decoupling control between velocity and tension.
ER  - 

TY  - JOUR
T1  - Class-specific soft voting based multiple extreme learning machines ensemble
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 275
EP  - 284
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Cao, Jingjing
AU  - Kwong, Sam
AU  - Wang, Ran
AU  - Li, Xiaodong
AU  - Li, Ke
AU  - Kong, Xiangfei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.02.072
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011345
KW  - Extreme learning machine
KW  - Soft voting
KW  - Condition number
KW  - Sparse ensemble
AB  - Abstract
Compared with conventional weighted voting methods, class-specific soft voting (CSSV) system has several advantages. On one hand, it not only deals with the soft class probability outputs but also refines the weights from classifiers to classes. On the other hand, the class-specific weights can be used to improve the combinative performance without increasing much computational load. This paper proposes two weight optimization based ensemble methods (CSSV-ELM and SpaCSSV-ELM) under the framework of CSSV scheme for multiple extreme learning machines (ELMs). The designed two models are in terms of accuracy and sparsity aspects, respectively. Firstly, CSSV-ELM takes advantage of the condition number of matrix, which reveals the stability of linear equation, to determine the weights of base ELM classifiers. This model can reduce the unreliability induced by randomly input parameters of a single ELM, and solve the ill-conditioned problem caused by linear system structure of ELM simultaneously. Secondly, sparse ensemble methods can lower memory requirement and speed up the classification process, but only for classifier-specific weight level. Therefore, a SpaCSSV-ELM method is proposed by transforming the weight optimization problem to a sparse coding problem, which uses the sparse representation technique for maintaining classification performance with less nonzero weight coefficients. Experiments are carried out on twenty UCI data sets and Finance event series data and the experimental results show the superior performance of the CSSV based ELM algorithms by comparing with the state-of-the-art algorithms.
ER  - 

TY  - JOUR
T1  - Efficient smile detection by Extreme Learning Machine
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 354
EP  - 363
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - An, Le
AU  - Yang, Songfan
AU  - Bhanu, Bir
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.04.072
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011370
KW  - Facial expression analysis
KW  - Smile detection
KW  - Extreme Learning Machine
KW  - Classification
KW  - Feature extraction
AB  - Abstract
Smile detection is a specialized task in facial expression analysis with applications such as photo selection, user experience analysis, and patient monitoring. As one of the most important and informative expressions, smile conveys the underlying emotion status such as joy, happiness, and satisfaction. In this paper, an efficient smile detection approach is proposed based on Extreme Learning Machine (ELM). The faces are first detected and a holistic flow-based face registration is applied which does not need any manual labeling or key point detection. Then ELM is used to train the classifier. The proposed smile detector is tested with different feature descriptors on publicly available databases including real-world face images. The comparisons against benchmark classifiers including Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) suggest that the proposed ELM based smile detector in general performs better and is very efficient. Compared to state-of-the-art smile detector, the proposed method achieves competitive results without preprocessing and manual registration.
ER  - 

TY  - JOUR
T1  - On extending extreme learning machine to non-redundant synergy pattern based graph classification
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 330
EP  - 339
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Wang, Zhanghui
AU  - Zhao, Yuhai
AU  - Wang, Guoren
AU  - Li, Yuan
AU  - Wang, Xue
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.11.057
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011497
KW  - Synergy graph pattern
KW  - Non-redundant
KW  - Extreme learning machine
KW  - Support graph vector model
KW  - Graph classification
AB  - Abstract
Graph patterns are widely used to define the feature space for building an efficient graph classification model. Synergy graph patterns refer to those graphs, where the relationships among the nodes are highly inseparable. Compared with the general graph patterns, synergy graph patterns which have much higher discriminative powers are more suitable as the classification features. Extreme Learning Machine (ELM) is a simple and efficient Single-hidden Layer Feedforward neural Networks (SLFNs) algorithm with extremely fast learning capacity. In this paper we propose the problem of extending ELM to non-redundant synergy pattern based graph classification.

The graph classification framework being widely used consists of two steps, namely feature generation and classification. The first issue is how to quickly obtain significant graph pattern features from a graph database. The next step is how to effectively build a graph classification model with these graph pattern features. An efficient depth-first algorithm, called GINS, was presented to find all non-redundant synergy graph patterns. Also, based on the proposed Support Graph Vector Model (SGVM) and ELM algorithm, the graph classification model was constructed. Extensive experiments are conducted on a series of real-life datasets. The results show that GINS is more efficient than two representative competitors. Besides, when the generated graph patterns are considered as the classification features, the GINS+ELM classification accuracy can be improved much.
ER  - 

TY  - JOUR
T1  - Elastic extreme learning machine for big data classification
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 464
EP  - 471
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Xin, Junchang
AU  - Wang, Zhiqiong
AU  - Qu, Luxuan
AU  - Wang, Guoren
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.09.075
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011503
KW  - Extreme learning machine
KW  - Big data classification
KW  - Incremental learning
KW  - Decremental learning
KW  - Correctional learning
AB  - Abstract
Extreme Learning Machine (ELM) and its variants have been widely used for many applications due to its fast convergence and good generalization performance. Though the distributed ELMâ based on MapReduce framework can handle very large scale training dataset in big data applications, how to cope with its rapidly updating is still a challenging task. Therefore, in this paper, a novel Elastic Extreme Learning Machine based on MapReduce framework, named Elastic ELM (E2LM), is proposed to cover the shortage of ELMâ whose learning ability is weak to the updated large-scale training dataset. Firstly, after analyzing the property of ELMâ adequately, it can be found out that its most computation-expensive part, matrix multiplication, can be incrementally, decrementally and correctionally calculated. Next, the Elastic ELM based on MapReduce framework is developed, which first calculates the intermediate matrix multiplications of the updated training data subset, and then update the matrix multiplications by modifying the old matrix multiplications with the intermediate ones. Then, the corresponding new output weight vector can be obtained with centralized computing using the update the matrix multiplications. Therefore, the efficient learning of rapidly updated massive training dataset can be realized effectively. Finally, we conduct extensive experiments on synthetic data to verify the effectiveness and efficiency of our proposed E2LM in learning massive rapidly updated training dataset with various experimental settings.
ER  - 

TY  - JOUR
T1  - Binary/ternary extreme learning machines
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 187
EP  - 197
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - van Heeswijk, Mark
AU  - Miche, Yoan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.01.072
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011515
KW  - Extreme learning machine
KW  - Hidden layer initialization
KW  - Intrinsic plasticity
KW  - Random projection
KW  - Binary features
KW  - Ternary features
AB  - Abstract
In this paper, a new hidden layer construction method for Extreme Learning Machines (ELMs) is investigated, aimed at generating a diverse set of weights. The paper proposes two new ELM variants: Binary ELM, with a weight initialization scheme based on { 0 , 1 } âweights; and Ternary ELM, with a weight initialization scheme based on { â 1 , 0 , 1 } âweights. The motivation behind this approach is that these features will be from very different subspaces and therefore each neuron extracts more diverse information from the inputs than neurons with completely random features traditionally used in ELM. Therefore, ideally it should lead to better ELMs. Experiments show that indeed ELMs with ternary weights generally achieve lower test error. Furthermore, the experiments show that the Binary and Ternary ELMs are more robust to irrelevant and noisy variables and are in fact performing implicit variable selection. Finally, since only the weight generation scheme is adapted, the computational time of the ELM is unaffected, and the improved accuracy, added robustness and the implicit variable selection of Binary ELM and Ternary ELM come for free.
ER  - 

TY  - JOUR
T1  - Enhancement of online sequential extreme learning machine based on the householder block exact inverse QRD recursive least squares
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 239
EP  - 252
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Horata, Punyaphol
AU  - Chiewchanwattana, Sirapat
AU  - Sunat, Khamron
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.10.047
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011539
KW  - Extreme learning machine
KW  - Online sequential extreme learning machine
KW  - Householder block exact inverse QR decomposition
KW  - Structural tolerance
KW  - Robustness
KW  - Ensemble
AB  - Abstract
The online sequential extreme learning machine (OS-ELM) has been used for training without retraining the ELM when a chunk of data is received. However, OS-ELM may be affected by an improper number of hidden nodes settings which reduces the generalization of OS-ELM. This paper addresses this problem in OS-ELM. A new structural tolerance OS-ELM (STOS-ELM), based on the Householder block exact inverse QRD recursive least squares algorithm having numerical robustness is proposed. Experimental results conducted on four regressions and five classification problems showed that STOS-ELM can handle the situation when the network is constructed with an improper number of hidden nodes. Accordingly, the proposed STOS-ELM can be easily applied; the size of the hidden layer of ELM can be roughly approximated. If a chunk of data is received, it can be updated in the existing network without having to worry about the proper number of given hidden nodes. Furthermore, the accuracy of the network trained by STOS-ELM is comparable to that of the batch ELM when the networks have the same configurations. STOS-ELM can also be applied in ensemble version (ESTOS-ELM). We found that the stability of STOS-ELM can be further improved using the ensemble technique. The results show that ESTOS-ELM is also more stable and accurate than both of the original OS-ELM and EOS-ELM, especially in the classification problems.
ER  - 

TY  - JOUR
T1  - Multi-dimensional extreme learning machine
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 160
EP  - 170
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Mao, Wentao
AU  - Zhao, Shengjie
AU  - Mu, Xiaoxia
AU  - Wang, Haicheng
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.02.073
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011540
KW  - Extreme learning machine
KW  - Multi-dimensional regression
KW  - Mixed integer programming
KW  - Loss function
AB  - Abstract
As an important branch of neural network, extreme learning machines (ELMs) have attracted wide interests in the fields of pattern classification and regression estimation. However, when facing learning problems with multi-dimensional outputs, named multi-dimensional regression, the conventional ELMs could not generally get satisfactory results because it is incapable of exploiting the relatedness among outputs efficiently. To solve this problem, a new regularized ELM is firstly proposed in this paper by introducing a hyper-spherical loss function as regularizer. As the regularization form with this loss function cannot be solved directly, an solution with iterative procedure is presented. For improving the learning performance, the algorithm proposed above is further reformulated to identify the inner grouping structure hidden in outputs by assuming that the grouping structure is determined by different linear combinations of a small number of latent basis neurons. This is achieved as a mixed integer programming, and finally an alternating minimization method is presented to solve this problem. Experiments on two multi-dimensional data sets, a toy problem and a real-life dynamical cylindrical vibration data set, are conducted, and the results demonstrate the effectiveness of the proposed algorithm.
ER  - 

TY  - JOUR
T1  - Anomaly detection in traffic using L1-norm minimization extreme learning machine
JO  - Neurocomputing
VL  - 149, Part A
IS  - 
SP  - 415
EP  - 425
PY  - 2015/2/3/
T2  - Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013)
AU  - Wang, Yibing
AU  - Li, Dong
AU  - Du, Yi
AU  - Pan, Zhisong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.04.073
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214011382
KW  - Traffic classification
KW  - Anomaly detection
KW  - Extreme learning machine
KW  - Support vector machine
KW  - L1-norm minimization
AB  - Abstract
Machine learning algorithms are widely used for traffic classification and anomaly detection nowadays, however, how to fast and accurately classify the flows remains extremely challengeable. In this paper, we propose an extreme learning machine (ELM) based algorithm called L1-Norm Minimization ELM, which fully inherits the merits of ELM, and meanwhile, exhibits the sparsity-induced characteristics which could reduce the complexity of learning model. At the evaluation stage, we preprocessed the raw data trace from trans-Pacific backbone link between Japan and the United States, and generated 248 features datasets. The empirical study shows that L1-ELM can achieve good generalization performance on the evaluation datasets, while preserving the fast learning and little human intervened advantages that ELM has.
ER  - 

TY  - JOUR
T1  - Confidence-weighted extreme learning machine for regression problems
JO  - Neurocomputing
VL  - 148
IS  - 
SP  - 544
EP  - 550
PY  - 2015/1/19/
T2  - 
AU  - Shang, Zhigen
AU  - He, Jianqiang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.07.009
UR  - https://www.sciencedirect.com/science/article/pii/S092523121400887X
KW  - Extreme learning machine
KW  - Relative entropy
KW  - Gaussian margin machine
KW  - Regression
AB  - Abstract
Based on Gaussian margin machine (GMM) and extreme learning machine (ELM), confidence-weighted ELM (CW-ELM) is proposed to provide point forecasts and confidence intervals. CW-ELM maintains a multivariate normal distribution over the output weight vector. It is applied to seek the least informative distribution from those that keep the targets within the forecast confidence intervals. For simplicity, the covariance matrix is assumed to be diagonal. The simplified problem of CW-ELM is approximately solved by using Leave-One-Out-Incremental ELM (LOO-IELM) and the interior point method. Our experimental results on both synthetic and real-world regression datasets demonstrate that CW-ELM has better performance than Bayesian ELM and Gaussian process regression.
ER  - 

TY  - JOUR
T1  - Identification and quantification of concurrent control chart patterns using extreme-point symmetric mode decomposition and extreme learning machines
JO  - Neurocomputing
VL  - 147
IS  - 
SP  - 260
EP  - 270
PY  - 2015/1/5/
T2  - Advances in Self-Organizing Maps Subtitle of the special issue: Selected Papers from the Workshop on Self-Organizing Maps 2012 (WSOM 2012)
AU  - Yang, Wen-An
AU  - Zhou, Wei
AU  - Liao, Wenhe
AU  - Guo, Yu
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.06.068
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214008613
KW  - Statistical process control
KW  - Control chart
KW  - Pattern recognition
KW  - Extreme learning machine
KW  - Extreme-point symmetric mode decomposition
AB  - Abstract
Control chart pattern recognition (CCPR) is an important issue in statistical process control because unnatural control chart patterns (CCPs) exhibited on control charts can be associated with specific causes that adversely affect the manufacturing processes. In recent years, many machine learning techniques [e.g., artificial neural networks (ANNs) and support vector machines (SVMs)] have been successfully applied to CCPR. However, such existing research for CCPR has mostly been developed for identification of basic CCPs. Little attention has been given to the utilization of ANNs/SVMs for identification of concurrent CCPs (two or more basic CCPs occurring simultaneously) which are commonly encountered in practical manufacturing processes. In addition, these existing research for CCPR cannot provide more detailed CCP parameter information, such as shift magnitude, trend slope, cycle amplitude, etc., which is very useful for quality practitioners to search the assignable causes that give rise to the out-of-control situation. This study proposes a hybrid approach that integrates extreme-point symmetric mode decomposition (ESMD) with extreme learning machine (ELM) to identify typical concurrent CCPs and in addition to accurately quantify the major CCP parameter of the specific basic CCPs involved. The numerical results indicate that the proposed model can effectively identify not only concurrent CCPs but also basic CCPs. Meanwhile, the major CCP parameter of the identified concurrent CCP can also be accurately quantified.
ER  - 

TY  - JOUR
T1  - Trends in extreme learning machines: A review
JO  - Neural Networks
VL  - 61
IS  - 
SP  - 32
EP  - 48
PY  - 2015/1//
T2  - 
AU  - Huang, Gao
AU  - Huang, Guang-Bin
AU  - Song, Shiji
AU  - You, Keyou
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2014.10.001
UR  - https://www.sciencedirect.com/science/article/pii/S0893608014002214
KW  - Extreme learning machine
KW  - Classification
KW  - Clustering
KW  - Feature learning
KW  - Regression
AB  - Abstract
Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of ELM from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to ELM which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, ELM has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, ELM have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in ELM together with its future perspectives.
ER  - 

TY  - JOUR
T1  - Integrating Data Selection and Extreme Learning Machine for Imbalanced Data
JO  - Procedia Computer Science
VL  - 59
IS  - 
SP  - 221
EP  - 229
PY  - 2015///
T2  - International Conference on Computer Science and Computational Intelligence (ICCSCI 2015)
AU  - Mahdiyah, Umi
AU  - Irawan, M. Isa
AU  - Imah, Elly Matul
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2015.07.561
UR  - https://www.sciencedirect.com/science/article/pii/S1877050915020906
KW  - Data Selection
KW  - Extreme Learning Machine
KW  - Imbalanced Data
AB  - Abstract
Extreme Learning Machine (ELM) is one of the artificial neural network method that introduced by Huang, this method has very fast learning capability. ELM is designed for balance data. Common problems in real-life is imbalanced data problem. So, for imbalanced data problem needs special treatment, because characteristics of the imbalanced data can decrease the accuracy of the data classification. The proposed method in this study is modified ELM to overcome the problems of imbalanced data by integrating the data selection process, which is called by Integrating the data selection and extreme learning machine (IDELM. Performances of learning method are evaluated using 13 imbalanced data from UCI Machine Learning Repository and Benchmark Data Sets for Highly Imbalanced Binary Classification (BDS). The validation includes comparison with some learning algorithms and the result showcases that average perform of our proposed learning method is compete and even outperform of some algorithm in some cases.
ER  - 

TY  - JOUR
T1  - On the Distributed Implementation of Unsupervised Extreme Learning Machines for Big Data
JO  - Procedia Computer Science
VL  - 53
IS  - 
SP  - 167
EP  - 174
PY  - 2015///
T2  - INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015
AU  - Rizk, Yara
AU  - Awad, Mariette
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2015.07.291
UR  - https://www.sciencedirect.com/science/article/pii/S1877050915017949
KW  - Big data
KW  - Extreme Learning Machines
KW  - Unsupervised learning
KW  - Distributed computing
AB  - Abstract
The emergence of the big data problem has pushed the machine learning research community to develop unsupervised, distributed and computationally efficient learning algorithms to benefit from this data. Extreme learning machines (ELM) have gained popularity as a neuron based architecture with fast training time and good generalization. In this work, we parallelize an ELM algorithm for unsupervised learning on a distributed framework to learn clustering models from big data based on the unsupervised ELM algorithm proposed in the literature. We propose three approaches to do so: 1) Parallel US-ELM which simply distributes the data over computing nodes, 2) Hierarchical US-ELM which hierarchically clusters the data and 3) Ensemble US- ELM which is an ensemble of weak ELM models. The algorithms achieved faster training times compared to their serial counterparts and generalized better than other clustering algorithms in the literature, when tested on multiple datasets from UCI.
ER  - 

TY  - JOUR
T1  - Generic Object Recognition with Local Receptive Fields Based Extreme Learning Machine
JO  - Procedia Computer Science
VL  - 53
IS  - 
SP  - 391
EP  - 399
PY  - 2015///
T2  - INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015
AU  - Bai, Zuo
AU  - Kasun, Liyanaarachchi Lekamalage Chamara
AU  - Huang, Guang-Bin
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2015.07.316
UR  - https://www.sciencedirect.com/science/article/pii/S1877050915018190
KW  - Generic object recognition
KW  - local receptive fields
KW  - Extreme Learning Machine (ELM)
AB  - Abstract
Generic object recognition is to classify the object to a generic category. Intra-class variabilities cause big troubles for this task. Traditional methods involve plenty of pre-processing steps, like model construction, feature extraction, etc. Moreover, these methods are only effective for some specific dataset. In this paper, we propose to use local receptive fields based extreme learning machine (ELM-LRF) as a general framework for object recognition. It is operated directly on the raw images and thus suitable for all different datasets. Additionally, the architecture is simple and only requires few computations, as most connection weights are randomly generated. Comparing to state-of-the-art results on NORB, ETH-80 and COIL datasets, it is on par with the best one on ETH-80 and sets the new records for NORB and COIL.
ER  - 

TY  - JOUR
T1  - Regularized Extreme Learning Machine for Large-scale Media Content Analysis
JO  - Procedia Computer Science
VL  - 53
IS  - 
SP  - 420
EP  - 427
PY  - 2015///
T2  - INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015
AU  - Iosifidis, Alexandros
AU  - Tefas, Anastasios
AU  - Pitas, Ioannis
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2015.07.319
UR  - https://www.sciencedirect.com/science/article/pii/S1877050915018220
KW  - Extreme Learning Machine
KW  - Regularization
KW  - Face Recognition
KW  - Large-scale learning
AB  - Abstract
In this paper, we propose a new regularization approach for Extreme Learning Machine-based Single- hidden Layer Feedforward Neural network training. We show that the proposed regularizer is able to weight the dimensions of the ELM space according to the importance of the network's hidden layer weights, without imposing additional computational and memory costs in the network learning process. This enhances the network's performance and makes the proposed approach suitable for learning non- linear decision surfaces in large-scale classification problems. We test our approach in medium- and large-scale face recognition problems, where we observe its superiority when compared to the existing regularized Extreme Learning Machine classifier in both constrained and unconstrained problems, thus making our approach applicable in demanding media analysis applications such as those appearing in digital cinema production.
ER  - 

TY  - JOUR
T1  - Joint sparse regularization based Sparse Semi-Supervised Extreme Learning Machine (S3ELM) for classification
JO  - Knowledge-Based Systems
VL  - 73
IS  - 
SP  - 149
EP  - 160
PY  - 2015/1//
T2  - 
AU  - Luo, Xiaozhuo
AU  - Liu, F.
AU  - Yang, Shuyuan
AU  - Wang, Xiaodong
AU  - Zhou, Zhiguo
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2014.09.014
UR  - https://www.sciencedirect.com/science/article/pii/S0950705114003542
KW  - Sparse semi-supervised learning
KW  - Extreme learning machine
KW  - â    2  ,  1     -Norm
KW  - Joint sparse regularization
KW  - Laplacian
AB  - Abstract
Extreme Learning Machine (ELM) has received increasing attention for its simple principle, low computational cost and excellent performance. However, a large number of labeled instances are often required, and the number of hidden nodes should be manually tuned, for better learning and generalization of ELM. In this paper, we propose a Sparse Semi-Supervised Extreme Learning Machine (S3ELM) via joint sparse regularization for classification, which can automatically prune the model structure via joint sparse regularization technology, to achieve more accurate, efficient and robust classification, when only a small number of labeled training samples are available. Different with most of greedy-algorithms based model selection approaches, by using â 2 , 1 -norm, S3ELM casts a joint sparse constraints on the training model of ELM and formulate a convex programming. Moreover, with a Laplacian, S3ELM can make full use of the information from both the labeled and unlabeled samples. Some experiments are taken on several benchmark datasets, and the results show that S3ELM is computationally attractive and outperforms its counterparts.
ER  - 

TY  - JOUR
T1  - A study on residence error of training an extreme learning machine and its application to evolutionary algorithms
JO  - Neurocomputing
VL  - 146
IS  - 
SP  - 75
EP  - 82
PY  - 2014/12/25/
T2  - Bridging Machine learning and Evolutionary Computation (BMLEC)Computational Collective Intelligence
AU  - Fu, Ai-Min
AU  - Wang, Xi-Zhao
AU  - He, Yu-Lin
AU  - Wang, Lai-Sheng
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.04.067
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214008777
KW  - Extreme learning machine
KW  - Genetic algorithm
KW  - Rank of matrix
KW  - Residence error
KW  - Solution stability
AB  - Abstract
This paper delivers a study on the change of rank of input matrix in Extreme Learning Machine (ELM) and the relationship between the rank of input matrix and the residence error of training an ELM. From the viewpoint of data analysis, the study reveals why ELM has a decreasing residence error with the increase of number of nodes in hidden layer and what role the Sigmoid function plays in increasing the rank of input matrix. Furthermore the relationship between the stability of solutions and the rank of output matrix is also discussed. An application of residence error to genetic algorithms of minimizing L1-norm ELM is given.
ER  - 

TY  - JOUR
T1  - Regularized extreme learning machine for multi-view semi-supervised action recognition
JO  - Neurocomputing
VL  - 145
IS  - 
SP  - 250
EP  - 262
PY  - 2014/12/5/
T2  - 
AU  - Iosifidis, Alexandros
AU  - Tefas, Anastasios
AU  - Pitas, Ioannis
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.05.036
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214006821
KW  - Extreme learning machine
KW  - Semi-supervised learning
KW  - Multi-view learning
AB  - Abstract
In this paper, three novel classification algorithms aiming at (semi-)supervised action classification are proposed. Inspired by the effectiveness of discriminant subspace learning techniques and the fast and efficient Extreme Learning Machine (ELM) algorithm for Single-hidden Layer Feedforward Neural networks training, the ELM algorithm is extended by incorporating discrimination criteria in its optimization process, in order to enhance its classification performance. The proposed Discriminant ELM algorithm is extended, by incorporating proper regularization in its optimization process, in order to exploit information appearing in both labeled and unlabeled action instances. An iterative optimization scheme is proposed in order to address multi-view action classification. The proposed classification algorithms are evaluated on three publicly available action recognition databases providing state-of-the-art performance in all the cases.
ER  - 

TY  - JOUR
T1  - Online sequential extreme learning machine with kernels for nonstationary time series prediction
JO  - Neurocomputing
VL  - 145
IS  - 
SP  - 90
EP  - 97
PY  - 2014/12/5/
T2  - 
AU  - Wang, Xinying
AU  - Han, Min
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2014.05.068
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214007711
KW  - Online
KW  - Time series
KW  - Extreme learning machine
KW  - Support vector machine
KW  - Nonstationary
AB  - Abstract
In this paper, an online sequential extreme learning machine with kernels (OS-ELMK) has been proposed for nonstationary time series prediction. An online sequential learning algorithm, which can learn samples one-by-one or chunk-by-chunk, is developed for extreme learning machine with kernels. A limited memory prediction strategy based on the proposed OS-ELMK is designed to model the nonstationary time series. Performance comparisons of OS-ELMK with other existing algorithms are presented using artificial and real life nonstationary time series data. The results show that the proposed OS-ELMK produces similar or better accuracies with at least an order-of-magnitude reduction in the learning time.
ER  - 

TY  - JOUR
T1  - A self adaptive differential harmony search based optimized extreme learning machine for financial time series prediction
JO  - Swarm and Evolutionary Computation
VL  - 19
IS  - 
SP  - 25
EP  - 42
PY  - 2014/12//
T2  - 
AU  - Dash, Rajashree
AU  - Dash, P.K.
AU  - Bisoi, Ranjeeta
SN  - 2210-6502
DO  - https://doi.org/10.1016/j.swevo.2014.07.003
UR  - https://www.sciencedirect.com/science/article/pii/S2210650214000546
KW  - CEFLANN
KW  - RBF
KW  - ELM
KW  - Harmony search (HS)
KW  - Differential evolution (DE)
KW  - SADHS-OELM
AB  - Abstract
This paper proposes a hybrid learning framework called Self Adaptive Differential Harmony Search Based Optimized Extreme Learning Machine (SADHS-OELM) for single hidden layer feed forward neural network (SLFN). The new learning paradigm seeks to take advantage of the generalization ability of extreme learning machines (ELM) along with the global learning capability of a self adaptive differential harmony search technique in order to optimize the fitting performance of SLFNs. SADHS is a variant of harmony search technique that uses the current to best mutation scheme of DE in the pitch adjustment operation for harmony improvisation process. SADHS has been used for optimal selection of the hidden layer parameters, the bias of neurons of the hidden-layer, and the regularization factor of robust least squares, whereas ELM has been applied to obtain the output weights analytically using a robust least squares solution. The proposed learning algorithm is applied on two SLFNs i.e. RBF and a low complexity Functional link Artificial Neural Networks (CEFLANN) for prediction of closing price and volatility of five different stock indices. The proposed learning scheme is also compared with other learning schemes like ELM, DE-OELM, DE, SADHS and two other variants of harmony search algorithm. Performance comparison of CEFLANN and RBF with different learning schemes clearly reveals that CEFLANN model trained with SADHS-OELM outperforms other learning methods and also the RBF model for both stock index and volatility prediction.
ER  - 

TY  - JOUR
T1  - Complex extreme learning machine applications in terahertz pulsed signals feature sets
JO  - Computer Methods and Programs in Biomedicine
VL  - 117
IS  - 2
SP  - 387
EP  - 403
PY  - 2014/11//
T2  - 
AU  - Yin, X.-X.
AU  - Hadjiloucas, S.
AU  - Zhang, Y.
SN  - 0169-2607
DO  - https://doi.org/10.1016/j.cmpb.2014.06.002
UR  - https://www.sciencedirect.com/science/article/pii/S0169260714002090
KW  - THz
KW  - Complex extreme learning machine
KW  - Quaternary classification
KW  - Lagrangian
KW  - Multiclass classification
AB  - Abstract
This paper presents a novel approach to the automatic classification of very large data sets composed of terahertz pulse transient signals, highlighting their potential use in biochemical, biomedical, pharmaceutical and security applications. Two different types of THz spectra are considered in the classification process. Firstly a binary classification study of poly-A and poly-C ribonucleic acid samples is performed. This is then contrasted with a difficult multi-class classification problem of spectra from six different powder samples that although have fairly indistinguishable features in the optical spectrum, they also possess a few discernable spectral features in the terahertz part of the spectrum. Classification is performed using a complex-valued extreme learning machine algorithm that takes into account features in both the amplitude as well as the phase of the recorded spectra. Classification speed and accuracy are contrasted with that achieved using a support vector machine classifier. The study systematically compares the classifier performance achieved after adopting different Gaussian kernels when separating amplitude and phase signatures. The two signatures are presented as feature vectors for both training and testing purposes. The study confirms the utility of complex-valued extreme learning machine algorithms for classification of the very large data sets generated with current terahertz imaging spectrometers. The classifier can take into consideration heterogeneous layers within an object as would be required within a tomographic setting and is sufficiently robust to detect patterns hidden inside noisy terahertz data sets. The proposed study opens up the opportunity for the establishment of complex-valued extreme learning machine algorithms as new chemometric tools that will assist the wider proliferation of terahertz sensing technology for chemical sensing, quality control, security screening and clinic diagnosis. Furthermore, the proposed algorithm should also be very useful in other applications requiring the classification of very large datasets.
ER  - 

TY  - JOUR
T1  - Least-squares temporal difference learning based on an extreme learning machine
JO  - Neurocomputing
VL  - 141
IS  - 
SP  - 37
EP  - 45
PY  - 2014/10/2/
T2  - 
AU  - Escandell-Montero, Pablo
AU  - MartÃ­nez-MartÃ­nez, JosÃ© M.
AU  - MartÃ­n-Guerrero, JosÃ© D.
AU  - Soria-Olivas, Emilio
AU  - GÃ³mez-Sanchis, Juan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.11.040
UR  - https://www.sciencedirect.com/science/article/pii/S0925231214003890
KW  - Least-squares temporal difference learning
KW  - Extreme learning machine
KW  - Reinforcement learning
AB  - Abstract
Reinforcement learning (RL) is a general class of algorithms for solving decision-making problems, which are usually modeled using the Markov decision process (MDP) framework. RL can find exact solutions only when the MDP state space is discrete and small enough. Due to the fact that many real-world problems are described by continuous variables, approximation is essential in practical applications of RL. This paper is focused on learning the value function of a fixed policy in continuous MPDs. This is an important subproblem of several RL algorithms. We propose a least-squares temporal difference (LSTD) algorithm based on the extreme learning machine. LSTD is typically combined with local function approximators, which scale poorly with the problem dimensionality. Our approach allows us to approximate value functions using single-hidden layer feedforward networks (SLFNs), a type of artificial neural network extensively used in many fields. Due to the global nature of SLFNs, the proposed approach is more suitable than traditional methods for high-dimensional problems. The method was empirically evaluated on a set of MDPs whose dimensionality varies from 1 to 6. For comparison purposes, experiments were replicated using a standard LSTD algorithm combined with Gaussian radial basis functions. Experimental results suggest that, although both methods can approximate accurately value functions, the proposed approach requires considerably fewer resources for the same degree of accuracy.
ER  - 

TY  - JOUR
T1  - Automatic recognition system of underlying causes of power quality disturbances based on S-Transform and Extreme Learning Machine
JO  - International Journal of Electrical Power & Energy Systems
VL  - 61
IS  - 
SP  - 553
EP  - 562
PY  - 2014/10//
T2  - 
AU  - EriÅti, HÃ¼seyin
AU  - YÄ±ldÄ±rÄ±m, Ãzal
AU  - EriÅti, BelkÄ±s
AU  - Demir, Yakup
SN  - 0142-0615
DO  - https://doi.org/10.1016/j.ijepes.2014.04.010
UR  - https://www.sciencedirect.com/science/article/pii/S0142061514001938
KW  - Power quality events
KW  - S-Transform
KW  - Extreme Learning Machine
KW  - Classification
AB  - Abstract
In this paper, a new S-Transform and Extreme Learning Machine (STâELM)-based event recognition approach for the purpose of classifying power quality (PQ) event signals automatically has been proposed. In this approach, the distinctive features of the PQ event signals have been obtained with the S-Transform-based feature extraction. The feature vector obtained with feature extraction has been applied as input to the ELM classifier. Ten different classification procedures were determined within the framework of this study to assess the performance of the ELM classifier on PQ event data. Real PQ event data and synthetic PQ event data obtained from MATLAB/Simulink environment have been used in these procedures. Also, three different PQ event data sets, which are formed by adding noises of 20, 30 and 50 dB to the synthetic PQ event data respectively, have been used in order to assess the performance of the proposed approach on noisy conditions. According to the results of performance evaluations, the proposed STâELM-based PQ event recognition system has a very high performance of recognizing PQ event data. Besides, classification of noisy data showed that the proposed approach is robust at recognizing noisy data. The performance of the STâELM-based recognition system on PQ data shows that this approach has an effective recognition structure that can be used in real power systems.
ER  - 

TY  - JOUR
T1  - Tuning extreme learning machine by an improved artificial bee colony to model and optimize the boiler efficiency
JO  - Knowledge-Based Systems
VL  - 67
IS  - 
SP  - 278
EP  - 289
PY  - 2014/9//
T2  - 
AU  - Li, Guoqiang
AU  - Niu, Peifeng
AU  - Ma, Yunpeng
AU  - Wang, Hongbin
AU  - Zhang, Weiping
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2014.04.042
UR  - https://www.sciencedirect.com/science/article/pii/S0950705114001725
KW  - Artificial bee colony
KW  - Extreme learning machine
KW  - Greedy selection mechanism
KW  - Opposition-based learning
KW  - Coal-fired boilers
AB  - Abstract
In this paper, a novel optimization technique based on artificial bee colony algorithm (ABC), which is called as PS-ABCII, is presented. In PS-ABCII, there are three major differences from other ABC-based techniques: (1) the opposition-based learning is applied to the population initialization; (2) the greedy selection mechanism is not adopted; (3) the mode that employed bees become scouts is modified. In order to illustrate the superiority of the proposed modified technique over other ABC-based techniques, ten classical benchmark functions are employed to test. In addition, a hybrid model called PS-ABCII-ELM is also proposed in this paper, which is combined of the PS-ABCII and Extreme Learning Machine (ELM). In PS-ABCII-ELM, the PS-ABCII is applied to tune input weights and biases of ELM in order to improve the generalization performance of ELM. And then it is applied to model and optimize the thermal efficiency of a 300 MW coal-fired boiler. The experimental results show that the proposed model is very convenient, direct and accurate, and it can give a general and suitable way to predict and improve the boiler efficiency of a coal-fired boiler under various operating conditions.
ER  - 

TY  - JOUR
T1  - Endpoint prediction model for basic oxygen furnace steel-making based on membrane algorithm evolving extreme learning machine
JO  - Applied Soft Computing
VL  - 19
IS  - 
SP  - 430
EP  - 437
PY  - 2014/6//
T2  - 
AU  - Han, Min
AU  - Liu, Chuang
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2013.09.012
UR  - https://www.sciencedirect.com/science/article/pii/S1568494613003062
KW  - Prediction model
KW  - Extreme learning machine
KW  - Evolutionary membrane algorithm
KW  - Soft measurement
KW  - Basic oxygen furnace
KW  - Endpoint carbon content
KW  - Endpoint temperature
AB  - Abstract
The endpoint parameters of molten steel, such as the steel temperature and the carbon content, directly affect the quality of the production steel. Moreover, these endpoint results cannot be the online continuous measurement in time. To solve the above-mentioned problems, an anti-jamming endpoint prediction model is proposed to predict the endpoint parameters of molten steel. More specifically, the model is constructed on the parameters of extreme learning machine (ELM) adaptively adjusted by the evolutionary membrane algorithm with the global optimization ability. In other words, the evolutionary membrane algorithm may find the suitable parameters of an ELM model which reduces the incidence of the overfitting of ELM affected by the noise in the actual data. Finally, the proposed model is applied to predict the endpoint parameters of molten steel in steel-making. In the simulation experiments, two test problems, including âSinCâ function with the Gaussian noise and the actual production data of basic oxygen furnace (BOF) steel-making, are employed to evaluate the performance of the proposed model. The results indicate that the proposed model has good prediction accuracy and robustness in the data with noise. Therefore, the proposed model has good application prospects in the industrial field.
ER  - 

TY  - JOUR
T1  - Optimally pruned extreme learning machine with ensemble of regularization techniques and negative correlation penalty applied to automotive engine coldstart hydrocarbon emission identification
JO  - Neurocomputing
VL  - 131
IS  - 
SP  - 143
EP  - 156
PY  - 2014/5/5/
T2  - 
AU  - Mozaffari, Ahmad
AU  - Azad, Nasser L.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.10.030
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010898
KW  - Automotive engine modeling
KW  - Coldstart
KW  - Negative correlation based ensembles
KW  - Regularization
KW  - Extreme learning machines
AB  - Abstract
In this investigation, the authors test the efficacy and reliability of optimally pruned extreme learning machine with ensemble of regularization techniques to identify the exhaust gas temperature ( T e x h ) and the engine-out hydrocarbon emission ( H C r a w ) during the coldstart operation of automotive engines. These variables have significant impact on the cumulative tailpipe emissions ( H C c u m ) during a coldstart phenomenon, which is the number one emission-related problem for today's spark-ignited (SI) engine vehicles. To do so, the concepts of ensemble computing with negative correlation learning (NCL) and pruning of neurons are used in tandem to cope with difficulties associated with extracting knowledge from collected database. In the proposed framework, the regularization strategies are adopted to help us increasing the numerical stability of identifier while mitigating the redundant complexity of hidden neurons. Moreover, to increase the generalization of identifier and also reduce the effects of uncertainty, an ensemble of independent OP-ELM with NCL selection criterion called OP-ELM-ER-NCL is taken into account. To endorse the valid performance of OP-ELM-ER-NCL for modeling the characteristics of engine over the coldstart phenomenon, its performance is compared to a set of well-known identification systems, i.e. standard extreme learning machine (ELM), back-propagation neural network (BPNN), OP-ELM with different types of regularization, ensemble of regularized OP-ELM without negative correlation (OP-ELM-ER), and an ensemble ELM with a constrained linear system of leave-one-out outputs (E-LL), in terms of both accuracy and computational complexity. The simulation results indicate that the proposed identifier is really capable of capturing the knowledge of collected database. It is observed that its resulted accuracy and robustness are comparable with those obtained by identification methods available in the literature. Besides, using NCL strategy aids the ensemble to select the most effective regularization techniques and remove the redundant (ineffective) ones, which consequently decreases the complexity of final ensemble.
ER  - 

TY  - JOUR
T1  - Extreme learning machine for ranking: Generalization analysis and applications
JO  - Neural Networks
VL  - 53
IS  - 
SP  - 119
EP  - 126
PY  - 2014/5//
T2  - 
AU  - Chen, Hong
AU  - Peng, Jiangtao
AU  - Zhou, Yicong
AU  - Li, Luoqing
AU  - Pan, Zhibin
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2014.01.015
UR  - https://www.sciencedirect.com/science/article/pii/S0893608014000276
KW  - Learning theory
KW  - Ranking
KW  - Extreme learning machine
KW  - Coefficient regularization
KW  - Generalization bound
AB  - Abstract
The extreme learning machine (ELM) has attracted increasing attention recently with its successful applications in classification and regression. In this paper, we investigate the generalization performance of ELM-based ranking. A new regularized ranking algorithm is proposed based on the combinations of activation functions in ELM. The generalization analysis is established for the ELM-based ranking (ELMRank) in terms of the covering numbers of hypothesis space. Empirical results on the benchmark datasets show the competitive performance of the ELMRank over the state-of-the-art ranking methods.
ER  - 

TY  - JOUR
T1  - Cross-person activity recognition using reduced kernel extreme learning machine
JO  - Neural Networks
VL  - 53
IS  - 
SP  - 1
EP  - 7
PY  - 2014/5//
T2  - 
AU  - Deng, Wan-Yu
AU  - Zheng, Qing-Hua
AU  - Wang, Zhong-Min
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2014.01.008
UR  - https://www.sciencedirect.com/science/article/pii/S0893608014000203
KW  - Extreme learning machine
KW  - Reduced kernel extreme learning machine
KW  - Activity recognition
KW  - Support vector machine
AB  - Abstract
Activity recognition based on mobile embedded accelerometer is very important for developing human-centric pervasive applications such as healthcare, personalized recommendation and so on. However, the distribution of accelerometer data is heavily affected by varying users. The performance will degrade when the model trained on one person is used to others. To solve this problem, we propose a fast and accurate cross-person activity recognition model, known as TransRKELM (Transfer learning Reduced Kernel Extreme Learning Machine) which uses RKELM (Reduced Kernel Extreme Learning Machine) to realize initial activity recognition model. In the online phase OS-RKELM (Online Sequential Reduced Kernel Extreme Learning Machine) is applied to update the initial model and adapt the recognition model to new device users based on recognition results with high confidence level efficiently. Experimental results show that, the proposed model can adapt the classifier to new device users quickly and obtain good recognition performance.
ER  - 

TY  - JOUR
T1  - Ensemble delta test-extreme learning machine (DT-ELM) for regression
JO  - Neurocomputing
VL  - 129
IS  - 
SP  - 153
EP  - 158
PY  - 2014/4/10/
T2  - 
AU  - Yu, Qi
AU  - van Heeswijk, Mark
AU  - Miche, Yoan
AU  - Nian, Rui
AU  - He, Bo
AU  - SÃ©verin, Eric
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.08.041
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009752
KW  - Extreme learning machine
KW  - Incremental learning
KW  - Bayesian information criterion
KW  - Delta test
KW  - Ensemble modeling
AB  - Abstract
Extreme learning machine (ELM) has shown its good performance in regression applications with a very fast speed. But there is still a difficulty to compromise between better generalization performance and smaller complexity of the ELM (a number of hidden nodes). This paper proposes a method called Delta Test-ELM (DT-ELM), which operates in an incremental way to create less complex ELM structures and determines the number of hidden nodes automatically. It uses Bayesian Information Criterion (BIC) as well as Delta Test (DT) to restrict the search as well as to consider the size of the network and prevent overfitting. Moreover, ensemble modeling is used on different DT-ELM models and it shows good test results in Experiments section.
ER  - 

TY  - JOUR
T1  - Online ship roll motion prediction based on grey sequential extreme learning machine
JO  - Neurocomputing
VL  - 129
IS  - 
SP  - 168
EP  - 174
PY  - 2014/4/10/
T2  - 
AU  - Yin, Jian-Chuan
AU  - Zou, Zao-Jian
AU  - Xu, Feng
AU  - Wang, Ni-Ni
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.09.043
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009739
KW  - Extreme learning machine
KW  - Grey prediction
KW  - Grey relational analysis
KW  - Sequential learning
KW  - Radial basis function network
KW  - Ship roll prediction
AB  - Abstract
For the online prediction of nonlinear systems with characteristics of time-varying dynamics and uncertainty, a sequential grey prediction approach is proposed based on the online sequential extreme learning machine (OS-ELM). The grey processing of time series alleviates the unfavorable effects of uncertainty in measurement data; the extremely fast learning speed and high generalization accuracy of OS-ELM enable online application of the sequential grey prediction approach. Ship's roll motion at sea is a complex nonlinear process with time-varying dynamics. Its dynamics also involves uncertainty caused by wind, random waves and rudder actions. In this paper, the proposed OS-ELM-based grey prediction approach is implemented for online ship roll prediction. The simulation of prediction is based on measurement data obtained from sea trials of the scientific research and training ship Yu Kun. Simulation results of ship roll prediction demonstrate the effectiveness and efficiency of the proposed grey neural prediction approach in dealing with time-varying nonlinear system with uncertainty.
ER  - 

TY  - JOUR
T1  - Genetic ensemble of extreme learning machine
JO  - Neurocomputing
VL  - 129
IS  - 
SP  - 175
EP  - 184
PY  - 2014/4/10/
T2  - 
AU  - Xue, Xiaowei
AU  - Yao, Min
AU  - Wu, Zhaohui
AU  - Yang, Jianhua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.09.042
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009727
KW  - Extreme learning machine
KW  - Hybrid model
KW  - Genetic algorithm
KW  - Neural network ensemble
AB  - Abstract
Extreme learning machine (ELM) was proposed as a new learning algorithm to train single-hidden-layer feedforward neural networks (SLFNs). ELM has been proven to perform in high efficiency, however, due to the random determination of parameters for hidden nodes, some un-optimal parameters may be generated to influence the generalization performance and stability. Moreover, ELM may suffer from overtraining problem as the entire training dataset is used to minimize training error. In this paper, a hybrid model is proposed to alleviate such weaknesses of ELM. The model adopts genetic algorithms (GAs) to produce a group of candidate networks first, and according to a specific ranking strategy, some of the networks are selected to ensemble a new network. To verify the performance of our method, empirical comparisons were carried out with the canonical ELM, E-ELM, simple ensemble, EE-ELM, EN-ELM, Bagging and Adaboost to solve both regression and classification problems. The results have shown that our method is able to generate more robust networks with better generalization performance.
ER  - 

TY  - JOUR
T1  - Learning of a single-hidden layer feedforward neural network using an optimized extreme learning machine
JO  - Neurocomputing
VL  - 129
IS  - 
SP  - 428
EP  - 436
PY  - 2014/4/10/
T2  - 
AU  - Matias, Tiago
AU  - Souza, Francisco
AU  - AraÃºjo, Rui
AU  - Antunes, Carlos Henggeler
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.09.016
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009314
KW  - Optimized extreme learning machine
KW  - Single-hidden layer feedforward neural networks
KW  - Genetic algorithms
KW  - Simulated annealing
KW  - Differential evolution
AB  - Abstract
This paper proposes a learning framework for single-hidden layer feedforward neural networks (SLFN) called optimized extreme learning machine (O-ELM). In O-ELM, the structure and the parameters of the SLFN are determined using an optimization method. The output weights, like in the batch ELM, are obtained by a least squares algorithm, but using Tikhonov's regularization in order to improve the SLFN performance in the presence of noisy data. The optimization method is used to the set of input variables, the hidden-layer configuration and bias, the input weights and Tikhonov's regularization factor. The proposed framework has been tested with three optimization methods (genetic algorithms, simulated annealing, and differential evolution) over 16 benchmark problems available in public repositories.
ER  - 

TY  - JOUR
T1  - Double parallel feedforward neural network based on extreme learning machine with L1/2 regularizer
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 113
EP  - 118
PY  - 2014/3/27/
T2  - 
AU  - Khan, Atlas
AU  - Yang, Jie
AU  - Wu, Wei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.053
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009983
KW  - DPFNN
KW  - ELM
KW  - L    1  /  2     regularizer
AB  - Abstract
A learning scheme based on Extreme Learning Machine (ELM) and L 1 / 2 regularization is proposed for a double parallel feedforward neural network. ELM has been widely used as a fast learning method for feedforward networks with a single hidden layer. A key problem for ELM is the choice of the (minimum) number of the hidden nodes. To resolve this problem, we propose to combine the L 1 / 2 regularization method, that becomes popular in recent years in informatics, with ELM. It is shown in our experiments that the involvement of the L 1 / 2 regularizer in DPFNN with ELM results in less hidden nodes but equally good performance.
ER  - 

TY  - JOUR
T1  - 1-Norm extreme learning machine for regression and multiclass classification using Newton method
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 4
EP  - 14
PY  - 2014/3/27/
T2  - 
AU  - Balasundaram, S.
AU  - Gupta, Deepak
AU  - Kapil
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.051
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009946
KW  - Extreme learning machine
KW  - Dual exterior penalty problem
KW  - Feedforward neural networks
KW  - Linear programming problem
KW  - Newton method
AB  - Abstract
In this paper, a novel 1-norm extreme learning machine (ELM) for regression and multiclass classification is proposed as a linear programming problem whose solution is obtained by solving its dual exterior penalty problem as an unconstrained minimization problem using a fast Newton method. The algorithm converges from any starting point and can be easily implemented in MATLAB. The main advantage of the proposed approach is that it leads to a sparse model representation meaning that many components of the optimal solution vector will become zero and therefore the decision function can be determined using much less number of hidden nodes in comparison to ELM. Numerical experiments were performed on a number of interesting real-world benchmark datasets and their results are compared with ELM using additive and radial basis function (RBF) hidden nodes, optimally pruned ELM (OP-ELM) and support vector machine (SVM) methods. Similar or better generalization performance of the proposed method on the test data over ELM, OP-ELM and SVM clearly illustrates its applicability and usefulness.
ER  - 

TY  - JOUR
T1  - Clustering in extreme learning machine feature space
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 88
EP  - 95
PY  - 2014/3/27/
T2  - 
AU  - He, Qing
AU  - Jin, Xin
AU  - Du, Changying
AU  - Zhuang, Fuzhen
AU  - Shi, Zhongzhi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.12.063
UR  - https://www.sciencedirect.com/science/article/pii/S092523121301000X
KW  - Extreme learning machine (ELM)
KW  - ELM feature space
KW  - Data clustering
KW  - Nonnegative matrix factorization (NMF)
KW  - ELM kMeans
KW  - ELM NMF clustering
AB  - Abstract
Extreme learning machine (ELM), used for the âgeneralizedâ single-hidden-layer feedforward networks (SLFNs), is a unified learning platform that can use a widespread type of feature mappings. In theory, ELM can approximate any target continuous function and classify any disjoint regions; in application, many experiment results have already demonstrated the good performance of ELM. In view of the good properties of the ELM feature mapping, the clustering problem using ELM feature mapping techniques is studied in this paper. Experiments show that the proposed ELM kMeans algorithm and ELM NMF (nonnegative matrix factorization) clustering can get better clustering results than the corresponding Mercer kernel based methods and the traditional algorithms using the original data. Moreover, the proposed methods have the advantage of being more convenient to implementation and computation, as the ELM feature mapping is much simpler than the Mercer kernel function based feature mapping methods.
ER  - 

TY  - JOUR
T1  - Discrete-time hypersonic flight control based on extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 232
EP  - 241
PY  - 2014/3/27/
T2  - 
AU  - Xu, Bin
AU  - Pan, Yongping
AU  - Wang, Danwei
AU  - Sun, Fuchun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.02.049
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010035
KW  - Hypersonic aircraft
KW  - Extreme learning machine
KW  - Neural networks
KW  - Single-hidden layer feedforward network
AB  - Abstract
This paper describes the neural controller design for the longitudinal dynamics of a generic hypersonic flight vehicle (HFV). The dynamics are transformed into the strict-feedback form. Considering the uncertainty, the neural controller is constructed based on the single-hidden layer feedforward network(SLFN). The hidden node parameters are modified using extreme learning machine (ELM) by assigning random values. Instead of using online sequential learning algorithm (OSLA), the output weight is updated based on the Lyapunov synthesis approach to guarantee the stability of closed-loop system. By estimating the bound of output weight vector, a novel back-stepping design is presented where less online parameters are required to be tuned. The simulation study is presented to show the effectiveness of the proposed control approach.
ER  - 

TY  - JOUR
T1  - Bankruptcy prediction using Extreme Learning Machine and financial expertise
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 296
EP  - 302
PY  - 2014/3/27/
T2  - 
AU  - Yu, Qi
AU  - Miche, Yoan
AU  - SÃ©verin, Eric
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.01.063
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010011
KW  - Extreme Learning Machine
KW  - Leave-One-Out
KW  - Incremental Learning
KW  - Bankruptcy Prediction
AB  - Abstract
Bankruptcy prediction has been widely studied as a binary classification problem using financial ratios methodologies. In this paper, Leave-One-Out-Incremental Extreme Learning Machine (LOO-IELM) is explored for this task. LOO-IELM operates in an incremental way to avoid inefficient and unnecessary calculations and stops automatically with the neurons of which the number is unknown. Moreover, Combo method and further Ensemble model are investigated based on different LOO-IELM models and the specific financial indicators. These indicators are chosen using different strategies according to the financial expertise. The entire process has shown its good performance with a very fast speed, and also helps to interpret the model and the special ratios.
ER  - 

TY  - JOUR
T1  - A multi-output two-stage locally regularized model construction method using the extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 104
EP  - 112
PY  - 2014/3/27/
T2  - 
AU  - Du, Dajun
AU  - Li, Kang
AU  - Li, Xue
AU  - Fei, Minrui
AU  - Wang, Haikuan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.056
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010060
KW  - Extreme learning machine
KW  - Multi-output linear-in-the-parameters (LITP) model
KW  - Regularization
KW  - Two-stage stepwise selection
AB  - Abstract
This paper investigates the construction of linear-in-the-parameters (LITP) models for multi-output regression problems. Most existing stepwise forward algorithms choose the regressor terms one by one, each time maximizing the model error reduction ratio. The drawback is that such procedures cannot guarantee a sparse model, especially under highly noisy learning conditions. The main objective of this paper is to improve the sparsity and generalization capability of a model for multi-output regression problems, while reducing the computational complexity. This is achieved by proposing a novel multi-output two-stage locally regularized model construction (MTLRMC) method using the extreme learning machine (ELM). In this new algorithm, the nonlinear parameters in each term, such as the width of the Gaussian function and the power of a polynomial term, are firstly determined by the ELM. An initial multi-output LITP model is then generated according to the termination criteria in the first stage. The significance of each selected regressor is checked and the insignificant ones are replaced at the second stage. The proposed method can produce an optimized compact model by using the regularized parameters. Further, to reduce the computational complexity, a proper regression context is used to allow fast implementation of the proposed method. Simulation results confirm the effectiveness of the proposed technique.
ER  - 

TY  - JOUR
T1  - Predicting pupylation sites in prokaryotic proteins using pseudo-amino acid composition and extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 267
EP  - 272
PY  - 2014/3/27/
T2  - 
AU  - Fan, Yong-Xian
AU  - Shen, Hong-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.11.058
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009958
KW  - Pupylated protein
KW  - Pupylation sites
KW  - Pseudo-amino acid composition
KW  - Extreme learning machine
KW  - Bioinformatics
KW  - PupS
AB  - Abstract
Pupylation is one of the most important post-translational modifications of prokaryotic proteins playing a key role in regulating a wild range of biological processes. Prokaryotic ubiquitin-like protein can attach to specific lysine residues of substrate proteins by forming isopeptide bonds for the selective degradation of proteins in Mycobacterium tuberculosis. In order to comprehensively understand these pupylation-related biological processes, identification of pupylation sites in the substrate protein sequence is the first step. The traditional wet-lab experimental approaches are both laborious and time-consuming. To timely and effectively discover pupylation sites when facing with the avalanche of new protein sequences emerging during the post-genomic Era, a novel computational predictor called PupS (pupylation site predictor) is proposed. PupS is constructed on the pseudo-amino acid composition and trained with extreme learning machine. The jackknife cross-validation results on the training dataset show that the area under an ROC Curve (AUC) value is 0.6483 by PupS, and an AUC of 0.6779 is obtained on the independent set. Our results also demonstrate that ELM is complementary to other algorithms and that constructing an ensemble classifier will generate better results. PupS software package is available at http://www.csbio.sjtu.edu.cn/bioinf/PupS/.
ER  - 

TY  - JOUR
T1  - Time-series processing of large scale remote sensing data with extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 199
EP  - 206
PY  - 2014/3/27/
T2  - 
AU  - Chen, Jiaoyan
AU  - Zheng, Guozhou
AU  - Fang, Cong
AU  - Zhang, Ningyu
AU  - Chen, Huajun
AU  - Wu, Zhaohui
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.02.051
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010084
KW  - Extreme learning machine
KW  - Remote sensing
KW  - Classification
KW  - Change detection
KW  - Time-series
AB  - Abstract
Nowadays, land-cover change detection plays a more and more important role in environment protection and many other fields. However, the current land-cover change detection methods encounter the problems of low accuracy and low efficiency, especially in dealing with large scale remote sensing (RS) data. This paper presents a novel extreme learning machine (ELM) based land-cover change detection method with high testing accuracy and fast processing speed. The evaluation results show that ELM outperforms the traditional methods, e.g., SVM and BP network, in terms of training speed and generalization performance, when applied in land-cover classification. In our experiments, we apply our method to the analysis of rapid land use change in Taihu Lake region over the past decade.
ER  - 

TY  - JOUR
T1  - Extreme learning machines for soybean classification in remote sensing hyperspectral images
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 207
EP  - 216
PY  - 2014/3/27/
T2  - 
AU  - Moreno, RamÃ³n
AU  - Corona, Francesco
AU  - Lendasse, Amaury
AU  - GraÃ±a, Manuel
AU  - GalvÃ£o, LÃªnio S.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.057
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010102
KW  - Extreme learning machine
KW  - Hyperspectral images
KW  - Agricultural remote sensing
AB  - Abstract
This paper focuses on the application of Extreme Learning Machines (ELM) to the classification of remote sensing hyperspectral data. The specific aim of the work is to obtain accurate thematic maps of soybean crops, which have proven to be difficult to identify by automated procedures. The classification process carried out is as follows: First, spectral data is transformed into a hyper-spherical representation. Second, a robust image gradient is computed over the hyper-spherical representation allowing an image segmentation that identifies major crop plots. Third, feature selection is achieved by a greedy wrapper approach. Finally, a classifier is trained and tested on the selected image pixel features. The classifiers used for feature selection and final classification are Single Layer Feedforward Networks (SLFN) trained with either the ELM or the incremental OP-ELM. Original image pixel features are computed following a Functional Data Analysis (FDA) characterization of the spectral data. Conventional ELM training of the SLFN improves over the classification performance of state of the art algorithms reported in the literature dealing with the data treated in this paper. Moreover, SLFN-ELM uses less features than the referred algorithms. OP-ELM is able to find competitive results using the FDA features from a single spectral band.
ER  - 

TY  - JOUR
T1  - Hierarchical extreme learning machine for feedforward neural network
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 128
EP  - 135
PY  - 2014/3/27/
T2  - 
AU  - Han, Hong-Gui
AU  - Wang, Li-Dan
AU  - Qiao, Jun-Fei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.01.057
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213007339
KW  - Hierarchical extreme learning machine
KW  - Feedforward neural network
KW  - Wastewater treatment process
KW  - Predicting water qualities
AB  - Abstract
An approach, named extended extreme learning machine (ELM), is proposed for training the weights of a class of hierarchical feedforward neural network (HFNN). Unlike conventional single-hidden-layer feedforward networks (SLFNs), this hierarchical ELM (HELM) is based on the hierarchical structure which is capable of hierarchical learning of sequential information online, and one may simply choose hidden layers and then only need to adjust the output weights linking the hidden layer and the output layer. In such HELM implementations, the extended ELM provides better generalization performance during the learning process. Moreover, the proposed extended ELM method is efficient not only for HFNNs with sigmoid hidden nodes but also for HFNNs with radial basis function (RBF) hidden nodes. Finally, the HELM is applied to the activated sludge wastewater treatment processes (WWTPs) for predicting the water qualities. Experimental results and the performance comparison demonstrate the effectiveness of the proposed HELM.
ER  - 

TY  - JOUR
T1  - Extreme learning machine towards dynamic model hypothesis in fish ethology research
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 273
EP  - 284
PY  - 2014/3/27/
T2  - 
AU  - Nian, Rui
AU  - He, Bo
AU  - Zheng, Bing
AU  - van Heeswijk, Mark
AU  - Yu, Qi
AU  - Miche, Yoan
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.054
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009995
KW  - Extreme learning machine
KW  - Fish ethology
KW  - Video surveillance system
KW  - Dynamic state space
KW  - Color distribution
KW  - Object recognition
AB  - Abstract
In this paper, we present one dynamic model hypothesis to perform fish trajectory tracking in the fish ethology research and develop the relevant mathematical criterion on the basis of the Extreme Learning Machine (ELM). It is shown that the proposed scheme can conduct the non-linear and non Gaussian tracking process by multiple historical cues and current predictions â the state vector motion, the color distribution and the appearance recognition, all of which can be extracted from the single-hidden layer feedforward neural network (SLFN) at diverse levels with ELM. The strategy of the hierarchical hybrid ELM ensemble then combines the individual SLFN of the tracking cues for the performance improvements. The simulation results have shown the excellent performance in both robustness and accuracy of the developed approach.
ER  - 

TY  - JOUR
T1  - Predicting minority class for suspended particulate matters level by extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 136
EP  - 144
PY  - 2014/3/27/
T2  - 
AU  - Vong, Chi-Man
AU  - Ip, Weng-Fai
AU  - Wong, Pak-Kin
AU  - Chiu, Chi-Chong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.11.056
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009880
KW  - PM10
KW  - Extreme learning machine (ELM)
KW  - Support vector machine (SVM)
KW  - Imbalance problem
KW  - Prior duplication
AB  - Abstract
Suspended particulate matters (PM10) is considered as a harmful air pollutant. Many models attempt to predict numerical levels of PM10 but a simple, clearly defined classification of PM10 levels is more readily comprehensible to the general public rather than a numerical value. However, the PM10 prediction model often suffers from data imbalance problem in the training dataset that results in failure to forecast the minority class of severe cases. In this study, a warning system using extreme learning machine (ELM), compared with support vector machine (SVM), was constructed to forecast the class of PM10 level: Good, Moderate, and Severe. An imbalance strategy called prior duplication was also applied to improve the forecast of minority class. The experimental comparisons between ELM and SVM demonstrate that ELM produces superior accuracy relative to SVM in forecasting minority class (Severe) of PM10 level with or without the imbalance strategy. Furthermore, our results show that the required training time and model size in the ELM model are much shorter and smaller than those of SVM respectively, leading to a more efficient and practical implementation of prediction model for large dataset. The performance superiority of ELM is also discussed in this paper.
ER  - 

TY  - JOUR
T1  - Fast prediction of proteinâprotein interaction sites based on Extreme Learning Machines
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 258
EP  - 266
PY  - 2014/3/27/
T2  - 
AU  - Wang, Debby D.
AU  - Wang, Ran
AU  - Yan, Hong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.12.062
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009892
KW  - Proteinâprotein interaction sites
KW  - Extreme Learning Machines
KW  - Support vector machines
KW  - Residue sequence profile
AB  - Abstract
Conventional machine learning methods can be used to identify proteinâprotein interaction sites and study the gene regulatory networks and functions. However, when applied to large datasets, the computational complexities of these methods become a major drawback. With a significantly reduced computational complexity, the Extreme Learning Machines provide an attractive balance between computational time and generalization performance. In the method proposed in this paper, after searching for interfacial residues using a dynamic strategy and extracting spatially neighboring residue profiles for a set of 563 non-redundant protein chains, we implement the interface prediction either on multi-chain sets or on single-chain sets, using the two methods Extreme Learning Machines and support vector machines for a comparable study. As a consequence, in both multi-chain and single-chain cases Extreme Learning Machines tend to obtain higher Recall values than support vector machines, and in the multi-chain case Extreme Learning Machines as well show a remarkable advantage in the computational speed.
ER  - 

TY  - JOUR
T1  - Online fault diagnosis method based on Incremental Support Vector Data Description and Extreme Learning Machine with incremental output structure
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 224
EP  - 231
PY  - 2014/3/27/
T2  - 
AU  - Yin, Gang
AU  - Zhang, Ying-Tang
AU  - Li, Zhi-Ning
AU  - Ren, Guo-Quan
AU  - Fan, Hong-Bo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.01.061
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009910
KW  - Incremental Support Vector Data Description
KW  - Extreme Learning Machine
KW  - Multi-scale principal component analysis
KW  - Online fault diagnosis
AB  - Abstract
Online fault diagnosis system should be able to detect faults, recognize fault types and update the discriminating ability and knowledge of itself automatically in real time. But the class number in fault diagnosis is not constant and it is in a dynamic state with new members enrolled. The traditional recognition algorithms are not able to update diagnosis system efficiently when the class number of failure modes is increasing. To solve the problem, an online fault diagnosis method based on Incremental Support Vector Data Description (ISVDD) and Extreme Learning Machine with incremental output structure (IOELM) is proposed. ISVDD is used to find a new failure mode quickly in the continuous condition monitoring of the equipments. The fixed structure of Extreme Learning Machine is changed into an elastic structure whose output nodes could be added incrementally to recognize the new fault mode efficiently. Recognition experiments on the diesel engine under eleven different conditions show that the online fault diagnosis method based on ISVDD and IOELM works well, and the method is also feasible in fault diagnosis of other mechanical equipments.
ER  - 

TY  - JOUR
T1  - Constructive multi-output extreme learning machine with application to large tanker motion dynamics identification
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 59
EP  - 72
PY  - 2014/3/27/
T2  - 
AU  - Wang, Ning
AU  - Han, Min
AU  - Dong, Nuo
AU  - Er, Meng Joo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.01.062
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009922
KW  - Extreme learning machine
KW  - Constructive method
KW  - Improved multi-response sparse regression
KW  - Multi-output regression
KW  - Tanker motion dynamics
AB  - Abstract
In this paper, a novel constructive multi-output extreme learning machine (CM-ELM) is proposed to deal with a large tanker motion dynamics identification. The significant contributions are as follows. (1) Driven by generated tanker dynamics data from the reference model, the CM-ELM method is proposed to identify multi-output dynamic models. (2) The candidate pool for CM-ELM is randomly generated by the ELM strategy, and ranked chunk-by-chunk based on a novel improved multi-response sparse regression (I-MRSR) incorporated with Î» weighting. (3) Consequently, the constructive model selection works with fast speed due to chunk-type training process, which also benefits stable hidden node selection and corresponding generalization. (4) Furthermore, output weight update on the final CM-ELM model randomly selected from the elite subset is conducted to enhance the overall performance of the resulting CM-ELM scheme. Finally, the convincing performance of the complete CM-ELM paradigm is verified by simulation studies on not only tanker motion dynamics identification but also benchmark multi-output regressions. Comprehensive comparisons of the CM-ELM with ELM and OP-ELM indicate the remarkable superiority in terms of generalization capability and stable compact structure. Conclusions are steadily drawn that the CM-ELM method is feasibly effective for tanker motion dynamics identification and multi-output regressions.
ER  - 

TY  - JOUR
T1  - Advances in extreme learning machines (ELM2012)
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 1
EP  - 3
PY  - 2014/3/27/
T2  - 
AU  - Lendasse, Amaury
AU  - He, Qing
AU  - Miche, Yoan
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.10.013
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010175
ER  - 

TY  - JOUR
T1  - Parallelized extreme learning machine ensemble based on minâmax modular network
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 31
EP  - 41
PY  - 2014/3/27/
T2  - 
AU  - Wang, Xiao-Lin
AU  - Chen, Yang-Yang
AU  - Zhao, Hai
AU  - Lu, Bao-Liang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.02.053
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010187
KW  - Extreme learning machine
KW  - Minâmax modular network
KW  - Big data
KW  - Ensemble method
KW  - Parallel learning
AB  - Abstract
Extreme Learning Machine (ELM) as an emergent technology has shown its promising performance in many applications. This paper proposes a parallelized ELM ensemble based on the MinâMax Modular network (M3-network) to meet the challenge of the so-called big data. The proposed M3-ELM first decomposes classification problems into smaller subproblems, then trains an ELM for each subproblem, and in the end ensembles these ELMs with the M3-network. Twelve data sets including both benchmarks and real-world applications are employed to test the proposed method. The experimental results show that M3-ELM not only speeds up the training phrases by 1.6â4.6 times but also reduces the test errors by 0.37â19.51% compared with the normal ELM. The results also indicate that M3-ELM possesses scalability on large-scale tasks and accuracy improvement on imbalanced tasks.
ER  - 

TY  - JOUR
T1  - TOSELM: Timeliness Online Sequential Extreme Learning Machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 119
EP  - 127
PY  - 2014/3/27/
T2  - 
AU  - Gu, Yang
AU  - Liu, Junfa
AU  - Chen, Yiqiang
AU  - Jiang, Xinlong
AU  - Yu, Hanchao
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.02.047
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009120
KW  - Timeliness
KW  - Online sequential learning
KW  - Adaptive weight
KW  - Adaptive iteration
AB  - Abstract
For handling data and training model, existing machine learning methods do not take timeliness problem into consideration. Timeliness here means the data distribution or the data trend changes with time passing by. Based on timeliness management scheme, a novel machine learning algorithm Timeliness Online Sequential Extreme Learning Machine (TOSELM) is proposed, which improves Online Sequential Extreme Learning Machine (OSELM) with central tendency and dispersion characteristics of data to deal with timeliness problem. The performance of proposed algorithm has been validated on several simulated and realistic datasets, and experimental results show that TOSELM utilizing adaptive weight scheme and iteration scheme can achieve higher learning accuracy, faster convergence and better stability than other machine learning methods.
ER  - 

TY  - JOUR
T1  - Extreme learning machine for classification over uncertain data
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 500
EP  - 506
PY  - 2014/3/27/
T2  - 
AU  - Sun, Yongjiao
AU  - Yuan, Ye
AU  - Wang, Guoren
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.08.011
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213008849
KW  - Extreme learning machine
KW  - Uncertain data
KW  - OS-ELM
KW  - SVM
KW  - Single hidden layer feedforward neural networks
AB  - Abstract
Conventional classification algorithms assume that the input data is exact or precise. Due to various reasons, including imprecise measurement, network delay, outdated sources and sampling errors, data uncertainty is common and widespread in real-world applications, such as sensor database, location database, biometric information systems. Though there exist a lot of approaches for classification, few of them address the problem of classification over uncertain data in database. Therefore, in this paper, we propose classification algorithms based on conventional and optimized ELM to conduct classification over uncertain data. Firstly we view the instances of each uncertain data as the training data for learning. Then, the probabilities of uncertain data in any class are computed according to learning results of each instance. Finally, using a bound-based approach, we implement the final classification. We also extend the proposed algorithms to classification over uncertain data in a distributed environment based on OS-ELM and Monte Carlo theory. The experiments verify the performance of our proposed algorithms.
ER  - 

TY  - JOUR
T1  - Fast sparse approximation of extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 96
EP  - 103
PY  - 2014/3/27/
T2  - 
AU  - Li, Xiaodong
AU  - Mao, Weijie
AU  - Jiang, Wei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.01.064
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010047
KW  - Fast greedy algorithm
KW  - Extreme learning machine (ELM)
KW  - Sparse approximation
AB  - Abstract
We introduce a fast sparse approximation schemes of extreme learning machine (ELM) named FSA-ELM of extreme learning machine (ELM). Our algorithms have two compelling features: low complexity and sparse solution. Experiments on benchmark data sets show that the proposed algorithm obtains sparse classifiers at a rather low complexity without sacrificing the generalization performance. As validated by the simulation results, FSA-ELM tends to have better scalability and achieves similar or much better generalization performance with much faster learning speed than the traditional ELM algorithm.
ER  - 

TY  - JOUR
T1  - Vehicle detection in driving simulation using extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 160
EP  - 165
PY  - 2014/3/27/
T2  - 
AU  - Zhu, Wentao
AU  - Miao, Jun
AU  - Hu, Jiangbi
AU  - Qing, Laiyun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.05.052
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010126
KW  - Extreme learning machine
KW  - Driving simulation
KW  - Vehicle detection
KW  - Road segmentation
AB  - Abstract
Automatically driving based on computer vision has attracted more and more attentions from both research and industrial fields. It has two main challenges, high road and vehicle detection accuracy and real-time performance. To study the two problems, we developed a driving simulation platform in a virtual scene. In this paper, as the first step of final solution, the Extreme Learning Machine (ELM) has been used to detect the virtual roads and vehicles. The Support Vector Machine (SVM) and Back Propagation (BP) network have been used as benchmark. Our experimental results show that the ELM has the fastest performance on road segmentation and vehicle detection with the similar accuracy compared with other techniques.
ER  - 

TY  - JOUR
T1  - A hierarchical structure of extreme learning machine (HELM) for high-dimensional datasets with noise
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 407
EP  - 414
PY  - 2014/3/27/
T2  - 
AU  - He, Yan-Lin
AU  - Geng, Zhi-Qiang
AU  - Xu, Yuan
AU  - Zhu, Qun-Xiong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.08.024
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213009004
KW  - Extreme learning machine
KW  - Single-hidden-layer feedforward neural networks
KW  - Auto-associative neural network
KW  - Matter-element model
KW  - Data attributes extension classification
AB  - Abstract
Extreme Learning Machine (ELM), a competitive machine learning technique for single-hidden-layer feedforward neural networks (SLFNNs), is simple in theory and fast in implementation. To deal with high-dimensional data with noise, ELM with a hierarchical structure (HELM) is proposed in this paper. The proposed HELM consists of two parts: some groups of subnets and a main net. The subnets are based on some well-trained auto-associative neural networks (AANNs), which can reduce dimension and filter out noise. The main net is based on the traditional ELM. Additionally, from the perspective of data attributes spaces (DASs), the difficulties in designing subnets are avoided by using a method of Data Attributes Extension Classification (DAEC). Experiments on five high-dimensional datasets with noise are carried out to examine the HELM model. Experimental results show that HELM has higher accuracy with fewer neurons in the main net than ELM.
ER  - 

TY  - JOUR
T1  - Neural modeling of vapor compression refrigeration cycle with extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 242
EP  - 248
PY  - 2014/3/27/
T2  - 
AU  - Zhao, Lei
AU  - Cai, Wen-Jian
AU  - Man, Zhi-Hong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.058
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010138
KW  - Extreme learning machine
KW  - Vapor compression refrigeration cycle
KW  - Modeling
KW  - Back propagation
KW  - Support vector regression
KW  - Radial basis function
AB  - Abstract
In this paper, a single-hidden layer feed-forward neural network (SLFN) is used to model the dynamics of the vapor compression cycle in refrigeration and air-conditioning systems, based on the extreme learning machine (ELM). It is shown that the assignment of the random input weights of the SLFN can greatly reduce the training time, and the regularization based optimization of the output weights of the SLFN ensures the high accuracy of the modeling of the dynamics of vapor compression cycle and the robustness of the SLFN against high frequency disturbances. The new SLFN model is tested with the real experimental data and compared with the ones trained with the back propagation (BP), the support vector regression (SVR) and the radial basis function neural network (RBF), respectively, with the results that the high degree of prediction accuracy and strongest robustness against the input disturbances are achieved.
ER  - 

TY  - JOUR
T1  - Real-time fault diagnosis for gas turbine generator systems using extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 249
EP  - 257
PY  - 2014/3/27/
T2  - 
AU  - Wong, Pak Kin
AU  - Yang, Zhixin
AU  - Vong, Chi Man
AU  - Zhong, Jianhua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.059
UR  - https://www.sciencedirect.com/science/article/pii/S092523121301014X
KW  - Real-time fault diagnosis
KW  - Gas turbine generator system
KW  - Extreme learning machine
KW  - Wavelet packet transform
KW  - Time-domain statistical features
KW  - Kernel principal component analysis
AB  - Abstract
Real-time fault diagnostic system is very important to maintain the operation of the gas turbine generator system (GTGS) in power plants, where any abnormal situation will interrupt the electricity supply. The GTGS is complicated and has many types of component faults. To prevent from interruption of electricity supply, a reliable and quick response framework for real-time fault diagnosis of the GTGS is necessary. As the architecture and the learning algorithm of extreme learning machine (ELM) are simple and effective respectively, ELM can identify faults quickly and precisely as compared with traditional identification techniques such as support vector machines (SVM). This paper therefore proposes a new application of ELM for building a real-time fault diagnostic system in which data pre-processing techniques are integrated. In terms of data pre-processing, wavelet packet transform and time-domain statistical features are proposed for extraction of vibration signal features. Kernel principal component analysis is then applied to further reduce the redundant features in order to shorten the fault identification time and improve accuracy. To evaluate the system performance, a comparison between ELM and the prevailing SVM on the fault detection was conducted. Experimental results show that the proposed diagnostic framework can detect component faults much faster than SVM, while ELM is competitive with SVM in accuracy. This paper is also the first in the literature that explores the superiority of the fault identification time of ELM.
ER  - 

TY  - JOUR
T1  - Dissimilarity based ensemble of extreme learning machine for gene expression data classification
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 22
EP  - 30
PY  - 2014/3/27/
T2  - 
AU  - Lu, Hui-juan
AU  - An, Chun-lin
AU  - Zheng, En-hui
AU  - Lu, Yi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.02.052
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010151
KW  - Extreme learning machine
KW  - Dissimilarity ensemble
KW  - Double-fault measure
KW  - Majority voting
KW  - Gene expression data
AB  - Abstract
Extreme learning machine (ELM) has salient features such as fast learning speed and excellent generalization performance. However, a single extreme learning machine is unstable in data classification. To overcome this drawback, more and more researchers consider using ensemble of ELMs. This paper proposes a method integrating voting-based extreme learning machines (V-ELMs) with dissimilarity (D-ELM). First, based on different dissimilarity measures, we remove a number of ELMs from the ensemble pool. Then, the remaining ELMs are grouped as an ensemble classifier by majority voting. Finally we use disagreement measure and double-fault measure to validate the D-ELM. The theoretical analysis and experimental results on gene expression data demonstrate that (1) the D-ELM can achieve better classification accuracy with less number of ELMs; (2) the double-fault measure based D-ELM (DF-D-ELM) performs better than disagreement measure based D-ELM (D-D-ELM).
ER  - 

TY  - JOUR
T1  - Breast tumor detection in digital mammography based on extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 175
EP  - 184
PY  - 2014/3/27/
T2  - 
AU  - Wang, Zhiqiong
AU  - Yu, Ge
AU  - Kang, Yan
AU  - Zhao, Yingjie
AU  - Qu, Qixun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.05.053
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010163
KW  - Extreme learning machine
KW  - Breast tumor detection
KW  - Mammography
KW  - Image segmentation
KW  - Feature extraction
AB  - Abstract
Breast tumor detection in digital mammography is one of the most important methods of breast cancer prevention. Computer-aided diagnosis (CAD) based on extreme learning machine (ELM) has significant meanings for breast tumor detection as it has good generalization abilities and a high learning efficiency. In this paper, a breast tumor detection algorithm in digital mammography based on ELM is proposed. First, a median filter is used for noise reduction, and contrast enhancement of the digital mammography in data preprocessing. Next, methods of wavelet modulus maxima transform, morphological operation and region growth are used for the breast tumor edge segmentation. Then, five textural features and five morphological features are extracted. Finally, an ELM classifier is used to detect the breast tumor. Comparing breast tumor detection based on Support Vector Machines (SVM), with breast tumor detection based on ELM, not only does ELM have a better classification accuracy than SVM, but it also has a greatly improved training speed.
ER  - 

TY  - JOUR
T1  - An incremental extreme learning machine for online sequential learning problems
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 50
EP  - 58
PY  - 2014/3/27/
T2  - 
AU  - Guo, Lu
AU  - Hao, Jing-hua
AU  - Liu, Min
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.03.055
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010059
KW  - Incremental learning algorithm
KW  - Extreme learning machine (ELM)
KW  - Incremental ELM (IELM)
KW  - Online sequential ELM (OS-ELM)
KW  - Fixed size LSSVM (FS-LSSVM)
AB  - Abstract
A fast and outstanding incremental learning algorithm is required to meet the demand of online applications where data comes one by one or chunk by chunk to avoid retraining and save precious time. Although many interesting research results have been achieved, there are still a lot of difficulties in real applications because of their unsatisfying generalization performance or intensive computation cost. This paper presents an Incremental Extreme Learning Machine (IELM) which is developed based on Extreme Learning Machine (ELM), a unified framework of LS-SVM and PSVM presented by Hang et al. (2011) in [15]. Under different application demand and different computational cost and efficiency, three different alternative solutions of IELM are achieved. Detailed comparisons of the IELM algorithm with other incremental algorithms are achieved by simulation on benchmark problems and real critical dimension (CD) prediction problem in lithography of actual semiconductor production line. The results show that kernel based IELM solution performs best while least square IELM solution is the fastest of the three alterative solutions when the number of training data is huge. All the results show that the presented IELM algorithms have better performance than other incremental algorithms such as online sequential ELM (OS-ELM) presented by Liang et al. (2006) [8] and fixed size LSSVM presented by Espinoza et al. (2006) [11].
ER  - 

TY  - JOUR
T1  - Aircraft recognition using modular extreme learning machine
JO  - Neurocomputing
VL  - 128
IS  - 
SP  - 166
EP  - 174
PY  - 2014/3/27/
T2  - 
AU  - Rong, Hai-Jun
AU  - Jia, Ya-Xin
AU  - Zhao, Guang-She
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.12.064
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213010023
KW  - Single-hidden layer feedforward network
KW  - Extreme learning machine
KW  - Aircraft recognition
KW  - Hu moments
KW  - Zernike moments
KW  - Wavelet moments
AB  - Abstract
In this paper, a novel recognition scheme is proposed for identifying the aircrafts of different types based on multiple modular neural network classifiers. Three moment invariants including Hu moments, Zernike moments and Wavelet moments are extracted from the characteristics exhibited by aircrafts and used as the input variables of each modular neural network respectively. Each modular neural network consists of multiple single-hidden layer feedforward networks which are trained using the extreme learning machine and different clustering data subsets. A clustering and selection method is used to get the classification rate of each modular neural network and then based on their weighted sum the final classification output is obtained. The proposed recognition scheme is finally evaluated by recognizing six different types of aircraft models and the simulation results show the superiority of the proposed method compared with the single ELM classifier and other classification algorithms.
ER  - 

TY  - JOUR
T1  - A framework on wavelet-based nonlinear features and extreme learning machine for epileptic seizure detection
JO  - Biomedical Signal Processing and Control
VL  - 10
IS  - 
SP  - 1
EP  - 10
PY  - 2014/3//
T2  - 
AU  - Chen, Lan-Lan
AU  - Zhang, Jian
AU  - Zou, Jun-Zhong
AU  - Zhao, Chen-Jie
AU  - Wang, Gui-Song
SN  - 1746-8094
DO  - https://doi.org/10.1016/j.bspc.2013.11.010
UR  - https://www.sciencedirect.com/science/article/pii/S1746809413001754
KW  - Seizure detection
KW  - Wavelet decomposition
KW  - Approximate entropy (ApEn)
KW  - Sample entropy (SampEn)
KW  - Recurrence quantification analysis (RQA)
KW  - Extreme learning machine (ELM)
KW  - Support vector machine (SVM)
AB  - AbstractBackground
Many investigations based on nonlinear methods have been carried out for the research of seizure detection. However, some of these nonlinear measures cannot achieve satisfying performance without considering the basic rhythms of epileptic EEGs.
New method
To overcome the defects, this paper proposed a framework on wavelet-based nonlinear features and extreme learning machine (ELM) for the seizure detection. Three nonlinear methods, i.e., approximate entropy (ApEn), sample entropy (SampEn) and recurrence quantification analysis (RQA) were computed from orignal EEG signals and corresponding wavelet decomposed sub-bands separately. The wavelet-based energy was measured as the comparative. Then the combination of sub-band features was fed to ELM and SVM classifier respectively.
Results
The decomposed sub-band signals show significant discrimination between interictal and ictal states and the union of sub-band features helps to achieve better detection. All the three nonlinear methods show higher sensitivity than the wavelet-based energy analysis using the proposed framework. The wavelet-based SampEn-ELM detector reaches the best performance with a sensitivity of 92.6% and a false detection rate (FDR) of 0.078. Compared with SVM, the ELM detector is better in terms of detection accuracy and learning efficiency.
Comparison with existing method(s)
The decomposition of original signals into sub-bands leads to better identification of seizure events compared with that of the existing nonlinear methods without considering the timeâfrequency decomposition.
Conclusions
The proposed framework achieves not only a high detection accuracy but also a very fast learning speed, which makes it feasible for the further development of the automatic seizure detection system.
ER  - 

TY  - JOUR
T1  - A hybrid model through the fusion of type-2 fuzzy logic systems and extreme learning machines for modelling permeability prediction
JO  - Information Fusion
VL  - 16
IS  - 
SP  - 29
EP  - 45
PY  - 2014/3//
T2  - Special Issue on Information Fusion in Hybrid Intelligent Fusion Systems
AU  - Olatunji, S.O.
AU  - Selamat, Ali
AU  - Abdulraheem, Abdulazeez
SN  - 1566-2535
DO  - https://doi.org/10.1016/j.inffus.2012.06.001
UR  - https://www.sciencedirect.com/science/article/pii/S1566253512000607
KW  - Type-2 fuzzy logic systems
KW  - Extreme learning machines (ELM)
KW  - Feedforward neural networks
KW  - Permeability
KW  - Well logs
KW  - Hybrid intelligent systems
AB  - Abstract
Extreme learning machines (ELM), as a learning tool, have gained popularity due to its unique characteristics and performance. However, the generalisation capability of ELM often depends on the nature of the dataset, particularly on whether uncertainty is present in the dataset or not. In order to reduce the effects of uncertainties in ELM prediction and improve its generalisation ability, this paper proposes a hybrid system through a combination of type-2 fuzzy logic systems (type-2 FLS) and ELM; thereafter the hybrid system was applied to model permeability of carbonate reservoir. Type-2 FLS has been chosen to be a precursor to ELM in order to better handle uncertainties existing in datasets beyond the capability of type-1 fuzzy logic systems. The type-2 FLS is used to first handle uncertainties in reservoir data so that its final output is then passed to the ELM for training and then final prediction is done using the unseen testing dataset. Comparative studies have been carried out to compare the performance of the proposed T2-ELM hybrid system with each of the constituent type-2 FLS and ELM, and also artificial neural network (ANN) and support Vector machines (SVM) using five different industrial reservoir data. Empirical results show that the proposed T2-ELM hybrid system outperformed each of type-2 FLS and ELM, as the two constituent models, in all cases, with the improvement made to the ELM performance far higher against that of type-2 FLS that had a closer performance to the hybrid since it is already noted for being able to model uncertainties. The proposed hybrid also outperformed ANN and SVM models considered.
ER  - 

TY  - JOUR
T1  - SW-ELM: A summation wavelet extreme learning machine algorithm with a priori parameter initialization
JO  - Neurocomputing
VL  - 123
IS  - 
SP  - 299
EP  - 307
PY  - 2014/1/10/
T2  - Contains Special issue articles: Advances in Pattern Recognition Applications and Methods
AU  - Javed, Kamran
AU  - Gouriveau, Rafael
AU  - Zerhouni, Noureddine
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2013.07.021
UR  - https://www.sciencedirect.com/science/article/pii/S0925231213007649
KW  - Wavelet neural network
KW  - Extreme learning machine
KW  - Parameters initialization
KW  - Activation functions
KW  - Prediction accuracy
AB  - Abstract
Combining neural networks and wavelet theory as an approximation or prediction models appears to be an effective solution in many applicative areas. However, when building such systems, one has to face parsimony problem, i.e., to look for a compromise between the complexity of the learning phase and accuracy performances. Following that, the aim of this paper is to propose a new structure of connectionist network, the Summation Wavelet Extreme Learning Machine (SW-ELM) that enables good accuracy and generalization performances, while limiting the learning time and reducing the impact of a random initialization procedure. SW-ELM is based on an Extreme Learning Machine (ELM) algorithm for fast batch learning, but with dual activation functions in the hidden layer nodes. This enhances dealing with non-linearity in an efficient manner. The initialization phase of wavelets (of hidden nodes) and neural network parameters (of input-hidden layer) is performed a priori, even before data are presented to the model. The whole proposition is illustrated and discussed by performing tests on three issues related to time-series application: an âinputâoutputâ approximation problem, a one-step ahead prediction problem, and a multi-steps ahead prediction problem. Performances of SW-ELM are benchmarked with ELM, Levenberg Marquardt algorithm for Single Layer Feed Forward Network (SLFN) and ELMAN network on six industrial datasets. Results show the significance of performances achieved by SW-ELM.
ER  - 

TY  - JOUR
T1  - A hybrid approach combining extreme learning machine and sparse representation for image classification
JO  - Engineering Applications of Artificial Intelligence
VL  - 27
IS  - 
SP  - 228
EP  - 235
PY  - 2014/1//
T2  - 
AU  - Luo, Minxia
AU  - Zhang, Kai
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2013.05.012
UR  - https://www.sciencedirect.com/science/article/pii/S0952197613000997
KW  - Extreme learning machine
KW  - Sparse representation
KW  - â    1    -  norm   minimization
KW  - Image classification
AB  - Abstract
Two well-known techniques, extreme learning machine (ELM) and sparse representation based classification (SRC) method, have attracted significant attention due to their respective performance characteristics in computer vision and pattern recognition. In general, ELM has speed advantage and SRC has accuracy advantage. However, there also remain drawbacks that limit their practical application. Actually, in the field of image classification, ELM performs extremely fast while it cannot handle noise well, whereas SRC shows notable robustness to noise while it suffers high computational cost. In order to incorporate their respective advantages and also overcome their respective drawbacks, this work proposes a novel hybrid approach combining ELM and SRC for image classification. The new approach is applied to handwritten digit classification and face recognition, experiments results demonstrate that it not only outperforms ELM in classification accuracy but also has much less computational complexity than SRC.
ER  - 

TY  - JOUR
T1  - Neural architecture design based on extreme learning machine
JO  - Neural Networks
VL  - 48
IS  - 
SP  - 19
EP  - 24
PY  - 2013/12//
T2  - 
AU  - Bueno-Crespo, AndrÃ©s
AU  - GarcÃ­a-Laencina, Pedro J.
AU  - Sancho-GÃ³mez, JosÃ©-Luis
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2013.06.010
UR  - https://www.sciencedirect.com/science/article/pii/S0893608013001810
KW  - Neural networks
KW  - Architecture design
KW  - Extreme learning machine
KW  - Multilayer perceptron
AB  - Abstract
Selection of the optimal neural architecture to solve a pattern classification problem entails to choose the relevant input units, the number of hidden neurons and its corresponding interconnection weights. This problem has been widely studied in many research works but their solutions usually involve excessive computational cost in most of the problems and they do not provide a unique solution. This paper proposes a new technique to efficiently design the MultiLayer Perceptron (MLP) architecture for classification using the Extreme Learning Machine (ELM) algorithm. The proposed method provides a high generalization capability and a unique solution for the architecture design. Moreover, the selected final network only retains those input connections that are relevant for the classification task. Experimental results show these advantages.
ER  - 

TY  - JOUR
T1  - Dynamic action recognition based on dynemes and Extreme Learning Machine
JO  - Pattern Recognition Letters
VL  - 34
IS  - 15
SP  - 1890
EP  - 1898
PY  - 2013/11/1/
T2  - Smart Approaches for Human Action Recognition
AU  - Iosifidis, Alexandros
AU  - Tefas, Anastasios
AU  - Pitas, Ioannis
SN  - 0167-8655
DO  - https://doi.org/10.1016/j.patrec.2012.10.019
UR  - https://www.sciencedirect.com/science/article/pii/S0167865512003492
KW  - Activity recognition
KW  - Dynamic classification
KW  - Fuzzy vector quantization
KW  - Extreme Learning Machine
AB  - Abstract
In this paper, we propose a novel method that performs dynamic action classification by exploiting the effectiveness of the Extreme Learning Machine (ELM) algorithm for single hidden layer feedforward neural networks training. It involves data grouping and ELM based data projection in multiple levels. Given a test action instance, a neural network is trained by using labeled action instances forming the groups that reside to the test sampleâs neighborhood. The action instances involved in this procedure are, subsequently, mapped to a new feature space, determined by the trained network outputs. This procedure is performed multiple times, which are determined by the test action instance at hand, until only a single class is retained. Experimental results denote the effectiveness of the dynamic classification approach, compared to the static one, as well as the effectiveness of the ELM in the proposed dynamic classification setting.
ER  - 

TY  - JOUR
T1  - Automatic recognition of epileptic EEG patterns via Extreme Learning Machine and multiresolution feature extraction
JO  - Expert Systems with Applications
VL  - 40
IS  - 14
SP  - 5477
EP  - 5489
PY  - 2013/10/15/
T2  - 
AU  - Song, Yuedong
AU  - Zhang, Jiaxiang
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2013.04.025
UR  - https://www.sciencedirect.com/science/article/pii/S0957417413002625
KW  - Epilepsy diagnosis
KW  - Electroencephalogram (EEG)
KW  - Multiresolution analysis
KW  - Feature extraction
KW  - Genetic algorithm (GA)
KW  - Extreme Learning Machine (ELM)
AB  - Abstract
Epilepsy is one of the most common neurological disorders- approximately one in every 100 people worldwide are suffering from it. In this paper, a novel pattern recognition model is presented for automatic epilepsy diagnosis. Wavelet transform is investigated to decompose EEG into five EEG frequency bands which approximate to delta (Î´), theta (Î¸), alpha (Î±), beta (Î²), and gamma (Î³) bands. Complexity based features such as permutation entropy (PE), sample entropy (SampEn), and the Hurst exponent (HE) are extracted from both the original EEG signals and each of the frequency bands. The wavelet-based methodology separates the alterations in PE, SampEn, and HE in specific frequency bands of the EEG. The effectiveness of these complexity based measures in discriminating between normal brain state and brain state during the absence of seizures is evaluated using the Extreme Learning Machine (ELM). It is discovered that although there exists no significant differences in the feature values extracted from the original EEG signals, differences can be recognized when the features are examined within specific EEG frequency bands. A genetic algorithm (GA) is developed to choose feature subsets that are effective for enhancing the recognition performance. The GA is also examined for weight alteration for both sensitivity and specificity. The results show that the abnormal EEG diagnosis rate of the model without the involvement of the genetic algorithm is 85.9%. However, the diagnosis rate of the model increases to 94.2% when the genetic algorithm is integrated as a feature selector.
ER  - 

TY  - JOUR
T1  - Online sequential extreme learning machine in nonstationary environments
JO  - Neurocomputing
VL  - 116
IS  - 
SP  - 94
EP  - 101
PY  - 2013/9/20/
T2  - Advanced Theory and Methodology in Intelligent ComputingSelected Papers from the Seventh International Conference on Intelligent Computing (ICIC 2011).
AU  - Ye, Yibin
AU  - Squartini, Stefano
AU  - Piazza, Francesco
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.064
UR  - https://www.sciencedirect.com/science/article/pii/S092523121200728X
KW  - Nonstationary and nonlinear system identification
KW  - Time-varying neural networks
KW  - Extreme learning machine
KW  - Online sequential learning
AB  - System identification in nonstationary environments represents a challenging problem to solve and lots of efforts have been put by the scientific community in the last decades to provide adequate solutions on purpose. Most of them are targeted to work under the system linearity assumption, but also some have been proposed to deal with the nonlinear case study. In particular the authors have recently advanced a neural architecture, namely time-varying neural networks (TV-NN), which has shown remarkable identification properties in the presence of nonlinear and nonstationary conditions. TV-NN training is an issue due to the high number of free parameters and the extreme learning machine (ELM) approach has been successfully used on purpose. ELM is a fast learning algorithm that has recently caught much attention within the neural networks (NNs) research community. Many variants of ELM have been appeared in recent literature, specially for the stationary case study. The reference one for TV-NN training is named ELM-TV and is of batch-learning type. In this contribution an online sequential version of ELM-TV is developed, in response to the need of dealing with applications where sequential arrival or large number of training data occurs. This algorithm generalizes the corresponding counterpart working under stationary conditions. Its performances have been evaluated in some nonstationary and nonlinear system identification tasks and related results show that the advanced technique produces comparable generalization performances to ELM-TV, ensuring at the same time all benefits of an online sequential approach.
ER  - 

TY  - JOUR
T1  - An improved evolutionary extreme learning machine based on particle swarm optimization
JO  - Neurocomputing
VL  - 116
IS  - 
SP  - 87
EP  - 93
PY  - 2013/9/20/
T2  - Advanced Theory and Methodology in Intelligent ComputingSelected Papers from the Seventh International Conference on Intelligent Computing (ICIC 2011).
AU  - Han, Fei
AU  - Yao, Hai-Fen
AU  - Ling, Qing-Hua
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.062
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212007205
KW  - Extreme learning machine
KW  - Particle swarm optimization
KW  - Generalization performance
KW  - Convergence rate
AB  - Recently Extreme Learning Machine (ELM) for single-hidden-layer feedforward neural networks (SLFN) has been attracting attentions for its faster learning speed and better generalization performance than those of traditional gradient-based learning algorithms. However, ELM may need high number of hidden neurons and lead to ill-condition problem due to the random determination of the input weights and hidden biases. In this paper, a hybrid learning algorithm is proposed to overcome the drawbacks of ELM, which uses an improved particle swarm optimization (PSO) algorithm to select the input weights and hidden biases and MooreâPenrose (MP) generalized inverse to analytically determine the output weights. In order to obtain optimal SLFN, the improved PSO optimizes the input weights and hidden biases according to not only the root mean squared error (RMSE) on validation set but also the norm of the output weights. The proposed algorithm has better generalization performance than traditional ELM and other evolutionary ELMs, and the conditioning of the SLFN trained by the proposed algorithm is also improved. Experiment results have verified the efficiency and effectiveness of the proposed method.
ER  - 

TY  - JOUR
T1  - A hybrid decision support system based on rough set and extreme learning machine for diagnosis of hepatitis disease
JO  - Applied Soft Computing
VL  - 13
IS  - 8
SP  - 3429
EP  - 3438
PY  - 2013/8//
T2  - 
AU  - Kaya, YÄ±lmaz
AU  - Uyar, Murat
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2013.03.008
UR  - https://www.sciencedirect.com/science/article/pii/S1568494613001130
KW  - Hepatitis disease
KW  - Rough set
KW  - Dimensionality reduction
KW  - Extreme learning machine
AB  - Abstract
Hepatitis is a disease which is seen at all levels of age. Hepatitis disease solely does not have a lethal effect, but the early diagnosis and treatment of hepatitis is crucial as it triggers other diseases. In this study, a new hybrid medical decision support system based on rough set (RS) and extreme learning machine (ELM) has been proposed for the diagnosis of hepatitis disease. RS-ELM consists of two stages. In the first one, redundant features have been removed from the data set through RS approach. In the second one, classification process has been implemented through ELM by using remaining features. Hepatitis data set, taken from UCI machine learning repository has been used to test the proposed hybrid model. A major part of the data set (48.3%) includes missing values. As removal of missing values from the data set leads to data loss, feature selection has been done in the first stage without deleting missing values. In the second stage, the classification process has been performed through ELM after the removal of missing values from sub-featured data sets that were reduced in different dimensions. The results showed that the highest 100.00% classification accuracy has been achieved through RS-ELM and it has been observed that RS-ELM model has been considerably successful compared to the other methods in the literature. Furthermore in this study, the most significant features have been determined for the diagnosis of the hepatitis. It is considered that proposed method is to be useful in similar medical applications.
ER  - 

TY  - JOUR
T1  - A new method for expert target recognition system: Genetic wavelet extreme learning machine (GAWELM)
JO  - Expert Systems with Applications
VL  - 40
IS  - 10
SP  - 3984
EP  - 3993
PY  - 2013/8//
T2  - 
AU  - Avci, Engin
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2013.01.011
UR  - https://www.sciencedirect.com/science/article/pii/S0957417413000146
KW  - Radar target echo signal
KW  - Discrete wavelet transform
KW  - Entropy
KW  - Genetic algorithm
KW  - Extreme learning machine classifier
AB  - In last yearâs, the expert target recognition has been become very important topic in radar literature. In this study, a target recognition system is introduced for expert target recognition (ATR) using radar target echo signals of High Range Resolution (HRR) radars. This study includes a combination of an adaptive feature extraction and classification using optimum wavelet entropy parameter values. The features used in this study are extracted from radar target echo signals. Herein, a genetic wavelet extreme learning machine classifier model (GAWELM) is developed for expert target recognition. The GAWELM composes of three stages. These stages of GAWELM are genetic algorithm, wavelet analysis and extreme learning machine (ELM) classifier. In previous studies of radar target recognition have shown that the learning speed of feedforward networks is in general much slower than required and it has been a major disadvantage. There are two important causes. These are: (1) the slow gradient-based learning algorithms are commonly used to train neural networks, and (2) all the parameters of the networks are fixed iteratively by using such learning algorithms. In this paper, a new learning algorithm named extreme learning machine (ELM) for single-hidden layer feedforward networks (SLFNs) Ahern, Delisle, et al., 1989; Al-Otum &amp; Al-Sowayan, 2011; Avci, Turkoglu, &amp; Poyraz, 2005a, 2005b; Biswal, Dash, &amp; Panigrahi, 2009; Frigui et al., in press; Cao, Lin, &amp; Huang, 2010; Guo, Rivero, Dorado, Munteanu, &amp; Pazos, 2011; Famili, Shen, Weber, &amp; Simoudis, 1997; Han &amp; Huang, 2006; Huang, Cai, Chen, &amp; Liu, 2011; Huang, Chen, &amp; Siew, 2006; Huang &amp; Siew, 2005; Huang, Liu, Gao, &amp; Guo, 2009; Jiang, Liu, Li, &amp; Tang, 2011; Kubrusly &amp; Levan, 2009; Le, Tamura, &amp; Matsumoto, 2011; Lhermitte et al., 2011; MartÃ­nez-MartÃ­nez et al., 2011; Matlab, 2011; Nelson, Starzyk, &amp; Ensley, 2002; Nejad &amp; Zakeri, 2011; Tabib, Sathe, Deshpande, &amp; Joshi, 2009; Tang, Sun, Tang, Zhou, &amp; Wei, 2011, which randomly choose hidden nodes and analytically determines the output weights of SLFNs, to eliminate the these disadvantages of feedforward networks for expert target recognition area. Then, the genetic algorithm (GA) stage is used for obtaining the feature extraction method and finding the optimum wavelet entropy parameter values. Herein, the optimal one of four variant feature extraction methods is obtained by using a genetic algorithm (GA). The four feature extraction methods proposed GAWELM model are discrete wavelet transform (DWT), discrete wavelet transformâshort-time Fourier transform (DWTâSTFT), discrete wavelet transformâBornâJordan timeâfrequency transform (DWTâBJTFT), and discrete wavelet transformâChoiâWilliams timeâfrequency transform (DWTâCWTFT). The discrete wavelet transform stage is performed for optimum feature extraction in the timeâfrequency domain. The discrete wavelet transform stage includes discrete wavelet transform and calculating of discrete wavelet entropies. The extreme learning machine (ELM) classifier is performed for evaluating the fitness function of the genetic algorithm and classification of radar targets. The performance of the developed GAWELM expert radar target recognition system is examined by using noisy real radar target echo signals. The applications results of the developed GAWELM expert radar target recognition system show that this GAWELM system is effective in rating real radar target echo signals. The correct classification rate of this GAWELM system is about 90% for radar target types used in this study.
ER  - 

TY  - JOUR
T1  - Advances in Extreme Learning Machines (ELM2011)
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 1
EP  - 2
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Huang, Guang-Bin
AU  - Wang, Dianhui
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.04.029
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212005954
ER  - 

TY  - JOUR
T1  - Extreme learning machine based genetic algorithm and its application in power system economic dispatch
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 154
EP  - 162
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Yang, Hongming
AU  - Yi, Jun
AU  - Zhao, Junhua
AU  - Dong, ZhaoYang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.054
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004456
KW  - Extreme learning machine
KW  - Genetic algorithm
KW  - Power system economic dispatch
AB  - In this paper a novel optimization algorithm, which utilizes the key ideas of both genetic algorithm (GA) and extreme learning machine (ELM), is proposed. Traditional genetic algorithm employs genetic operations, such as selection, mutation and crossover to generate the optimal solution. In practice, the child solutions generated by crossover and mutation are largely random and therefore cannot ensure the fast convergence of the algorithm. To tackle the weakness of traditional GA, the ELM is introduced to estimate the nonlinear functional relationships between the parent population and child population generated by genetic operations. The trained downward-climbing and upward-climbing ELMs are then employed to generate candidate solutions, which forms the new population together with the solutions given by genetic operations. The proposed algorithm is applied to the power system economic dispatch problem. As demonstrated in case studies, the modified genetic algorithm is able to locate local minima faster and escape from local minima with a greater probability. The proposed algorithm can therefore ensure the faster convergence and provide more economical dispatch plans.
ER  - 

TY  - JOUR
T1  - Silicon spiking neurons for hardware implementation of extreme learning machines
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 125
EP  - 134
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Basu, Arindam
AU  - Shuo, Sun
AU  - Zhou, Hongming
AU  - Hiot Lim, Meng
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.01.042
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212005814
KW  - Spiking neural network
KW  - Extreme learning machine
KW  - Asynchronous communication
KW  - Silicon neuron
KW  - Neuromorphic
AB  - In this paper, we propose a silicon implementation of extreme learning machines (ELM) using spiking neural circuits. The major components of a silicon spiking neural network, neuron, synapse and âAddress Event Representationâ (AER) for asynchronous spike based communication, are described. The benefits of using this hardware to implement an ELM as opposed to other single layer feedforward networks (SLFN) are explained. Several possible architectures for efficient implementation of ELM using these circuits are presented and their possible impact on ELM performance is discussed.
ER  - 

TY  - JOUR
T1  - Feature selection for nonlinear models with extreme learning machines
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 111
EP  - 124
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - BenoÃ®t, FrÃ©nay
AU  - van Heeswijk, Mark
AU  - Miche, Yoan
AU  - Verleysen, Michel
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.055
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004468
KW  - Extreme learning machines
KW  - Regression
KW  - Feature selection
KW  - Regularisation
AB  - In the context of feature selection, there is a trade-off between the number of selected features and the generalisation error. Two plots may help to summarise feature selection: the feature selection path and the sparsity-error trade-off curve. The feature selection path shows the best feature subset for each subset size, whereas the sparsity-error trade-off curve shows the corresponding generalisation errors. These graphical tools may help experts to choose suitable feature subsets and extract useful domain knowledge. In order to obtain these tools, extreme learning machines are used here, since they are fast to train and an estimate of their generalisation error can easily be obtained using the PRESS statistics. An algorithm is introduced, which adds an additional layer to standard extreme learning machines in order to optimise the subset of selected features. Experimental results illustrate the quality of the presented method.
ER  - 

TY  - JOUR
T1  - Partitioned online sequential extreme learning machine for large ordered system modeling
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 59
EP  - 64
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Lim, JunSeok
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.049
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004237
KW  - Extreme learning machine
KW  - OS-ELM
KW  - RLS
KW  - Partitioning
AB  - In this paper, we propose an algorithm entitled âpartitioned OS-ELMâ (POS-ELM) that partitions a large data matrix into small matrices, applies an RLS (Recursive Least Square) scheme in each of the small sub-matrices and assembles the whole estimation vector by the concatenation of the sub-vectors from the RLS outputs of the sub-matrices. Consequently, the algorithm is less complex than the conventional OS-ELM and maintains an almost compatible estimation performance.
ER  - 

TY  - JOUR
T1  - Architecture selection for networks trained with extreme learning machine using localized generalization error model
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 3
EP  - 9
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Xi-zhao, Wang
AU  - Qing-yan, Shao
AU  - Qing, Miao
AU  - Jun-hai, Zhai
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.053
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004328
KW  - Localized generalization error
KW  - Extreme learning machine
KW  - Network architecture selection
KW  - Cross validation (CV)
KW  - Sensitivity measure
AB  - The initial localized generalization error model (LGEM) aims to find an upper bound of error between a target function and a radial basis function neural network (RBFNN) within a neighborhood of the training samples. The contribution of LGEM can be briefly described as that the generalization error is less than or equal to the summation of three terms: training error, stochastic sensitivity measure (SSM), and a constant. This paper extends the initial LGEM to a new LGEM model for single-hidden layer feed-forward neural networks (SLFNs) trained with extreme learning machine (ELM) which is a type of new training algorithms without iterations. The development of this extended LGEM can provide some useful guidelines for improving the generalization ability of SLFNs trained with ELM. An algorithm for architecture selection of the SLFNs is also proposed based on the extended LGEM. Experimental results on a number of benchmark data sets show that an approximately optimal architecture in terms of number of neurons of a SLFN can be found using our method. Furthermore, the experimental results on eleven UCI data sets show that the proposed method is effective and efficient.
ER  - 

TY  - JOUR
T1  - Image classification based on effective extreme learning machine
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 90
EP  - 97
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Cao, Feilong
AU  - Liu, Bo
AU  - Sun Park, Dong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.02.042
UR  - https://www.sciencedirect.com/science/article/pii/S092523121200433X
KW  - Image classification
KW  - Curvelet transform
KW  - Discriminative locality alignment
KW  - Extreme k-means
KW  - Effective extreme learning machine
AB  - In this work, a new image classification method is proposed based on extreme k-means (EKM) and effective extreme learning machine (EELM). The proposed method has image decomposition with curvelet transform, reduces dimensionality with discriminative locality alignment (DLA), generates a set of distinctive features with EKM, and has a classification with EELM. Since EKM has a better clustering performance than k-means and EELM has a better accuracy than ELM, the proposed EKM-EELM algorithm has a significant improvement in classification rate. Extensive experiments are performed using challenging databases and results are compared against state of the art techniques. Experimental results show that the proposed method has superior performances on classification rate than some other traditional methods for image classification.
ER  - 

TY  - JOUR
T1  - Optimizing extreme learning machines via ridge regression and batch intrinsic plasticity
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 23
EP  - 30
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Neumann, Klaus
AU  - Steil, Jochen J.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.01.041
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212005619
KW  - Neural network
KW  - Learning
KW  - Extreme learning machine
KW  - Batch intrinsic plasticity
KW  - Ridge regression
KW  - Regularization
AB  - Extreme learning machines are randomly initialized single-hidden layer feed-forward neural networks where the training is restricted to the output weights in order to achieve fast learning with good performance. This contribution shows how batch intrinsic plasticity, a novel and efficient scheme for input specific tuning of non-linear transfer functions, and ridge regression can be combined to optimize extreme learning machines without searching for a suitable hidden layer size. We show that our scheme achieves excellent performance on a number of standard regression tasks and regression applications from robotics.
ER  - 

TY  - JOUR
T1  - A novel automatic two-stage locally regularized classifier construction method using the extreme learning machine
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 10
EP  - 22
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Du, Dajun
AU  - Li, Kang
AU  - Irwin, George W.
AU  - Deng, Jing
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.052
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004262
KW  - Classification
KW  - Extreme learning machine
KW  - Leave-one-out (LOO) misclassification rate
KW  - Linear-in-the-parameters model
KW  - Regularization
KW  - Two-stage stepwise selection
AB  - This paper investigates the design of a linear-in-the-parameters (LITP) regression classifier for two-class problems. Most existing algorithms generally learn a classifier (model) from the available training data based on some stopping criterions, such as the Akaike's final prediction error (FPE). The drawback here is that the classifier obtained is then not directly obtained based on its generalization capability. The main objective of this paper is to improve the sparsity and generalization capability of a classifier, while reducing the computational expense in producing it. This is achieved by proposing an automatic two-stage locally regularized classifier construction (TSLRCC) method using the extreme learning machine (ELM). In this new algorithm, the nonlinear parameters in each term, such as the width of the Gaussian function and the power of a polynomial term, are firstly determined by the ELM. An initial classifier is then generated by the direct evaluation of these candidates models according to the leave-one-out (LOO) misclassification rate in the first stage. The significance of each selected regressor term is also checked and insignificant ones are replaced in the second stage. To reduce the computational complexity, a proper regression context is defined which allows fast implementation of the proposed method. Simulation results confirm the effectiveness of the proposed technique.
ER  - 

TY  - JOUR
T1  - Parallel extreme learning machine for regression based on MapReduce
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 52
EP  - 58
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - He, Qing
AU  - Shang, Tianfeng
AU  - Zhuang, Fuzhen
AU  - Shi, Zhongzhi
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.01.040
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004213
KW  - Data mining
KW  - Regression
KW  - ELM
KW  - MapReduce
KW  - PELM
AB  - Regression is one of the most basic problems in data mining. For regression problem, extreme learning machine (ELM) can get better generalization performance at a much faster learning speed. However, the enlarging volume of datasets makes regression by ELM on very large scale datasets a challenging task. Through analyzing the mechanism of ELM algorithm, an efficient parallel ELM for regression is designed and implemented based on MapReduce framework, which is a simple but powerful parallel programming technique currently. The experimental results demonstrate that the proposed parallel ELM for regression can efficiently handle very large datasets on commodity hardware with a good performance on different evaluation criterions, including speedup, scaleup and sizeup.
ER  - 

TY  - JOUR
T1  - EEG-based vigilance estimation using extreme learning machines
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 135
EP  - 143
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Shi, Li-Chen
AU  - Lu, Bao-Liang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.02.041
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004183
KW  - Extreme learning machine
KW  - L2 norm penalty
KW  - L1 norm penalty
KW  - EEG
KW  - Vigilance estimation
AB  - For many human machine interaction systems, techniques for continuously estimating the vigilance of operators are highly desirable to ensure work safety. Up to now, various signals are studied for vigilance analysis. Among them, electroencephalogram (EEG) is the most commonly used signal. In this paper, extreme learning machine (ELM) and its modifications with L1 norm and L2 norm penalties are adopted for EEG-based vigilance estimation. A comparative study on system performance is conducted among ordinary ELM, its modifications, and support vector machines (SVMs). Experimental results show that, compared with SVMs, the ordinary ELM and its modifications can all dramatically speed up the training process while still achieving similar or better vigilance estimation accuracy. In addition, the following three observations have been made from the experiment results: (a) the ordinary ELM and the ELM with L1 norm penalty (LARS-ELM) are sensitive on the number of hidden nodes; (b) the ELM with L2 norm penalty (regularized-ELM) and the ELMs with both L1 norm and L2 norm penalties (LARS-EN-ELM, TROP-ELM) are stable and insensitive on the number of hidden nodes; and (c) regularized-ELM has a much faster training speed, while LARS-EN-ELM can achieve better vigilance estimation accuracy.
ER  - 

TY  - JOUR
T1  - Evolutionary extreme learning machine ensembles with size control
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 98
EP  - 110
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Wang, Dianhui
AU  - Alhamdoosh, Monther
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.046
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004195
KW  - Learner model ensembles
KW  - Extreme learning machines
KW  - Evolutionary computation
KW  - Generalization capability
KW  - Robustness
AB  - Ensemble learning aims to improve the generalization power and the reliability of learner models through sampling and optimization techniques. It has been shown that an ensemble constructed by a selective collection of base learners outperforms favorably. However, effective implementation of such an ensemble from a given learner pool is still an open problem. This paper presents an evolutionary approach for constituting extreme learning machine (ELM) ensembles. Our proposed algorithm employs the model diversity as fitness function to direct the selection of base learners, and produces an optimal solution with ensemble size control. A comprehensive comparison is carried out, where the basic ELM is used to generate a set of neural networks and 12 benchmarked regression datasets are employed in simulations. Our reporting results demonstrate that the proposed method outperforms other ensembling techniques, including simple average, bagging and adaboost, in terms of both effectiveness and efficiency.
ER  - 

TY  - JOUR
T1  - Extreme learning machine based wind speed estimation and sensorless control for wind turbine power generation system
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 163
EP  - 175
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Wu, Si
AU  - Wang, Youyi
AU  - Cheng, Shijie
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.051
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004250
KW  - Wind speed estimation
KW  - Sensorless control
KW  - Wind turbine power generation system
KW  - Extreme learning machine
AB  - This paper proposes a precise real-time wind speed estimation method and sensorless control for variable-speed variable-pitch wind turbine power generation system (WTPGS). The wind speed estimation is realized by a nonlinear inputâoutput mapping extreme learning machine (ELM). A specific design characteristic of the wind turbine is used for improving the mapping accuracy with considering the variable pitch angle. Moreover, since the design is independent of the environmental air density, the proposed ELM wind speed estimation method is robust to the air density variations. The estimated wind speed is then used to determine the optimal rotational speed command for maximum power point tracking. A fast and effective ELM mapping based pitch controller is proposed too when the WTPGS operates in its high wind speed region. The ELM pitch controller can act much faster and more precise than conventional pitch controllers. Furthermore, the complicated design precess for the parameters of conventional pitch controllers will be avoided in the proposed method. The effectiveness of the proposed methods are verified both by simulations and experiments on a WTPGS installed with Permanent Magnet Synchronous Generator (PMSG).
ER  - 

TY  - JOUR
T1  - Semantic concept detection for video based on extreme learning machine
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 176
EP  - 183
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Lu, Bo
AU  - Wang, Guoren
AU  - Yuan, Ye
AU  - Han, Dong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.02.043
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004341
KW  - Extreme learning machine
KW  - ELM classifier
KW  - ELM-OAA classifier
KW  - Multi-modality
KW  - Probability-based fusion
KW  - Semantic concept detection
KW  - Contextual correlation
KW  - Single hidden layer feedforward networks
AB  - Semantic concept detection is an important step in concept-based semantic video retrieval, which can be regarded as an intermediate descriptor to bridge the semantic gap. Most existing concept detection methods utilize Support Vector Machines (SVM) as concept classifier. However, there are several drawbacks of using SVM, such as the high computational cost and large number of parameters to be optimized. In this paper we propose an Extreme Learning Machine (ELM) based Multi-modality Classifier Combination Framework (MCCF) to improve the accuracy of semantic concept detection. In this framework: (i) three ELM classifiers are trained by exploring three kinds of visual features respectively, (ii) a probability-based fusion method is then proposed to combine the prediction results of each ELM classifier, (iii) we integrate the prediction results of ELM classifier with the information of contextual correlation among concepts to further improve the accuracy of semantic concept detection. Experiments on the widely used TRECVID datasets demonstrate that our approach can effectively improve the accuracy of semantic concept detection and achieve performance at extremely high speed.
ER  - 

TY  - JOUR
T1  - Regularized extreme learning machine for regression with missing data
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 45
EP  - 51
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Yu, Qi
AU  - Miche, Yoan
AU  - Eirola, Emil
AU  - van Heeswijk, Mark
AU  - SÃ©verin, Eric
AU  - Lendasse, Amaury
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.02.040
UR  - https://www.sciencedirect.com/science/article/pii/S092523121200416X
KW  - ELM
KW  - Ridge regression
KW  - Tikhonov regularization
KW  - LARS
KW  - Missing data
KW  - Pairwise distance estimation
AB  - This paper proposes a method which is the advanced modification of the original extreme learning machine with a new tool for solving the missing data problem. It uses a cascade of L1 penalty (LARS) and L2 penalty (Tikhonov regularization) on ELM (TROP-ELM) to regularize the matrix computations and hence makes the MSE computation more reliable, and on the other hand, it estimates the expected pairwise distances between samples directly on incomplete data so that it offers the ELM a solution to solve the missing data issues. According to the experiments on five data sets, the method shows its significant advantages: fast computational speed, no parameter need to be tuned and it appears more stable and reliable generalization performance by the two penalties. Moreover, it completes ELM with a new tool to solve missing data problem even when half of the training data are missing as the extreme case.
ER  - 

TY  - JOUR
T1  - Robust extreme learning machine
JO  - Neurocomputing
VL  - 102
IS  - 
SP  - 31
EP  - 44
PY  - 2013/2/15/
T2  - Advances in Extreme Learning Machines (ELM 2011)
AU  - Horata, Punyaphol
AU  - Chiewchanwattana, Sirapat
AU  - Sunat, Khamron
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.12.045
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212004171
KW  - Extreme learning machine
KW  - MooreâPenrose pseudo inverse
KW  - Singular Value Decomposition
KW  - Extended Complete Orthogonal Decomposition
KW  - Iteratively reweighted least squares
KW  - Multivariate least-trimmed squares
KW  - Minimax probability machine regression
KW  - Meta-metrics evaluation
KW  - Outlier
KW  - Robustness
AB  - The output weights computing of extreme learning machine (ELM) encounters two problems, the computational and outlier robustness problems. The computational problem occurs when the hidden layer output matrix is a not full column rank matrix or an ill-conditioned matrix because of randomly generated input weights and biases. An existing solution to this problem is Singular Value Decomposition (SVD) method. However, the training speed is still affected by the large complexity of SVD when computing the MooreâPenrose (MP) pseudo inverse. The outlier robustness problem may occur when the training data set contaminated with outliers then the accuracy rate of ELM is extremely affected. This paper proposes the Extended Complete Orthogonal Decomposition (ECOD) method to solve the computational problem in ELM weights computing via ECODLS algorithm. And the paper also proposes the other three algorithms, i.e. the iteratively reweighted least squares (IRWLS-ELM), ELM based on the multivariate least-trimmed squares (MLTS-ELM), and ELM based on the one-step reweighted MLTS (RMLTS-ELM) to solve the outlier robustness problem. However, they also encounter the computational problem. Therefore, the ECOD via ECODLS algorithm is also used successfully in the three proposed algorithms. The experiments of regression problems were conducted on both toy and real-world data sets. The outlier types are one-sided and two-sided outliers. Each experiment was randomly contaminated with outliers, of one type only, with 10%, 20%, 30%, 40%, and 50% of the total training data size. Meta-metrics evaluation was used to measure the outlier robustness of the proposed algorithms compared to the existing algorithms, i.e. the minimax probability machine regression (MPMR) and the ordinary ELM. The experimental results showed that ECOD can effectively replace SVD. The ECOD is robust to the not full column rank or the ill-conditional problem. The speed of the ELM training using ECOD is also faster than the ordinary training algorithm. Moreover, the meta-metrics measure showed that the proposed algorithms are less affected by the increasing number of outliers than the existing algorithms.
ER  - 

TY  - JOUR
T1  - Weighted extreme learning machine for imbalance learning
JO  - Neurocomputing
VL  - 101
IS  - 
SP  - 229
EP  - 242
PY  - 2013/2/4/
T2  - 
AU  - Zong, Weiwei
AU  - Huang, Guang-Bin
AU  - Chen, Yiqiang
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.08.010
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212006479
KW  - Extreme learning machine
KW  - Imbalanced learning
KW  - Single hidden layer feedforward networks
KW  - Weighted extreme learning machine
AB  - Extreme learning machine (ELM) is a competitive machine learning technique, which is simple in theory and fast in implementation. The network types are âgeneralizedâ single hidden layer feedforward networks, which are quite diversified in the form of variety in feature mapping functions or kernels. To deal with data with imbalanced class distribution, a weighted ELM is proposed which is able to generalize to balanced data. The proposed method maintains the advantages from original ELM: (1) it is simple in theory and convenient in implementation; (2) a wide type of feature mapping functions or kernels are available for the proposed framework; (3) the proposed method can be applied directly into multiclass classification tasks. In addition, after integrating with the weighting scheme, (1) the weighted ELM is able to deal with data with imbalanced class distribution while maintain the good performance on well balanced data as unweighted ELM; (2) by assigning different weights for each example according to users' needs, the weighted ELM can be generalized to cost sensitive learning.
ER  - 

TY  - JOUR
T1  - Reservoir computing and extreme learning machines for non-linear time-series data analysis
JO  - Neural Networks
VL  - 38
IS  - 
SP  - 76
EP  - 89
PY  - 2013/2//
T2  - 
AU  - Butcher, J.B.
AU  - Verstraeten, D.
AU  - Schrauwen, B.
AU  - Day, C.R.
AU  - Haycock, P.W.
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2012.11.011
UR  - https://www.sciencedirect.com/science/article/pii/S0893608012003085
KW  - Reservoir computing
KW  - Extreme learning machine
KW  - Reservoir with random static projections
KW  - Non-linearity
KW  - Short-term memory
KW  - Time-series data
AB  - Random projection architectures such as Echo state networks (ESNs) and Extreme Learning Machines (ELMs) use a network containing a randomly connected hidden layer and train only the output weights, overcoming the problems associated with the complex and computationally demanding training algorithms traditionally used to train neural networks, particularly recurrent neural networks. In this study an ESN is shown to contain an antagonistic trade-off between the amount of non-linear mapping and short-term memory it can exhibit when applied to time-series data which are highly non-linear. To overcome this trade-off a new architecture, Reservoir with Random Static Projections (R2SP) is investigated, that is shown to offer a significant improvement in performance. A similar approach using an ELM whose input is presented through a time delay (TD-ELM) is shown to further enhance performance where it significantly outperformed the ESN and R2SP as well other architectures when applied to a novel task which allows the short-term memory and non-linearity to be varied. The hard-limiting memory of the TD-ELM appears to be best suited for the data investigated in this study, although ESN-based approaches may offer improved performance when processing data which require a longer fading memory.
ER  - 

TY  - JOUR
T1  - Multiple extreme learning machines for a two-class imbalance corporate life cycle prediction
JO  - Knowledge-Based Systems
VL  - 39
IS  - 
SP  - 214
EP  - 223
PY  - 2013/2//
T2  - 
AU  - Lin, Sin-Jin
AU  - Chang, Chingho
AU  - Hsu, Ming-Fu
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2012.11.003
UR  - https://www.sciencedirect.com/science/article/pii/S0950705112003127
KW  - Ensemble learning
KW  - Extreme learning machine
KW  - Imbalanced dataset
KW  - Corporate life cycle
KW  - Knowledge generation
AB  - Pre-warning of whether a corporate will fall into a decline stage in the near future is an emerging issue in financial management. Improper decision-making by firms incurs a higher possibility to cause financial crisis (distress) and deteriorates the soundness of financial markets. The aim of this study is to establish a novel prediction mechanism based on combining the sampling technique (synthetic minority over-sampling technique; SMOTE), feature selection ensemble (original, intersection, and union), extreme learning machine (ELM) ensemble and decision tree (DT). The proposed model â namely, the multiple extreme learning machines (MELMs) â shows promising performance under numerous assessing criteria, but one critical defect of the ensemble classifier is that it lacks comprehensibility. Thus, we perform a DT as the knowledge generator to extract the inherent information from the ensemble mechanism. This knowledge visualized process can assist decision makers in efficiently allocating limited financial resources and to help firms survive in an extremely competitive environment.
ER  - 

TY  - JOUR
T1  - A lossless copyright authentication scheme based on BesselâFourier moment and extreme learning machine in curvature-feature domain
JO  - Journal of Systems and Software
VL  - 86
IS  - 1
SP  - 222
EP  - 232
PY  - 2013/1//
T2  - 
AU  - Gao, Guangyong
AU  - Jiang, Guoping
SN  - 0164-1212
DO  - https://doi.org/10.1016/j.jss.2012.07.070
UR  - https://www.sciencedirect.com/science/article/pii/S0164121212002270
KW  - Multiple zero-watermarking
KW  - Copyright authentication
KW  - BesselâFourier moment
KW  - Extreme learning machine (ELM)
KW  - Curvature feature
AB  - To overcome some drawbacks existing in current zero-watermarking methods, a lossless copyright authentication scheme is proposed in this paper. This scheme designs a multiple zero-watermarking algorithm based on BesselâFourier moment and extreme learning machine (ELM) in curvature-feature domain, develops a method for image feature enhancement and noise suppression in curvature-feature domain, and presents a simple algorithm which uses BesselâFourier moment phase to estimate the rotation angle of the rotation-attacked image. The experimental results, involving five types of images, indicate the proposed scheme has better overall performance compared to other five current methods, especially in the aspects of resisting high ratio cropping and large angle rotation attacks. Finally, some related factors including phase and magnitude components, feature vector dimension and ELM optimization are considered in the algorithm performance evaluation.
ER  - 

TY  - JOUR
T1  - Mobility Prediction in Mobile Ad Hoc Networks Using Extreme Learning Machines
JO  - Procedia Computer Science
VL  - 19
IS  - 
SP  - 305
EP  - 312
PY  - 2013///
T2  - The 4th International Conference on Ambient Systems, Networks and Technologies (ANT 2013), the 3rd International Conference on Sustainable Energy Information Technology (SEIT-2013)
AU  - Ghouti, Lahouari
AU  - Sheltami, Tarek R.
AU  - Alutaibi, Khaled S.
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2013.06.043
UR  - https://www.sciencedirect.com/science/article/pii/S1877050913006510
KW  - Mobile Ad Hoc Networks (MANETs)
KW  - Mobility Prediction
KW  - Extreme Learning Machines (ELMs)
AB  - Recent advances in wireless technology and computing have paved the way to the unprecedented rapid growth in de- mand and availability of mobile networking and services coupled with diverse system/network applications. Such advances triggered the emergence of future generation wireless networks and services to address the increasingly strin- gent requirements of quality-of-service (QoS) at various levels. The expected growth in wireless network activity and the number of wireless users will enable similar growth in bandwidth-crunching wireless applications to meet the QoS requirements. Mobility prediction of wireless users and units plays a major role in efficient planning and manage- ment of the bandwidth resources available in wireless networks. In return, this efficiency will allow better planning and improved overall QoS in terms of continuous service availability and efficient power management. In this paper, we propose extreme learning machines (ELMs), known for universal approximation, to model and predict mobility of arbitrary nodes in a mobile ad hoc network (MANET). MANETs use mobility prediction in location-aided routing and mobility aware topology control protocols. In these protocols, each mobile node is assumed to know its current mobility information (position, speed and movement direction angle). In this way, future node positions are predicted along with future distances between neighboring nodes. Unlike multilayer perceptrons (MLPs), ELMs capture better the existing interaction/correlation between the cartesian coordinates of the arbitrary nodes leading to more realistic and accurate mobility prediction based on several standard mobility models. Simulation results using standard mobility models illustrate how the proposed prediction method can lead to a significant improvement over conventional methods based on MLPs. Moreover, the proposed solution circumvents the prediction accuracy limitations in current algorithms when predicting future distances between neighboring nodes. The latter prediction is required by some applications like mobility aware topology control protocols.
ER  - 

TY  - JOUR
T1  - Fashion retailing forecasting based on extreme learning machine with adaptive metrics of inputs
JO  - Knowledge-Based Systems
VL  - 36
IS  - 
SP  - 253
EP  - 259
PY  - 2012/12//
T2  - 
AU  - Xia, Min
AU  - Zhang, Yingchao
AU  - Weng, Liguo
AU  - Ye, Xiaoling
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2012.07.002
UR  - https://www.sciencedirect.com/science/article/pii/S0950705112001906
KW  - Extreme learning machine
KW  - Fashion retailing
KW  - Forecasting
KW  - Adaptive metrics
KW  - Neural network
AB  - In the fashion retail industry, a versatile sales forecasting system is crucial for fashion retailers. In order to avoid stock-out and maintain a high inventory fill rate, fashion retailers require specific and accurate sales forecasting systems. In this study, a hybrid method based on extreme learning machine model with the adaptive metrics of inputs is proposed for improving sales forecasting accuracy. The adaptive metrics of inputs can solve the problems of amplitude changing and trend determination, and reduce the effect of the overfitting of networks. The proposed algorithms are validated using real POS data of three fashion retailers selling high-ended, medium and basic fashion items in Hong Kong. It was found that the proposed model is practical for fashion retail sales forecasting and outperforms the auto-regression (AR), artificial neural network (ANN), and extreme learning machine (ELM) models.
ER  - 

TY  - JOUR
T1  - A new automatic target recognition system based on wavelet extreme learning machine
JO  - Expert Systems with Applications
VL  - 39
IS  - 16
SP  - 12340
EP  - 12348
PY  - 2012/11/15/
T2  - 
AU  - Avci, Engin
AU  - Coteli, Resul
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2012.04.012
UR  - https://www.sciencedirect.com/science/article/pii/S0957417412006094
KW  - Extreme learning machine
KW  - Radar target echo signal
KW  - Feature extraction
KW  - Wavelet decomposition
KW  - Automatic radar target recognition systems
AB  - In this paper, an automatic system is presented for target recognition using target echo signals of High Resolution Range (HRR) radars. This paper especially deals with combination of the feature extraction and classification from measured real target echo signal waveforms by using X-band pulse radar. The past studies in the field of radar target recognition have shown that the learning speed of feedforward neural networks is in general much slower than required and it has been a major disadvantage. There are two key reasons forth is status of feedforward neural networks: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms (Feng, Huang, Lin, &amp; Gay, 2009; Huang &amp; Siew, 2004, 2005; Huang &amp; Chen, 2007, 2008; Huang, Chen, &amp; Siew, 2006; Huang, Ding, &amp; Zhou, 2010; Huang, Zhu, &amp; Siew, 2004; Huang, Liang, Rong, Saratchandran, &amp; Sundararajan, 2005; Huang, Zhou, Ding, &amp; Zhang, 2012; Huang, Li, Chen, &amp; Siew, 2008; Huang, Wang, &amp; Lan, 2011; Huang et al., 2006; Huang, Zhu, &amp; Siew, 2006a, 2006b; Lan, Soh, &amp; Huang, 2009; Li, Huang, Saratchandran, &amp; Sundararajan, 2005; Liang, Huang, Saratchandran, &amp; Sundararajan, 2006; Liang, Saratchandran, Huang, &amp; Sundararajan, 2006; Rong, Huang, Saratchandran, &amp; Sundararajan, 2009; Wang &amp; Huang, 2005; Wang, Cao, &amp; Yuan, 2011; Yeu, Lim, Huang, Agarwal, &amp; Ong, 2006; Zhang, Huang, Sundararajan, &amp; Saratchandran, 2007; Zhu, Qin, Suganthan, &amp; Huang, 2005). To resolve these disadvantages of feedforward neural networks for automatic target recognition area in this paper suggested a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) (Feng, Huang, Lin, &amp; Gay, 2009; Huang &amp; Siew, 2004, 2005; Huang &amp; Chen, 2007, 2008; Huang, Chen, &amp; Siew, 2006; Huang, Ding, &amp; Zhou, 2010; Huang, Zhu, &amp; Siew, 2004; Huang, Liang, Rong, Saratchandran, &amp; Sundararajan, 2005; Huang, Zhou, Ding, &amp; Zhang, 2012; Huang, Li, Chen, &amp; Siew, 2008; Huang, Wang, &amp; Lan, 2011; Huang et al., 2006; Huang, Zhu, &amp; Siew, 2006a, 2006b; Lan, Soh, &amp; Huang, 2009; Li, Huang, Saratchandran, &amp; Sundararajan, 2005; Liang, Huang, Saratchandran, &amp; Sundararajan, 2006; Liang, Saratchandran, Huang, &amp; Sundararajan, 2006; Rong, Huang, Saratchandran, &amp; Sundararajan, 2009; Wang &amp; Huang, 2005; Wang, Cao, &amp; Yuan, 2011; Yeu, Lim, Huang, Agarwal, &amp; Ong, 2006; Zhang, Huang, Sundararajan, &amp; Saratchandran, 2007; Zhu, Qin, Suganthan, &amp; Huang, 2005) which randomly choose hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. Moreover, the Discrete Wavelet Transform (DWT) and wavelet entropy is used for adaptive feature extraction in the time-frequency domain in feature extraction stage to strengthen the premium features of the ELM in this study. The correct recognition performance of this new system is compared with feedforward neural networks. The experimental results show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks.
ER  - 

TY  - JOUR
T1  - A comparative analysis of support vector machines and extreme learning machines
JO  - Neural Networks
VL  - 33
IS  - 
SP  - 58
EP  - 66
PY  - 2012/9//
T2  - 
AU  - Liu, Xueyi
AU  - Gao, Chuanhou
AU  - Li, Ping
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2012.04.002
UR  - https://www.sciencedirect.com/science/article/pii/S0893608012001086
KW  - SVM
KW  - ELM
KW  - VC dimension
KW  - Generalization ability
KW  - Computational complexity
AB  - The theory of extreme learning machines (ELMs) has recently become increasingly popular. As a new learning algorithm for single-hidden-layer feed-forward neural networks, an ELM offers the advantages of low computational cost, good generalization ability, and ease of implementation. Hence the comparison and model selection between ELMs and other kinds of state-of-the-art machine learning approaches has become significant and has attracted many research efforts. This paper performs a comparative analysis of the basic ELMs and support vector machines (SVMs) from two viewpoints that are different from previous works: one is the VapnikâChervonenkis (VC) dimension, and the other is their performance under different training sample sizes. It is shown that the VC dimension of an ELM is equal to the number of hidden nodes of the ELM with probability one. Additionally, their generalization ability and computational complexity are exhibited with changing training sample size. ELMs have weaker generalization ability than SVMs for small sample but can generalize as well as SVMs for large sample. Remarkably, great superiority in computational speed especially for large-scale sample problems is found in ELMs. The results obtained can provide insight into the essential relationship between them, and can also serve as complementary knowledge for their past experimental and theoretical comparisons.
ER  - 

TY  - JOUR
T1  - Privacy-preserving back-propagation and extreme learning machine algorithms
JO  - Data & Knowledge Engineering
VL  - 79â80
IS  - 
SP  - 40
EP  - 61
PY  - 2012/9//
Y2  - 2012/10//
T2  - 
AU  - Samet, Saeed
AU  - Miri, Ali
SN  - 0169-023X
DO  - https://doi.org/10.1016/j.datak.2012.06.001
UR  - https://www.sciencedirect.com/science/article/pii/S0169023X12000602
KW  - Privacy preserving data mining
KW  - Neural networks
KW  - Machine learning
KW  - Back-propagation
KW  - Extreme learning machine
KW  - Distributed data structures
AB  - Neural network systems are highly capable of deriving knowledge from complex data, and they are used to extract patterns and trends which are otherwise hidden in many applications. Preserving the privacy of sensitive data and individuals' information is a major challenge in many of these applications. One of the most popular algorithms in neural network learning systems is the back-propagation (BP) algorithm, which is designed for single-layer and multi-layer models and can be applied to continuous data and differentiable activation functions. Another recently introduced learning technique is the extreme learning machine (ELM) algorithm. Although it works only on single-layer models, ELM can out-perform the BP algorithm by reducing the communication required between parties in the learning phase. In this paper, we present new privacy-preserving protocols for both the BP and ELM algorithms when data is horizontally and vertically partitioned among several parties. These new protocols, which preserve the privacy of both the input data and the constructed learning model, can be applied to online incoming records and/or batch learning. Furthermore, the final model is securely shared among all parties, who can use it jointly to predict the corresponding output for their target data.
ER  - 

TY  - JOUR
T1  - A novel approach for detection and classification of mammographic microcalcifications using wavelet analysis and extreme learning machine
JO  - Computers in Biology and Medicine
VL  - 42
IS  - 9
SP  - 898
EP  - 905
PY  - 2012/9//
T2  - 
AU  - Malar, E.
AU  - Kandaswamy, A.
AU  - Chakravarthy, D.
AU  - Giri Dharan, A.
SN  - 0010-4825
DO  - https://doi.org/10.1016/j.compbiomed.2012.07.001
UR  - https://www.sciencedirect.com/science/article/pii/S0010482512001059
KW  - Extreme learning machine
KW  - Microcalcification
KW  - GLSDM
KW  - Gabor filter
KW  - Wavelet
AB  - The objective of this paper is to reveal the effectiveness of wavelet based tissue texture analysis for microcalcification detection in digitized mammograms using Extreme Learning Machine (ELM). Microcalcifications are tiny deposits of calcium in the breast tissue which are potential indicators for early detection of breast cancer. The dense nature of the breast tissue and the poor contrast of the mammogram image prohibit the effectiveness in identifying microcalcifications. Hence, a new approach to discriminate the microcalcifications from the normal tissue is done using wavelet features and is compared with different feature vectors extracted using Gray Level Spatial Dependence Matrix (GLSDM) and Gabor filter based techniques. A total of 120 Region of Interests (ROIs) extracted from 55 mammogram images of mini-Mias database, including normal and microcalcification images are used in the current research. The network is trained with the above mentioned features and the results denote that ELM produces relatively better classification accuracy (94%) with a significant reduction in training time than the other artificial neural networks like Bayesnet classifier, Naivebayes classifier, and Support Vector Machine. ELM also avoids problems like local minima, improper learning rate, and over fitting.
ER  - 

TY  - JOUR
T1  - Online sequential extreme learning machine with forgetting mechanism
JO  - Neurocomputing
VL  - 87
IS  - 
SP  - 79
EP  - 89
PY  - 2012/6/15/
T2  - 
AU  - Zhao, Jianwei
AU  - Wang, Zhihui
AU  - Park, Dong Sun
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2012.02.003
UR  - https://www.sciencedirect.com/science/article/pii/S0925231212000690
KW  - Extreme learning machine
KW  - Online learning
KW  - Forgetting mechanism
KW  - Timeliness
AB  - The ensemble of online sequential extreme learning machine (EOS-ELM), an average of several online sequential extreme learning machines (OS-ELMs), can learn data one-by-one or chunk-by-chunk with fixed or varying chunk size. EOS-ELM provides higher accuracy with fewer training time, better generalization performance and stability than other popular sequential learning algorithms. However, in plenty of practical applications such as stock forecast, weather forecast, etc., training data often have timeliness, that is, each datum has a period of validity. In order to reflect the timeliness of training data in the process of learning, an improved EOS-ELM, called online sequential extreme learning machine with forgetting mechanism (FOS-ELM), is proposed in this paper. The proposed FOS-ELM cannot only retain the advantages of EOS-ELM, but also improve the learning effects by discarding the outdated data quickly in the process of learning to reduce their bad affection to the following learning. Detailed performance comparisons of FOS-ELM are carried out with EOS-ELM in the stock price short-term predictions. The experimental results show that FOS-ELM has higher accuracy with fewer training time, better stability and short-term predictability than EOS-ELM.
ER  - 

TY  - JOUR
T1  - Reversible watermarking via extreme learning machine prediction
JO  - Neurocomputing
VL  - 82
IS  - 
SP  - 62
EP  - 68
PY  - 2012/4/1/
T2  - 
AU  - Feng, Guorui
AU  - Qian, Zhenxing
AU  - Dai, Ningjie
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.10.028
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211007211
KW  - Down-sample pattern
KW  - Reversible watermarking
KW  - Global regression
KW  - Extreme learning machine
AB  - In this paper, we attempt to construct a novel framework of reversible watermarking. This work is based on the difference-image histogram shift. De-correlation is the core of high capacity data-hiding in histogram-shift techniques. For the sake of higher payload, we choose the down-sample pattern as reference set. For each layer, prediction points are obtained in terms of points from the reference set. The full-resolution image quality reconstructed determines to reversible watermarking performance. When existing the prior knowledge, an effective regression method named extreme learning machine is utilized to estimate missing pixels. It can yield high-quality recovery image. Compared to other better algorithms on state of the art, the proposed method achieves higher capacity gain of watermarked images with the similar distortion.
ER  - 

TY  - JOUR
T1  - Fast learning Circular Complex-valued Extreme Learning Machine (CC-ELM) for real-valued classification problems
JO  - Information Sciences
VL  - 187
IS  - 
SP  - 277
EP  - 290
PY  - 2012/3/15/
T2  - 
AU  - Savitha, R.
AU  - Suresh, S.
AU  - Sundararajan, N.
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2011.11.003
UR  - https://www.sciencedirect.com/science/article/pii/S0020025511005809
KW  - Complex-valued ELM
KW  - Orthogonal decision boundaries
KW  - Circular function
KW  - Acoustic emission and mammogram classification
AB  - In this paper, we present a fast learning fully complex-valued extreme learning machine classifier, referred to as âCircular Complex-valued Extreme Learning Machine (CC-ELM)â for handling real-valued classification problems. CC-ELM is a single hidden layer network with non-linear input and hidden layers and a linear output layer. A circular transformation with a translational/rotational bias term that performs a one-to-one transformation of real-valued features to the complex plane is used as an activation function for the input neurons. The neurons in the hidden layer employ a fully complex-valued Gaussian-like (âsechâ) activation function. The input parameters of CC-ELM are chosen randomly and the output weights are computed analytically. This paper also presents an analytical proof to show that the decision boundaries of a single complex-valued neuron at the hidden and output layers of CC-ELM consist of two hyper-surfaces that intersect orthogonally. These orthogonal boundaries and the input circular transformation help CC-ELM to perform real-valued classification tasks efficiently.

Performance of CC-ELM is evaluated using a set of benchmark real-valued classification problems from the University of California, Irvine machine learning repository. Finally, the performance of CC-ELM is compared with existing methods on two practical problems, viz., the acoustic emission signal classification problem and a mammogram classification problem. These study results show that CC-ELM performs better than other existing (both) real-valued and complex-valued classifiers, especially when the data sets are highly unbalanced.
ER  - 

TY  - JOUR
T1  - Voting based extreme learning machine
JO  - Information Sciences
VL  - 185
IS  - 1
SP  - 66
EP  - 77
PY  - 2012/2/15/
T2  - 
AU  - Cao, Jiuwen
AU  - Lin, Zhiping
AU  - Huang, Guang-Bin
AU  - Liu, Nan
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2011.09.015
UR  - https://www.sciencedirect.com/science/article/pii/S0020025511004725
KW  - Classification
KW  - Extreme learning machine
KW  - Majority voting
KW  - Single hidden layer feedforward networks
KW  - Ensemble methods
AB  - This paper proposes an improved learning algorithm for classification which is referred to as voting based extreme learning machine. The proposed method incorporates the voting method into the popular extreme learning machine (ELM) in classification applications. Simulations on many real world classification datasets have demonstrated that this algorithm generally outperforms the original ELM algorithm as well as several recent classification algorithms.
ER  - 

TY  - JOUR
T1  - Hidden Node Optimization for Extreme Learning Machine
JO  - AASRI Procedia
VL  - 3
IS  - 
SP  - 375
EP  - 380
PY  - 2012///
T2  - Conference on Modelling, Identification and Control
AU  - Huang, Yan-wei
AU  - Lai, Da-hu
SN  - 2212-6716
DO  - https://doi.org/10.1016/j.aasri.2012.11.059
UR  - https://www.sciencedirect.com/science/article/pii/S2212671612002181
KW  - ELM
KW  - VC confidence
KW  - structural risk
KW  - hidden nodes
KW  - PSO
AB  - The number of hidden nodes is a critical factor for the generalization of ELM. Generally, it is heavy for time consumption to obtain the optimal number of hidden nodes with trial-and-error. A novel algorithm is proposed to optimize the hidden node number to guarantee good generalization, which employs the PSO in the optimization process with structural risk minimization principle. The simulation results indicate our algorithm for the optimal number of hidden nodes is reasonable and feasible with 6 datasets on benchmark problems by the accuracy comparisons.
ER  - 

TY  - JOUR
T1  - Comparing error minimized extreme learning machines and support vector sequential feed-forward neural networks
JO  - Neural Networks
VL  - 25
IS  - 
SP  - 122
EP  - 129
PY  - 2012/1//
T2  - 
AU  - Romero, Enrique
AU  - AlquÃ©zar, RenÃ©
SN  - 0893-6080
DO  - https://doi.org/10.1016/j.neunet.2011.08.005
UR  - https://www.sciencedirect.com/science/article/pii/S0893608011002231
KW  - Error minimized extreme learning machines
KW  - Support vector sequential feed-forward neural networks
KW  - Sequential approximations
AB  - Recently, error minimized extreme learning machines (EM-ELMs) have been proposed as a simple and efficient approach to build single-hidden-layer feed-forward networks (SLFNs) sequentially. They add random hidden nodes one by one (or group by group) and update the output weights incrementally to minimize the sum-of-squares error in the training set. Other very similar methods that also construct SLFNs sequentially had been reported earlier with the main difference that their hidden-layer weights are a subset of the data instead of being random. These approaches are referred to as support vector sequential feed-forward neural networks (SV-SFNNs), and they are a particular case of the sequential approximation with optimal coefficients and interacting frequencies (SAOCIF) method. In this paper, it is firstly shown that EM-ELMs can also be cast as a particular case of SAOCIF. In particular, EM-ELMs can easily be extended to test some number of random candidates at each step and select the best of them, as SAOCIF does. Moreover, it is demonstrated that the cost of the computation of the optimal output-layer weights in the originally proposed EM-ELMs can be improved if it is replaced by the one included in SAOCIF. Secondly, we present the results of an experimental study on 10 benchmark classification and 10 benchmark regression data sets, comparing EM-ELMs and SV-SFNNs, that was carried out under the same conditions for the two models. Although both models have the same (efficient) computational cost, a statistically significant improvement in generalization performance of SV-SFNNs vs. EM-ELMs was found in 12 out of the 20 benchmark problems.
ER  - 

TY  - JOUR
T1  - Regularized extreme learning machine for regression problems
JO  - Neurocomputing
VL  - 74
IS  - 17
SP  - 3716
EP  - 3721
PY  - 2011/10//
T2  - 
AU  - MartÃ­nez-MartÃ­nez, JosÃ© M.
AU  - Escandell-Montero, Pablo
AU  - Soria-Olivas, Emilio
AU  - MartÃ­n-Guerrero, JosÃ© D.
AU  - Magdalena-Benedito, Rafael
AU  - GÃ³mez-Sanchis, Juan
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.06.013
UR  - https://www.sciencedirect.com/science/article/pii/S092523121100378X
KW  - Regularization
KW  - Extreme learning machine
KW  - Regression
KW  - Artificial neural networks
AB  - Extreme learning machine (ELM) is a new learning algorithm for single-hidden layer feedforward networks (SLFNs) proposed by Huang et al. [1]. Its main advantage is the lower computational cost, which is especially relevant when dealing with many patterns defined in a high-dimensional space. This paper proposes an algorithm for pruning ELM networks by using regularized regression methods, thus obtaining a suitable number of the hidden nodes in the network architecture. Beginning from an initial large number of hidden nodes, irrelevant nodes are then pruned using ridge regression, elastic net and lasso methods; hence, the architectural design of ELM network can be automated. Empirical studies on several commonly used regression benchmark problems show that the proposed approach leads to compact networks that generate competitive results compared with the ELM algorithm.
ER  - 

TY  - JOUR
T1  - Human face recognition based on multidimensional PCA and extreme learning machine
JO  - Pattern Recognition
VL  - 44
IS  - 10â11
SP  - 2588
EP  - 2597
PY  - 2011/10//
Y2  - 2011/11//
T2  - Semi-Supervised Learning for Visual Content Analysis and Understanding
AU  - Mohammed, A.A.
AU  - Minhas, R.
AU  - Jonathan Wu, Q.M.
AU  - Sid-Ahmed, M.A.
SN  - 0031-3203
DO  - https://doi.org/10.1016/j.patcog.2011.03.013
UR  - https://www.sciencedirect.com/science/article/pii/S0031320311000987
KW  - Face recognition
KW  - Multiresolution analysis
KW  - Bidirectional two dimensional principal component analysis
KW  - Extreme learning machine
KW  - KNN classifier
AB  - In this work, a new human face recognition algorithm based on bidirectional two dimensional principal component analysis (B2DPCA) and extreme learning machine (ELM) is introduced. The proposed method is based on curvelet image decomposition of human faces and a subband that exhibits a maximum standard deviation is dimensionally reduced using an improved dimensionality reduction technique. Discriminative feature sets are generated using B2DPCA to ascertain classification accuracy. Other notable contributions of the proposed work include significant improvements in classification rate, up to hundred folds reduction in training time and minimal dependence on the number of prototypes. Extensive experiments are performed using challenging databases and results are compared against state of the art techniques.
ER  - 

TY  - JOUR
T1  - A study on effectiveness of extreme learning machine
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2483
EP  - 2490
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Wang, Yuguang
AU  - Cao, Feilong
AU  - Yuan, Yubo
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.11.030
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002116
KW  - Feedforward neural networks
KW  - Extreme learning machine
KW  - Effective extreme learning machine
AB  - Extreme learning machine (ELM), proposed by Huang et al., has been shown a promising learning algorithm for single-hidden layer feedforward neural networks (SLFNs). Nevertheless, because of the random choice of input weights and biases, the ELM algorithm sometimes makes the hidden layer output matrix H of SLFN not full column rank, which lowers the effectiveness of ELM. This paper discusses the effectiveness of ELM and proposes an improved algorithm called EELM that makes a proper selection of the input weights and bias before calculating the output weights, which ensures the full column rank of H in theory. This improves to some extend the learning rate (testing accuracy, prediction accuracy, learning time) and the robustness property of the networks. The experimental results based on both the benchmark function approximation and real-world problems including classification and regression applications show the good performances of EELM.
ER  - 

TY  - JOUR
T1  - Testing correct model specification using extreme learning machines
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2552
EP  - 2565
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Cho, Jin Seo
AU  - White, Halbert
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.11.031
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002128
KW  - Artificial neural networks
KW  - Gaussian process
KW  - Functional regression
KW  - Extreme learning machines
AB  - Testing the correct model specification hypothesis for artificial neural network (ANN) models of the conditional mean is not standard. The traditional Wald, Lagrange multiplier, and quasi-likelihood ratio statistics weakly converge to functions of Gaussian processes, rather than to convenient chi-squared distributions. Also, their large-sample null distributions are problem dependent, limiting applicability. We overcome this challenge by applying functional regression methods of Cho et al. [8] to extreme learning machines (ELM). The Wald ELM (WELM) test statistic proposed here is easy to compute and has a large-sample standard chi-squared distribution under the null hypothesis of correct specification. We provide associated theory for time-series data and affirm our theory with some Monte Carlo experiments.
ER  - 

TY  - JOUR
T1  - Optimization approximation solution for regression problem based on extreme learning machine
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2475
EP  - 2482
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Yuan, Yubo
AU  - Wang, Yuguang
AU  - Cao, Feilong
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.12.037
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002505
KW  - Extreme learning machine
KW  - Regression
KW  - Optimization
KW  - Matrix theory
AB  - Extreme learning machine (ELM) is one of the most popular and important learning algorithms. It comes from single-hidden-layer feedforward neural networks. It has been proved that ELM can achieve better performance than support vector machine (SVM) in regression and classification. In this paper, mathematically, with regression problem, the step 3 of ELM is studied. First of all, the equation H Î² = T are reformulated as an optimal model. With the optimality, the necessary conditions of optimal solution are presented. The equation H Î² = T is replaced by H T H Î² = H T T . We can prove that the latter must have one solution at least. Second, optimal approximation solution is discussed in cases of H is column full rank, row full rank, neither column nor row full rank. In the last case, the rank-1 and rank-2 methods are used to get optimal approximation solution. In theory, this paper present a better algorithm for ELM.
ER  - 

TY  - JOUR
T1  - Application of error minimized extreme learning machine for simultaneous learning of a function and its derivatives
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2511
EP  - 2519
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Balasundaram, S.
AU  - Kapil
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.12.033
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002189
KW  - Derivatives approximation
KW  - Extreme learning machine
KW  - Feedforward neural networks
KW  - Function approximation
KW  - Incremental learning
AB  - In this paper a new learning algorithm is proposed for the problem of simultaneous learning of a function and its derivatives as an extension of the study of error minimized extreme learning machine for single hidden layer feedforward neural networks. Our formulation leads to solving a system of linear equations and its solution is obtained by MooreâPenrose generalized pseudo-inverse. In this approach the number of hidden nodes is automatically determined by repeatedly adding new hidden nodes to the network either one by one or group by group and updating the output weights incrementally in an efficient manner until the network output error is less than the given expected learning accuracy. For the verification of the efficiency of the proposed method a number of interesting examples are considered and the results obtained with the proposed method are compared with that of other two popular methods. It is observed that the proposed method is fast and produces similar or better generalization performance on the test data.
ER  - 

TY  - JOUR
T1  - Fast automatic two-stage nonlinear model identification based on the extreme learning machine
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2422
EP  - 2429
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Deng, Jing
AU  - Li, Kang
AU  - Irwin, George W.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.11.035
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002554
KW  - Extreme learning machine
KW  - Two-stage stepwise selection
KW  - Leave-one-out cross validation
KW  - RBF networks
AB  - It is convenient and effective to solve nonlinear problems with a model that has a linear-in-the-parameters (LITP) structure. However, the nonlinear parameters (e.g. the width of Gaussian function) of each model term needs to be pre-determined either from expert experience or through exhaustive search. An alternative approach is to optimize them by a gradient-based technique (e.g. Newton's method). Unfortunately, all of these methods still need a lot of computations. Recently, the extreme learning machine (ELM) has shown its advantages in terms of fast learning from data, but the sparsity of the constructed model cannot be guaranteed. This paper proposes a novel algorithm for automatic construction of a nonlinear system model based on the extreme learning machine. This is achieved by effectively integrating the ELM and leave-one-out (LOO) cross validation with our two-stage stepwise construction procedure [1]. The main objective is to improve the compactness and generalization capability of the model constructed by the ELM method. Numerical analysis shows that the proposed algorithm only involves about half of the computation of orthogonal least squares (OLS) based method. Simulation examples are included to confirm the efficacy and superiority of the proposed technique.
ER  - 

TY  - JOUR
T1  - Face recognition based on extreme learning machine
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2541
EP  - 2551
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Zong, Weiwei
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.12.041
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002578
KW  - Face recognition
KW  - Discriminative locality alignment
KW  - Support vector machine
KW  - Extreme learning machine
KW  - One-against-all
KW  - One-against-one
AB  - Extreme learning machine (ELM) is an efficient learning algorithm for generalized single hidden layer feedforward networks (SLFNs), which performs well in both regression and classification applications. It has recently been shown that from the optimization point of view ELM and support vector machine (SVM) are equivalent but ELM has less stringent optimization constraints. Due to the mild optimization constraints ELM can be easy of implementation and usually obtains better generalization performance. In this paper we study the performance of the one-against-all (OAA) and one-against-one (OAO) ELM for classification in multi-label face recognition applications. The performance is verified through four benchmarking face image data sets.
ER  - 

TY  - JOUR
T1  - Advances in extreme learning machines (ELM2010)
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2411
EP  - 2412
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Huang, Guang-Bin
AU  - Wang, Dianhui
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2011.03.030
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002633
ER  - 

TY  - JOUR
T1  - MELM-GRBF: A modified version of the extreme learning machine for generalized radial basis function neural networks
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2502
EP  - 2510
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - FernÃ¡ndez-Navarro, Francisco
AU  - HervÃ¡s-MartÃ­nez, CÃ©sar
AU  - Sanchez-Monedero, Javier
AU  - GutiÃ©rrez, Pedro Antonio
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.11.032
UR  - https://www.sciencedirect.com/science/article/pii/S092523121100213X
KW  - Generalized radial basis functions neural networks
KW  - Extreme learning machine
KW  - Multi-classification
KW  - Generalized Gaussian distribution
AB  - In this paper, we propose a methodology for training a new model of artificial neural network called the generalized radial basis function (GRBF) neural network. This model is based on generalized Gaussian distribution, which parametrizes the Gaussian distribution by adding a new parameter Ï . The generalized radial basis function allows different radial basis functions to be represented by updating the new parameter Ï . For example, when GRBF takes a value of Ï = 2 , it represents the standard Gaussian radial basis function. The model parameters are optimized through a modified version of the extreme learning machine (ELM) algorithm. In the methodology proposed (MELM-GRBF), the centers of each GRBF were taken randomly from the patterns of the training set and the radius and Ï values were determined analytically, taking into account that the model must fulfil two constraints: locality and coverage. An thorough experimental study is presented to test its overall performance. Fifteen datasets were considered, including binary and multi-class problems, all of them taken from the UCI repository. The MELM-GRBF was compared to ELM with sigmoidal, hard-limit, triangular basis and radial basis functions in the hidden layer and to the ELM-RBF methodology proposed by Huang et al. (2004) [1]. The MELM-GRBF obtained better results in accuracy than the corresponding sigmoidal, hard-limit, triangular basis and radial basis functions for almost all datasets, producing the highest mean accuracy rank when compared with these other basis functions for all datasets.
ER  - 

TY  - JOUR
T1  - Image deblurring with filters learned by extreme learning machine
JO  - Neurocomputing
VL  - 74
IS  - 16
SP  - 2464
EP  - 2474
PY  - 2011/9//
T2  - Advances in Extreme Learning Machine: Theory and ApplicationsBiological Inspired Systems. Computational and Ambient IntelligenceSelected papers of the 10th International Work-Conference on Artificial Neural Networks (IWANN2009)
AU  - Wang, Liang
AU  - Huang, Yaping
AU  - Luo, Xiaoyue
AU  - Wang, Zhe
AU  - Luo, Siwei
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.12.035
UR  - https://www.sciencedirect.com/science/article/pii/S0925231211002487
KW  - Image processing
KW  - Inverse problem
KW  - Calculus of variations
KW  - Partial differential equation (PDE)
KW  - Machine learning
KW  - Natural image priors
AB  - Image deblurring is a basic and important task of image processing. Traditional filtering based image deblurring methods, e.g. enhancement filters, partial differential equation (PDE) and etc., are limited by the hypothesis that natural images and noise are with low and high frequency terms, respectively. Noise removal and edge protection are always the dilemma for traditional models.

In this paper, we study image deblurring problem from a brand new perspectiveâclassification. And we also generalize the traditional PDE model to a more general case, using the theories of calculus of variations. Furthermore, inspired by the theories of approximation of functions, we transform the operator-learning problem into a coefficient-learning problem by means of selecting a group of basis, and build a filter-learning model. Based on extreme learning machine (ELM) [1â4], an algorithm is designed and a group of filters are learned effectively. Then a generalized image deblurring model, learned filtering PDE (LF-PDE), is built.

The experiments verify the effectiveness of our models and the corresponding learned filters. It is shown that our model can overcome many drawbacks of the traditional models and achieve much better results.
ER  - 

TY  - JOUR
T1  - Application of extreme learning machine for series compensated transmission line protection
JO  - Engineering Applications of Artificial Intelligence
VL  - 24
IS  - 5
SP  - 880
EP  - 887
PY  - 2011/8//
T2  - 
AU  - Malathi, V.
AU  - Marimuthu, N.S.
AU  - Baskar, S.
AU  - Ramar, K.
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2011.03.003
UR  - https://www.sciencedirect.com/science/article/pii/S0952197611000479
KW  - Extreme learning machine
KW  - Fault classification
KW  - Fault location
KW  - Fault section identification
KW  - Series compensation
KW  - Transmission line protection
KW  - Wavelet transform
AB  - This paper proposes a new approach based on combined Wavelet Transform-Extreme Learning Machine (WT-ELM) technique for fault section identification (whether the fault is before or after the series capacitor as observed from the relay point), classification and location in a series compensated transmission line. This method uses the samples of fault currents for half cycle duration from the inception of fault. The features of fault currents are extracted by first level decomposition of the current samples using discrete wavelet transform (DWT) and the extracted features are applied as inputs to ELMs for fault section identification, classification and location. The feasibility of the proposed method has been tested on a 400 kV, 300 km series compensated transmission line for all the ten types of faults using MATLAB simulink. On testing 28,800 fault cases with varying fault resistance, fault inception angle, fault distance, load angle, percentage compensation level and source impedance, the performance of the proposed method has been found to be quite promising. The results also indicate that the proposed method is robust to wide variation in system and operating conditions.
ER  - 

TY  - JOUR
T1  - Sales forecasting system based on Gray extreme learning machine with Taguchi method in retail industry
JO  - Expert Systems with Applications
VL  - 38
IS  - 3
SP  - 1336
EP  - 1345
PY  - 2011/3//
T2  - 
AU  - Chen, F.L.
AU  - Ou, T.Y.
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2010.07.014
UR  - https://www.sciencedirect.com/science/article/pii/S0957417410006317
KW  - Sales forecasting
KW  - Gray extreme learning machine
KW  - Taguchi method
KW  - Retail industry
AB  - Due to the strong competition that exists today, most retailers are in a continuous effort for increasing profits and reducing their cost. An accurate sales forecasting system is an efficient way to achieve the aforementioned goals and lead to improve the customersâ satisfaction, reduce destruction of products, increase sales revenue and make production plan efficiently. In this study, the Gray extreme learning machine (GELM) integrates Gray relation analysis and extreme learning machine with Taguchi method to support purchasing decisions. GRA can sieve out the more influential factors from raw data and transforms them as the input data in a novel neural network such as ELM. The proposed system evaluated the real sales data in the retail industry. The experimental results demonstrate that our proposed system outperform several sales forecasting methods which are based on back-propagation neural networks such as BPN and MFLN models.
ER  - 

TY  - JOUR
T1  - Ordinal extreme learning machine
JO  - Neurocomputing
VL  - 74
IS  - 1â3
SP  - 447
EP  - 456
PY  - 2010/12//
T2  - Artificial Brains
AU  - Deng, Wan-Yu
AU  - Zheng, Qing-Hua
AU  - Lian, Shiguo
AU  - Chen, Lin
AU  - Wang, Xin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.08.022
UR  - https://www.sciencedirect.com/science/article/pii/S0925231210004042
KW  - Ordinal regression
KW  - Extreme learning machine
KW  - Error correcting output codes
AB  - Recently, a new fast learning algorithm called Extreme Learning Machine (ELM) has been developed for Single-Hidden Layer Feedforward Networks (SLFNs) in G.-B. Huang, Q.-Y. Zhu and C.-K. Siew â[Extreme learning machine: theory and applications,â Neurocomputing 70 (2006) 489â501]. And, ELM has been successfully applied to many classification and regression problems. In this paper, the ELM algorithm is further studied for ordinal regression problems (named ORELM). We firstly proposed an encoding-based framework for ordinal regression which includes three encoding schemes: single multi-output classifier, multiple binary-classifications with one-against-all (OAA) decomposition method and one-against-one (OAO) method. Then, the SLFN was redesigned for ordinal regression problems based on the proposed framework and the algorithms are trained by the extreme learning machine in which input weights are assigned randomly and output weights can be decided analytically. Lastly widely experiments on three kinds of datasets were carried to test the proposed algorithm. The comparative results with such traditional methods as Gaussian Process for Ordinal Regression (ORGP) and Support Vector for Ordinal Regression (ORSVM) show that ORELM can obtain extremely rapid training speed and good generalization ability. Especially when the data setâs scalability increases, the advantage of ORELM will become more apparent. Additionally, ORELM has the following advantages, including the capabilities of learning in both online and batch modes and handling non-linear data.
ER  - 

TY  - JOUR
T1  - Optimization method based extreme learning machine for classification
JO  - Neurocomputing
VL  - 74
IS  - 1â3
SP  - 155
EP  - 163
PY  - 2010/12//
T2  - Artificial Brains
AU  - Huang, Guang-Bin
AU  - Ding, Xiaojian
AU  - Zhou, Hongming
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.02.019
UR  - https://www.sciencedirect.com/science/article/pii/S0925231210002225
KW  - Extreme learning machine
KW  - Support vector machine
KW  - Support vector network
KW  - ELM kernel
KW  - ELM feature space
KW  - Equivalence between ELM and SVM
KW  - Maximal margin
KW  - Minimal norm of weights
KW  - Primal and dual ELM networks
AB  - Extreme learning machine (ELM) as an emergent technology has shown its good performance in regression applications as well as in large dataset (and/or multi-label) classification applications. The ELM theory shows that the hidden nodes of the âgeneralizedâ single-hidden layer feedforward networks (SLFNs), which need not be neuron alike, can be randomly generated and the universal approximation capability of such SLFNs can be guaranteed. This paper further studies ELM for classification in the aspect of the standard optimization method and extends ELM to a specific type of âgeneralizedâ SLFNsâsupport vector network. This paper shows that: (1) under the ELM learning framework, SVM's maximal margin property and the minimal norm of weights theory of feedforward neural networks are actually consistent; (2) from the standard optimization method point of view ELM for classification and SVM are equivalent but ELM has less optimization constraints due to its special separability feature; (3) as analyzed in theory and further verified by the simulation results, ELM for classification tends to achieve better generalization performance than traditional SVM. ELM for classification is less sensitive to user specified parameters and can be implemented easily.
ER  - 

TY  - JOUR
T1  - Performance enhancement of extreme learning machine for multi-category sparse data classification problems
JO  - Engineering Applications of Artificial Intelligence
VL  - 23
IS  - 7
SP  - 1149
EP  - 1157
PY  - 2010/10//
T2  - 
AU  - Suresh, S.
AU  - Saraswathi, S.
AU  - Sundararajan, N.
SN  - 0952-1976
DO  - https://doi.org/10.1016/j.engappai.2010.06.009
UR  - https://www.sciencedirect.com/science/article/pii/S0952197610001326
KW  - Neural network
KW  - Extreme learning machine
KW  - K-fold validation
KW  - Genetic algorithm
KW  - Multi-category sparse classification
KW  - Micro-array gene expression data
AB  - This paper presents a performance enhancement scheme for the recently developed extreme learning machine (ELM) for multi-category sparse data classification problems. ELM is a single hidden layer neural network with good generalization capabilities and extremely fast learning capacity. In ELM, the input weights are randomly chosen and the output weights are analytically calculated. The generalization performance of the ELM algorithm for sparse data classification problem depends critically on three free parameters. They are, the number of hidden neurons, the input weights and the bias values which need to be optimally chosen. Selection of these parameters for the best performance of ELM involves a complex optimization problem.

In this paper, we present a new, real-coded genetic algorithm approach called âRCGA-ELMâ to select the optimal number of hidden neurons, input weights and bias values which results in better performance. Two new genetic operators called ânetwork based operatorâ and âweight based operatorâ are proposed to find a compact network with higher generalization performance. We also present an alternate and less computationally intensive approach called âsparse-ELMâ. Sparse-ELM searches for the best parameters of ELM using K-fold validation. A multi-class human cancer classification problem using micro-array gene expression data (which is sparse), is used for evaluating the performance of the two schemes. Results indicate that the proposed RCGA-ELM and sparse-ELM significantly improve ELM performance for sparse multi-category classification problems.
ER  - 

TY  - JOUR
T1  - Constructive hidden nodes selection of extreme learning machine for regression
JO  - Neurocomputing
VL  - 73
IS  - 16â18
SP  - 3191
EP  - 3199
PY  - 2010/10//
T2  - 10th Brazilian Symposium on Neural Networks (SBRN2008)
AU  - Lan, Yuan
AU  - Soh, Yeng Chai
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.05.022
UR  - https://www.sciencedirect.com/science/article/pii/S0925231210002778
KW  - Extreme learning machine
KW  - Constructive method
KW  - Incremental extreme learning machine
KW  - Error-minimized extreme learning machine
AB  - In this paper, we attempt to address the architectural design of ELM regressor by applying a constructive method on the basis of ELM algorithm. After the nonlinearities of ELM network are fixed by randomly generating the parameters, the network will correspond to a linear regression model. The selection of hidden nodes can then be regarded as a subset model selection in linear regression. The proposed constructive hidden nodes selection for ELM (referred to as CS-ELM) selects the optimal number of hidden nodes when the unbiased risk estimation based criterion CP reaches the minimum value. A comparison of the proposed CS-ELM with other model selection algorithms of ELM is evaluated on several real benchmark regression applications. And the empirical study shows that CS-ELM leads to a compact network structure automatically.
ER  - 

TY  - JOUR
T1  - Two-stage extreme learning machine for regression
JO  - Neurocomputing
VL  - 73
IS  - 16â18
SP  - 3028
EP  - 3038
PY  - 2010/10//
T2  - 10th Brazilian Symposium on Neural Networks (SBRN2008)
AU  - Lan, Yuan
AU  - Soh, Yeng Chai
AU  - Huang, Guang-Bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.07.012
UR  - https://www.sciencedirect.com/science/article/pii/S0925231210003401
KW  - Extreme learning machine
KW  - Fast recursive algorithm
KW  - Final prediction error
KW  - Leave-one-out cross-validation
AB  - Extreme learning machine (ELM) proposed by Huang et al. was developed for generalized single hidden layer feedforward networks (SLFNs) with a wide variety of hidden nodes. It proved to be very fast and effective especially for solving function approximation problems with a predetermined network structure. However, the method for determining the network structure of preliminary ELM may be tedious and may not lead to a parsimonious solution. In this paper, a systematic two-stage algorithm (named TS-ELM) is introduced to handle the problem. In the first stage, a forward recursive algorithm is applied to select the hidden nodes from the candidates randomly generated in each step and add them to the network until the stopping criterion achieves its minimum. The significance of each hidden node is then reviewed in the second stage and the insignificance ones are removed from the network, which drastically reduces the network complexity. The effectiveness of TS-ELM is verified by the empirical studies in this paper.
ER  - 

TY  - JOUR
T1  - A new online learning algorithm for structure-adjustable extreme learning machine
JO  - Computers & Mathematics with Applications
VL  - 60
IS  - 3
SP  - 377
EP  - 389
PY  - 2010/8//
T2  - 
AU  - Li, Guohu
AU  - Liu, Min
AU  - Dong, Mingyu
SN  - 0898-1221
DO  - https://doi.org/10.1016/j.camwa.2010.03.023
UR  - https://www.sciencedirect.com/science/article/pii/S0898122110001999
KW  - Online learning
KW  - Extreme learning machine (ELM)
KW  - Adjustable structure
KW  - Neural network
KW  - Modelling
AB  - In actual industrial fields, data for modelling are usually generated gradually, which requires that the data-based prediction model has the online learning capability. Although many online learning algorithms have been proposed, the generalization performance needs to be improved further. In this paper, a structure-adjustable online learning neural network (SAO-ELM) based on the extreme learning machine (ELM) with quicker learning speed and better generalization performance is proposed. Firstly, ELM is changed into a structure-adjustable learning machine, in which the number of nodes in its single hidden layer can be adjusted. Then, a special strategy is developed to handle the difficulty that the new added hidden nodesâ outputs corresponding to the discarded training data cannot be obtained. After that, an iterative equation is presented to update the output matrix when hidden nodes are added. Results of numerical comparison based on data from the real world benchmark problems and an actual continuous casting process show that the performance of SAO-ELM has significant advantages over that of the typical online learning algorithms on generalization performance. In addition, SAO-ELM retains the merit of quick learning characteristic of ELM.
ER  - 

TY  - JOUR
T1  - Intelligent approaches using support vector machine and extreme learning machine for transmission line protection
JO  - Neurocomputing
VL  - 73
IS  - 10â12
SP  - 2160
EP  - 2167
PY  - 2010/6//
T2  - Subspace Learning / Selected papers from the European Symposium on Time Series Prediction
AU  - Malathi, V.
AU  - Marimuthu, N.S.
AU  - Baskar, S.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.02.001
UR  - https://www.sciencedirect.com/science/article/pii/S0925231210000822
KW  - Extreme learning machine
KW  - Fault classification
KW  - Fault location
KW  - Support vector machine
KW  - Transmission line
KW  - Wavelet transform
AB  - This paper proposes two approaches based on wavelet transform-support vector machine (WT-SVM) and wavelet transform-extreme learning machine (WT-ELM) for transmission line protection. These methods uses fault current samples for half cycle from the inception of fault. The features of the line currents are extracted by first level decomposition of the current samples using discrete wavelet transform (DWT) and extracted features are applied as inputs to SVM and ELM for faulted phase detection, fault classification, location and discrimination between fault and switching transient condition. The feasibility of the proposed methods have been tested on a 240-kV, 225-km transmission line for all the 10 types of fault using MATLAB Simulink. Upon testing on 9600 fault cases with varying fault resistance, fault inception angle, fault distance, pre-fault power level, and source impedances, the performance of the proposed methods are quite promising. The performance of the proposed methods is compared in terms of classification accuracy and fault location error. The results indicate that SVM based approach is accurate compared to ELM based approach for fault classification. For fault location, the maximum error is less with SVM than ELM and the mean error of SVM is slightly higher than ELM.
ER  - 

TY  - JOUR
T1  - Human action recognition using extreme learning machine based on visual vocabularies
JO  - Neurocomputing
VL  - 73
IS  - 10â12
SP  - 1906
EP  - 1917
PY  - 2010/6//
T2  - Subspace Learning / Selected papers from the European Symposium on Time Series Prediction
AU  - Minhas, Rashid
AU  - Baradarani, Aryaz
AU  - Seifzadeh, Sepideh
AU  - Jonathan Wu, Q.M.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2010.01.020
UR  - https://www.sciencedirect.com/science/article/pii/S0925231210001517
KW  - Extreme learning machine
KW  - Activity recognition
KW  - 3D dual-tree complex wavelet transform
KW  - Two-dimensional PCA
KW  - Video classification
AB  - This paper introduces a novel recognition framework for human actions using hybrid features. The hybrid features consist of spatio-temporal and local static features extracted using motion-selectivity attribute of 3D dual-tree complex wavelet transform (3D DT-CWT) and affine SIFT local image detector, respectively. The proposed model offers two core advantages: (1) the framework is significantly faster than traditional approaches due to volumetric processing of images as a â3D box of dataâ instead of a frame by frame analysis, (2) rich representation of human actions in terms of reduction in artifacts in view of the promising properties of our recently designed full symmetry complex filter banks with better directionality and shift-invariance properties. No assumptions about scene background, location, objects of interest, or point of view information are made whereas bidirectional two-dimensional PCA (2D-PCA) is employed for dimensionality reduction which offers enhanced capabilities to preserve structure and correlation amongst neighborhood pixels of a video frame.
ER  - 

TY  - JOUR
T1  - A fast recognition framework based on extreme learning machine using hybrid object information
JO  - Neurocomputing
VL  - 73
IS  - 10â12
SP  - 1831
EP  - 1839
PY  - 2010/6//
T2  - Subspace Learning / Selected papers from the European Symposium on Time Series Prediction
AU  - Minhas, Rashid
AU  - Mohammed, Abdul Adeel
AU  - Jonathan Wu, Q.M.
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2009.11.049
UR  - https://www.sciencedirect.com/science/article/pii/S0925231210001438
KW  - Extreme learning machine
KW  - Object recognition
KW  - Ferns
KW  - Two-dimensional PCA
KW  - Object classification
AB  - This paper presents a new supervised learning scheme, which uses hybrid information i.e. global and local object information, for accurate identification and classification at considerably high speed both in training and testing phase. The first contribution of this paper is a unique image representation using bidirectional two-dimensional PCA and Ferns style approach to represent global and local information, respectively, of an object. Secondly, the application of extreme learning machine supports reliable recognition with minimum error and learning speed approximately thousands of times faster than traditional neural networks. The proposed method is capable of classifying various datasets in a fraction of second compared to other modern algorithms that require at least 2â3 s per image [14].
ER  - 

TY  - JOUR
T1  - Composite function wavelet neural networks with extreme learning machine
JO  - Neurocomputing
VL  - 73
IS  - 7â9
SP  - 1405
EP  - 1416
PY  - 2010/3//
T2  - Advances in Computational Intelligence and Learning17th European Symposium on Artificial Neural Networks 200917th European Symposium on Artificial Neural Networks 2009
AU  - Cao, Jiuwen
AU  - Lin, Zhiping
AU  - Huang, Guang-bin
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2009.12.007
UR  - https://www.sciencedirect.com/science/article/pii/S0925231209004251
KW  - Wavelet neural networks
KW  - Composite function
KW  - Parameter initialization
KW  - Extreme learning machine
AB  - A new structure of wavelet neural networks (WNN) with extreme learning machine (ELM) is introduced in this paper. In the proposed wavelet neural networks, composite functions are applied at the hidden nodes and the learning is done using ELM. The input information is first processed by wavelet functions and then passed through a type of bounded nonconstant piecewise continuous activation functions g : R â R . A selection method that takes into account the domain of input space where the wavelets are not zero is used to initialize the translation and dilation parameters. The formed wavelet neural network is then trained with the computationally efficient ELM algorithm. Experimental results on the regression of some nonlinear functions and real-world data, the prediction of a chaotic signal and classifications on serval benchmark real-world data sets show that the proposed neural networks can achieve better performances in most cases than some relevant neural networks and learn much faster than neural networks training with the traditional back-propagation (BP) algorithm.
ER  - 


