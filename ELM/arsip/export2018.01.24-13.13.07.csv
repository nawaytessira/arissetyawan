"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Distributed and weighted extreme learning machine for imbalanced big data learning","Z. Wang; J. Xin; H. Yang; S. Tian; G. Yu; C. Xu; Y. Yao","Sino- Dutch Biomedical & Information Engineering School, Northeastern University, Shenyang 110169, China","Tsinghua Science and Technology","20170406","2017","22","2","160","173","The Extreme Learning Machine (ELM) and its variants are effective in many machine learning applications such as Imbalanced Learning (IL) or Big Data (BD) learning. However, they are unable to solve both imbalanced and large-volume data learning problems. This study addresses the IL problem in BD applications. The Distributed and Weighted ELM (DW-ELM) algorithm is proposed, which is based on the MapReduce framework. To confirm the feasibility of parallel computation, first, the fact that matrix multiplication operators are decomposable is illustrated. Then, to further improve the computational efficiency, an Improved DW-ELM algorithm (IDW-ELM) is developed using only one MapReduce job. The successful operations of the proposed DW-ELM and IDW-ELM algorithms are finally validated through experiments.","","","10.23919/TST.2017.7889638","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889638","weighted Extreme Learning Machine (ELM); imbalanced big data; MapReduce framework; user-definedcounter","Big Data;Computer science;Distributed databases;Machine learning algorithms;Matrix decomposition;Prediction algorithms;Training","","","","","","","","","","April 2017","","TUP","TUP Journals & Magazines"
"An Extreme Learning Machine Approach to Density Estimation Problems","C. Cervellera; D. Macci√≤","National Research Council, Institute of Intelligent Systems for Automation, Genova, Italy","IEEE Transactions on Cybernetics","20170906","2017","47","10","3254","3265","In this paper, we discuss how the extreme learning machine (ELM) framework can be effectively employed in the unsupervised context of multivariate density estimation. In particular, two algorithms are introduced, one for the estimation of the cumulative distribution function underlying the observed data, and one for the estimation of the probability density function. The algorithms rely on the concept of F-discrepancy, which is closely related to the Kolmogorov-Smirnov criterion for goodness of fit. Both methods retain the key feature of the ELM of providing the solution through random assignment of the hidden feature map and a very light computational burden. A theoretical analysis is provided, discussing convergence under proper hypotheses on the chosen activation functions. Simulation tests show how ELMs can be successfully employed in the density estimation framework, as a possible alternative to other standard methods.","2168-2267;21682267","","10.1109/TCYB.2017.2648261","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820121","<italic xmlns:ali=""http://www.niso.org/schemas/ali/1.0/"" xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"">F</italic>-discrepancy;Density estimation;extreme learning machine (ELM);unsupervised learning","Algorithm design and analysis;Approximation algorithms;Context;Estimation;Kernel;Neural networks;Standards","computerised instrumentation;convergence;density measurement;estimation theory;learning (artificial intelligence);statistical distributions","F-discrepancy;Kolmogorov-Smirnov criterion;convergence;cumulative distribution function estimation;extreme learning machine;multivariate density estimation;probability density function estimation;unsupervised context","","","","","","","20170117","Oct. 2017","","IEEE","IEEE Journals & Magazines"
"A heterogeneous ensemble of extreme learning machines with correntropy and negative correlation","A. O. M. Abuassba; Y. Zhang; X. Luo; D. Zhang; W. Aziguli","School of Computer and Communication Engineering, University of Science and Technology Beijing (USTB), Beijing 100083, China, and the Beijing Key Laboratory of Knowledge Engineering for Materials Science, Beijing 100083, China","Tsinghua Science and Technology","20171214","2017","22","6","691","701","The Extreme Learning Machine (ELM) is an effective learning algorithm for a Single-Layer Feedforward Network (SLFN). It performs well in managing some problems due to its fast learning speed. However, in practical applications, its performance might be affected by the noise in the training data. To tackle the noise issue, we propose a novel heterogeneous ensemble of ELMs in this article. Specifically, the correntropy is used to achieve insensitive performance to outliers, while implementing Negative Correlation Learning (NCL) to enhance diversity among the ensemble. The proposed Heterogeneous Ensemble of ELMs (HE<sup>2</sup>LM) for classification has different ELM algorithms including the Regularized ELM (RELM), the Kernel ELM (KELM), and the L<sub>2</sub>-norm-optimized ELM (ELML2). The ensemble is constructed by training a randomly selected ELM classifier on a subset of the training data selected through random resampling. Then, the class label of unseen data is predicted using a maximum weighted sum approach. After splitting the training data into subsets, the proposed HE<sup>2</sup>LM is tested through classification and regression tasks on real-world benchmark datasets and synthetic datasets. Hence, the simulation results show that compared with other algorithms, our proposed method can achieve higher prediction accuracy, better generalization, and less sensitivity to outliers.","","","10.23919/TST.2017.8195351","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8195351","Extreme Learning Machine (ELM);classification;correntropy;ensemble;negative correlation","Correlation;Diversity reception;Kernel;Optimization;Prediction algorithms;Training;Training data","","","","","","","","","","December 2017","","TUP","TUP Journals & Magazines"
