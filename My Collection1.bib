@article{Ashari2013,
abstract = {â€”Energy simulation tool is a tool to simulate energy use by a building prior to the erection of the building. Commonly it has a feature providing alternative designs that are better than the user's design. In this paper, we propose a novel method in searching alternative design that is by using classification method. The classifiers we use are Na{\"{i}}ve Bayes, Decision Tree, and k-Nearest Neighbor. Our experiments hows that Decision Tree has the fastest classification time followed by Na{\"{i}}ve Bayes and k-Nearest Neighbor. The differences between classification time of Decision Tree and Na{\"{i}}ve Bayes also between Na{\"{i}}ve Bayes and k-NN are about an order of magnitude. Based on Percision, Recall, F-measure, Accuracy, and AUC, the performance of Na{\"{i}}ve Bayes is the best. It outperforms Decision Tree and k-Nearest Neighbor on all parameters but precision.},
author = {Ashari, Ahmad and Paryudi, I and Tjoa, Am},
doi = {10.14569/IJACSA.2013.041105},
journal = {International Journal of Advanced Computer Science and Applications},
keywords = {bayes,classification method,data preparation followed by,decision tree,discussion are,energy simulation tool,experiment in section 4,k-nearest neighbor,na{\"{i}}ve,section 3 explains the,the,the result and its},
number = {11},
pages = {33--39},
title = {{Performance Comparison between Na{\"{i}}ve Bayes, Decision Tree and k-Nearest Neighbor in Searching Alternative Design in an Energy Simulation Tool}},
url = {http://thesai.org/Downloads/Volume4No11/Paper{\_}5-Performance{\_}Comparison{\_}between{\_}Na?ve{\_}Bayes.pdf},
volume = {4},
year = {2013}
}
@article{Entezari-Maleki2009,
abstract = {In this paper, the efficacy of seven data classification methods; Decision Tree (DT), k-Nearest Neighbor (k-NN), Logistic Regression (LogR), Na{\"{i}}ve Bayes (NB), C4.5, Support Vector Machine (SVM) and Linear Classifier (LC) with regard to the Area Under Curve (AUC) metric have been compared. The effects of parameters including size of the dataset, kind of the independent attributes, and the number of the discrete and continuous attributes have been investigated. Based on the results, it can be concluded that in the datasets with few numbers of records, the AUC become deviated and the comparison between classifiers may not do correctly. When the number of the records and the number of the attributes in each record are increased, the results become more stable. Four classifiers DT, k-NN, SVM and C4.5 obtain higher AUC than three classifiers LogR, NB and LC. Among these four classifiers, C4.5 provides higher AUC in the most cases. As a comparison among three classifiers LogR, NB and LC, it can be said that NB provides the best AUC among them and classifiers LogR and NB have the same results, approximately.},
author = {Entezari-Maleki, Reza and Rezaei, Arash and Minaei-Bidgoli, Behrouz},
doi = {10.4156/jcit.vol4.issue3.14},
issn = {1975-9320},
journal = {Journal of Convergence Information Technology},
keywords = {area under curve metric,attributes types,classification methods,sample size},
number = {3},
pages = {94--102},
title = {{Comparison of Classification Methods Based on the Type of Attributes and Sample Size}},
url = {http://www4.ncsu.edu/{~}arezaei2/paper/JCIT4-184028{\_}Camera Ready.pdf{\%}5Cnhttp://www.aicit.org/jcit/paper{\_}detail.html?q=66},
volume = {4},
year = {2009}
}
@article{Guosheng2008,
abstract = {Suppliers' selection in supply chain management (SCM) has attracted considerable research interests in recent years. Recent literatures show that neural networks achieve better performance than traditional statistical methods. However, neural networks have inherent drawbacks, such as local optimization solution, lack generalization, and uncontrolled convergence. A relatively new machine learning technique, support vector machine (SVM), which overcomes the drawbacks of neural networks, is introduced to provide a model with better explanatory power to select ideal supplier partners. Meanwhile, in practice, the suppliers' samples are very insufficient. SVMs are adaptive to deal with small samples' training and testing. The prediction accuracies for BPNN and SVM methods are compared to choose the appreciating suppliers. The actual examples illustrate that SVM methods are superior to BPNN. {\textcopyright} 2008 The Second Academy of China Aerospace Science {\&} Industry Cooperation.},
author = {Guosheng, Hu and Guohong, Zhang},
doi = {10.1016/S1004-4132(08)60085-7},
isbn = {1004-4132},
issn = {10044132},
journal = {Journal of Systems Engineering and Electronics},
keywords = {BPNN,logistics,supplier selection,supply chain management,support vector machine},
number = {2},
pages = {316--320},
title = {{Comparison on neural networks and support vector machines in suppliers' selection}},
volume = {19},
year = {2008}
}
@book{Han2012,
abstract = {Presenting proven algorithms and sound implementations ready to be used directly or with strategic modification against live data, this resource is all you need if you want to apply todays most powerful data mining techniques to meet real business challenges.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Han, Jiawei and Kamber, Micheline and Pei, Jian},
booktitle = {San Francisco, CA, itd: Morgan Kaufmann},
doi = {10.1016/B978-0-12-381479-1.00001-0},
eprint = {arXiv:1011.1669v3},
isbn = {978-0-12-381479-1},
issn = {1469-994X},
keywords = {0123814790,9780123814791},
pages = {745},
pmid = {24520147},
title = {{Data Mining: Concepts and Techniques}},
url = {http://myweb.sabanciuniv.edu/rdehkharghani/files/2016/02/The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf{\%}0Ahttp://scholar.google.com/schol},
year = {2012}
}
@book{Harrington2012,
author = {Harrington, Peter},
isbn = {9781617290183},
publisher = {Manning},
title = {{Machine Learning in Action}},
year = {2012}
}
@article{Hoens2013,
abstract = {$\backslash$nClassification is one of the most fundamental tasks in the machine learning and data-mining communities. One of the most common challenges faced when trying to perform classification is the class imbalance problem. A number of sampling approaches, ranging from under-sampling to over-sampling, have been developed to solve the problem of class imbalance. This chapter provides an overview of the sampling strategies as well as classification algorithms developed for countering class imbalance. It considers the issues of correctly evaluating the performance of a classifier on imbalanced datasets and presents a discussion on various metrics. The sampling techniques discussed here include under-sampling, over-sampling, hybrid techniques and ensemble-based methods. Methods have also been developed that aim to directly combat class imbalance without the need for sampling. These methods come mainly from the cost-sensitive learning community; however, classifiers that deal with imbalance are not necessarily cost-sensitive learners.$\backslash$n$\backslash$n$\backslash$nControlled Vocabulary Terms$\backslash$n$\backslash$nclassification; learning (artificial intelligence); sampling methods$\backslash$n},
author = {Hoens, T Ryan and Chawla, Nitesh V},
doi = {10.1002/9781118646106.ch3},
isbn = {9781118646106},
journal = {Imbalanced Learning:Foundations, Algorithms, and Applications},
keywords = {class imbalance problem,classification algorithms,classifiers,cost-sensitive learning community,imbalanced datasets,machine learning,sampling methods},
pages = {43--59},
title = {{Imbalanced Datasets: From Sampling to Classifiers}},
url = {http://dx.doi.org/10.1002/9781118646106.ch3},
year = {2013}
}
@article{Huang2003,
abstract = { Predictive accuracy has often been used as the main and often only evaluation criterion for the predictive performance of classification or data mining algorithms. In recent years, the area under the ROC (receiver operating characteristics) curve, or simply AUC, has been proposed as an alternative single-number measure for evaluating performance of learning algorithms. We proved that AUC is, in general, a better measure (defined precisely) than accuracy. Many popular data mining algorithms should then be reevaluated in terms of AUC. For example, it is well accepted that Naive Bayes and decision trees are very similar in accuracy. How do they compare in AUC? Also, how does the recently developed SVM (support vector machine) compare to traditional learning algorithms in accuracy and AUC? We will answer these questions. Our conclusions will provide important guidelines in data mining applications on real-world datasets.},
author = {Huang, J. and Lu, J. and Ling, C.X.},
doi = {10.1109/ICDM.2003.1250975},
isbn = {0-7695-1978-4},
issn = {15504786},
journal = {Third IEEE International Conference on Data Mining},
pages = {553--556},
title = {{Comparing naive Bayes, decision trees, and SVM with AUC and accuracy}},
url = {http://ieeexplore.ieee.org/document/1250975/},
year = {2003}
}
@book{Kantardzic2011,
abstract = {This book reviews state-of-the-art methodologies and techniques for analyzing enormous quantities of raw data in high-dimensional data spaces, to extract new information for decision making. The goal of this book is to provide a single introductory source, organized in a systematic way, in which we could direct the readers in analysis of large data sets, through the explanation of basic concepts, models and methodologies developed in recent decades. If you are an instructor or professor and would like to obtain instructor's materials, please visit http://booksupport.wiley.com. If you are an instructor or professor and would like to obtain a solutions manual, please send an email to: pressbooks@ieee.org. {\textcopyright} 2011 Institute of Electrical and Electronics Engineers.},
author = {Kantardzic, Mehmed},
booktitle = {Wiley-IEEE Press},
doi = {10.1002/9781118029145},
isbn = {1118029135},
pages = {552},
title = {{Data Mining: Concepts, Models, Methods, and Algorithms}},
url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470890452.html},
year = {2011}
}
@article{Raczko2017,
abstract = {Knowledge of tree species composition in a forest is an important topic in forest management. Accurate tree species maps allow for much more detailed and in-depth analysis of biophysical forest variables. The paper presents a comparison of three classification algorithms: support vector machines (SVM), random forest (RF) and artificial neural networks (ANN) for tree species classification using airborne hyperspectral data from the Airborne Prism EXperiment sensor. The aim of this paper is to evaluate the three nonparametric classification algorithms (SVM, RF and ANN) in an attempt to classify the five most common tree species of the Szklarska Por{\c{e}}ba area: spruce (Picea alba L. Karst), larch (Larix decidua Mill.), alder (Alnus Mill), beech (Fagus sylvatica L.) and birch (Betula pendula Roth). To avoid human introduced biases a 0.632 bootstrap procedure was used during evaluation of each compared classifier. Of all compared classification results, ANN achieved the highest median overall classificati...},
archivePrefix = {arXiv},
arxivId = {http://www.tandfonline.com/doi/pdf/10.1080/22797254.2017.1299557},
author = {Raczko, Edwin and Zagajewski, Bogdan},
doi = {10.1080/22797254.2017.1299557},
eprint = {/www.tandfonline.com/doi/pdf/10.1080/22797254.2017.1299557},
isbn = {9788364528163},
issn = {2279-7254},
journal = {European Journal of Remote Sensing},
keywords = {Support vector machines,artificial,artificial neural networks,classification,hyperspectral data,random forest,support vector machines},
number = {1},
pages = {144--154},
primaryClass = {http:},
publisher = {Taylor {\&} Francis},
title = {{Comparison of support vector machine, random forest and neural network classifiers for tree species classification on airborne hyperspectral APEX images}},
url = {https://www.tandfonline.com/doi/full/10.1080/22797254.2017.1299557},
volume = {50},
year = {2017}
}
@book{Tan2006,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {et. al Tan, Pang-Ning},
booktitle = {Introduction to Data Mining},
doi = {10.1016/0022-4405(81)90007-8},
eprint = {arXiv:1011.1669v3},
isbn = {0321321367},
issn = {00224405},
number = {Pearson Addison-Wesley},
pmid = {21635741},
title = {{Introduction to Data Mining}},
year = {2006}
}
@article{Zhang2017,
abstract = {Current benchmark reports of classification algorithms generally concern common classifiers and their variants but do not include many algorithms that have been introduced in recent years. Moreover, important properties such as the dependency on number of classes and features and CPU running time are typically not examined. In this paper, we carry out a comparative empirical study on both established classifiers and more recently proposed ones on 71 data sets originating from different domains, publicly available at UCI and KEEL repositories. The list of 11 algorithms studied includes Extreme Learning Machine (ELM), Sparse Representation based Classification (SRC), and Deep Learning (DL), which have not been thoroughly investigated in existing comparative studies. It is found that Stochastic Gradient Boosting Trees (GBDT) matches or exceeds the prediction performance of Support Vector Machines (SVM) and Random Forests (RF), while being the fastest algorithm in terms of prediction efficiency. ELM also yields good accuracy results, ranking in the top-5, alongside GBDT, RF, SVM, and C4.5 but this performance varies widely across all data sets. Unsurprisingly, top accuracy performers have average or slow training time efficiency. DL is the worst performer in terms of accuracy but second fastest in prediction efficiency. SRC shows good accuracy performance but it is the slowest classifier in both training and testing.},
author = {Zhang, Chongsheng and Liu, Changchang and Zhang, Xiangliang and Almpanidis, George},
doi = {10.1016/j.eswa.2017.04.003},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Classification benchmarking,Classifier comparison,Classifier evaluation},
pages = {128--150},
publisher = {Elsevier Ltd},
title = {{An up-to-date comparison of state-of-the-art classification algorithms}},
url = {http://dx.doi.org/10.1016/j.eswa.2017.04.003},
volume = {82},
year = {2017}
}
